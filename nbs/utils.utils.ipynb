{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f38d0edc",
   "metadata": {},
   "source": [
    "<h1>Table of Contents<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"></ul></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c64bab1d",
   "metadata": {},
   "source": [
    "<h1>Table of Contents<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"></ul></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8385fe3f",
   "metadata": {},
   "source": [
    "<h1>Table of Contents<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"></ul></div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a28b1c11",
   "metadata": {},
   "outputs": [],
   "source": [
    "# default_exp utils.utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16881815",
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "\n",
    "import sys\n",
    "import os\n",
    "import soundfile as sf\n",
    "import pandas as pd\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import soundfile as sf\n",
    "import librosa\n",
    "from torch.nn import functional as F\n",
    "\n",
    "\n",
    "def load_filepaths_and_text(filename: str, split: str = \"|\"):\n",
    "    with open(filename, encoding=\"utf-8\") as f:\n",
    "        filepaths_and_text = [line.strip().split(split) for line in f]\n",
    "    return filepaths_and_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f470161",
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "\n",
    "import torch\n",
    "import numpy as np\n",
    "from scipy.signal import get_window\n",
    "import librosa.util as librosa_util\n",
    "\n",
    "\n",
    "def window_sumsquare(\n",
    "    window,\n",
    "    n_frames,\n",
    "    hop_length=200,\n",
    "    win_length=800,\n",
    "    n_fft=800,\n",
    "    dtype=np.float32,\n",
    "    norm=None,\n",
    "):\n",
    "    \"\"\"\n",
    "    # from librosa 0.6\n",
    "    Compute the sum-square envelope of a window function at a given hop length.\n",
    "\n",
    "    This is used to estimate modulation effects induced by windowing\n",
    "    observations in short-time fourier transforms.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    window : string, tuple, number, callable, or list-like\n",
    "        Window specification, as in `get_window`\n",
    "\n",
    "    n_frames : int > 0\n",
    "        The number of analysis frames\n",
    "\n",
    "    hop_length : int > 0\n",
    "        The number of samples to advance between frames\n",
    "\n",
    "    win_length : [optional]\n",
    "        The length of the window function.  By default, this matches `n_fft`.\n",
    "\n",
    "    n_fft : int > 0\n",
    "        The length of each analysis frame.\n",
    "\n",
    "    dtype : np.dtype\n",
    "        The data type of the output\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    wss : np.ndarray, shape=`(n_fft + hop_length * (n_frames - 1))`\n",
    "        The sum-squared envelope of the window function\n",
    "    \"\"\"\n",
    "    if win_length is None:\n",
    "        win_length = n_fft\n",
    "\n",
    "    n = n_fft + hop_length * (n_frames - 1)\n",
    "    x = np.zeros(n, dtype=dtype)\n",
    "\n",
    "    # Compute the squared window at the desired length\n",
    "    win_sq = get_window(window, win_length, fftbins=True)\n",
    "    win_sq = librosa_util.normalize(win_sq, norm=norm) ** 2\n",
    "    win_sq = librosa_util.pad_center(win_sq, n_fft)\n",
    "\n",
    "    # Fill the envelope\n",
    "    for i in range(n_frames):\n",
    "        sample = i * hop_length\n",
    "        x[sample : min(n, sample + n_fft)] += win_sq[: max(0, min(n_fft, n - sample))]\n",
    "    return x\n",
    "\n",
    "\n",
    "def griffin_lim(magnitudes, stft_fn, n_iters=30):\n",
    "    \"\"\"\n",
    "    PARAMS\n",
    "    ------\n",
    "    magnitudes: spectrogram magnitudes\n",
    "    stft_fn: STFT class with transform (STFT) and inverse (ISTFT) methods\n",
    "    \"\"\"\n",
    "\n",
    "    angles = np.angle(np.exp(2j * np.pi * np.random.rand(*magnitudes.size())))\n",
    "    angles = angles.astype(np.float32)\n",
    "    angles = torch.autograd.Variable(torch.from_numpy(angles))\n",
    "    signal = stft_fn.inverse(magnitudes, angles).squeeze(1)\n",
    "\n",
    "    for i in range(n_iters):\n",
    "        _, angles = stft_fn.transform(signal)\n",
    "        signal = stft_fn.inverse(magnitudes, angles).squeeze(1)\n",
    "    return signal\n",
    "\n",
    "\n",
    "def dynamic_range_compression(x, C=1, clip_val=1e-5):\n",
    "    \"\"\"\n",
    "    PARAMS\n",
    "    ------\n",
    "    C: compression factor\n",
    "    \"\"\"\n",
    "    return torch.log(torch.clamp(x, min=clip_val) * C)\n",
    "\n",
    "\n",
    "def dynamic_range_decompression(x, C=1):\n",
    "    \"\"\"\n",
    "    PARAMS\n",
    "    ------\n",
    "    C: compression factor used to compress\n",
    "    \"\"\"\n",
    "    return torch.exp(x) / C"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1744f5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "def to_gpu(x):\n",
    "    x = x.contiguous()\n",
    "\n",
    "    if torch.cuda.is_available():\n",
    "        x = x.cuda(non_blocking=True)\n",
    "    return torch.autograd.Variable(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afec67d2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 1.0415e+00, -3.7111e-01, -3.2838e-01, -6.2205e-01, -2.6169e-01,\n",
       "         -9.8103e-01, -1.8675e+00, -7.7150e-01, -1.7760e-01, -6.8241e-01],\n",
       "        [-5.1025e-01, -1.1788e+00,  1.2456e+00,  1.1683e+00, -1.5050e+00,\n",
       "          3.8878e-01,  3.4331e-01, -4.6678e-02, -4.9398e-01, -1.3587e+00],\n",
       "        [-2.0366e+00, -2.1385e-01,  1.2572e-01,  1.0080e+00, -4.1069e-01,\n",
       "         -1.1727e+00, -5.8472e-01, -1.5301e-01, -7.7718e-01, -1.4033e-01],\n",
       "        [-8.1851e-01,  1.1898e+00,  3.7606e-01, -2.1779e+00,  2.1037e-01,\n",
       "         -1.0227e+00,  7.8290e-01,  9.2825e-01,  1.7582e+00, -6.0930e-02],\n",
       "        [-2.2755e+00, -1.9536e+00,  2.1239e-01, -6.8103e-01, -1.1368e-02,\n",
       "          5.7643e-01, -6.6171e-01, -3.3325e-01, -8.7990e-01,  1.0076e+00],\n",
       "        [-3.9319e-01,  8.9259e-01, -6.4939e-01, -4.6909e-01, -8.9252e-01,\n",
       "          9.5496e-01,  5.3429e-02, -1.4436e-01, -1.6097e-01, -3.0059e-01],\n",
       "        [-3.0589e-01, -2.9385e-02, -1.1399e+00,  1.7461e+00,  1.1013e-01,\n",
       "          4.2333e-01, -1.7093e+00,  5.6877e-02,  9.2514e-01,  9.9316e-01],\n",
       "        [ 4.9825e-01, -1.1996e+00,  1.6417e+00, -9.8894e-01, -4.0618e-01,\n",
       "         -7.6356e-01, -9.5752e-01,  1.1703e+00,  1.3896e-01, -3.3922e-01],\n",
       "        [ 8.8861e-01,  5.1271e-01, -1.6149e+00,  5.4874e-01,  5.3368e-02,\n",
       "          1.0879e+00,  1.5214e-01, -1.4647e-01,  6.3347e-01, -1.5482e-03],\n",
       "        [-5.4721e-01,  1.2666e+00, -1.2289e+00,  2.3877e+00,  5.3439e-01,\n",
       "         -9.8616e-01, -1.8520e-01, -1.1032e+00,  7.2345e-01, -7.1658e-01]])"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "to_gpu(torch.randn(10, 10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b28796e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "\n",
    "\n",
    "def get_mask_from_lengths(lengths: torch.Tensor, max_len: int = 0):\n",
    "    \"\"\"Return a mask matrix. Unmasked entires are true.\"\"\"\n",
    "    if max_len == 0:\n",
    "        max_len = int(torch.max(lengths).item())\n",
    "    ids = torch.arange(0, max_len, device=lengths.device, dtype=torch.long)\n",
    "    mask = (ids < lengths.unsqueeze(1)).bool()\n",
    "    return mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3af55f39",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "assert (\n",
    "    get_mask_from_lengths(torch.LongTensor([1, 3, 2, 1]))\n",
    "    == torch.Tensor(\n",
    "        [\n",
    "            [True, False, False],\n",
    "            [True, True, True],\n",
    "            [True, True, False],\n",
    "            [True, False, False],\n",
    "        ]\n",
    "    )\n",
    ").all()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "084d17c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "import torch.distributed as dist\n",
    "\n",
    "\n",
    "def reduce_tensor(tensor, n_gpus):\n",
    "    rt = tensor.clone()\n",
    "    dist.all_reduce(rt, op=dist.ReduceOp.SUM)\n",
    "    rt /= n_gpus\n",
    "    return rt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db0550fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "def subsequent_mask(length):\n",
    "    mask = torch.tril(torch.ones(length, length)).unsqueeze(0).unsqueeze(0)\n",
    "    return mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a37dff7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "assert (subsequent_mask(2) == torch.tensor([[[1, 0], [1, 1]]])).all()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecb9fcbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "def convert_pad_shape(pad_shape):\n",
    "    \"\"\"Reverse, then flatten a list of lists.\"\"\"\n",
    "    l = pad_shape[::-1]\n",
    "    pad_shape = [item for sublist in l for item in sublist]\n",
    "    return pad_shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7678bc6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "convert_pad_shape([[1, 2], [3, 4], [5, 6, 7]]) == [5, 6, 7, 3, 4, 1, 2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56693e82",
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "def sequence_mask(length, max_length=None):\n",
    "    \"\"\"The same as get_mask_from_lengths\"\"\"\n",
    "    if max_length is None:\n",
    "        max_length = length.max()\n",
    "    x = torch.arange(max_length, dtype=length.dtype, device=length.device)\n",
    "    return x.unsqueeze(0) < length.unsqueeze(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da5e98e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "assert (\n",
    "    sequence_mask(torch.tensor([1, 3, 2, 1]))\n",
    "    == torch.Tensor(\n",
    "        [\n",
    "            [True, False, False],\n",
    "            [True, True, True],\n",
    "            [True, True, False],\n",
    "            [True, False, False],\n",
    "        ]\n",
    "    )\n",
    ").all()\n",
    "assert (\n",
    "    sequence_mask(torch.tensor([1, 3, 2, 1]), 4)\n",
    "    == torch.Tensor(\n",
    "        [\n",
    "            [True, False, False, False],\n",
    "            [True, True, True, False],\n",
    "            [True, True, False, False],\n",
    "            [True, False, False, False],\n",
    "        ]\n",
    "    )\n",
    ").all()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "361d085c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "def generate_path(duration, mask):\n",
    "    \"\"\"\n",
    "    duration: [b, 1, t_x]\n",
    "    mask: [b, 1, t_y, t_x]\n",
    "    \"\"\"\n",
    "    device = duration.device\n",
    "\n",
    "    b, _, t_y, t_x = mask.shape\n",
    "    cum_duration = torch.cumsum(duration, -1)\n",
    "\n",
    "    cum_duration_flat = cum_duration.view(b * t_x)\n",
    "    path = sequence_mask(cum_duration_flat, t_y).to(mask.dtype)\n",
    "    path = path.view(b, t_x, t_y)\n",
    "    path = path - F.pad(path, convert_pad_shape([[0, 0], [1, 0], [0, 0]]))[:, :-1]\n",
    "    path = path.unsqueeze(1).transpose(2, 3) * mask\n",
    "    return path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63d134ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "\n",
    "\n",
    "def slice_segments(x, ids_str, segment_size=4):\n",
    "    ret = torch.zeros_like(x[:, :, :segment_size])\n",
    "    for i in range(x.size(0)):\n",
    "        idx_str = ids_str[i]\n",
    "        idx_end = idx_str + segment_size\n",
    "        ret[i] = x[i, :, idx_str:idx_end]\n",
    "    return ret\n",
    "\n",
    "\n",
    "def rand_slice_segments(x, x_lengths=None, segment_size=4):\n",
    "    b, d, t = x.size()\n",
    "    if x_lengths is None:\n",
    "        x_lengths = t\n",
    "    ids_str_max = x_lengths - segment_size\n",
    "    ids_str = (torch.rand([b]).to(device=x.device) * ids_str_max).to(dtype=torch.long)\n",
    "    ret = slice_segments(x, ids_str, segment_size)\n",
    "    return ret, ids_str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c767aa3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "def init_weights(m, mean=0.0, std=0.01):\n",
    "    classname = m.__class__.__name__\n",
    "    if classname.find(\"Conv\") != -1:\n",
    "        m.weight.data.normal_(mean, std)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a9547a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "def get_padding(kernel_size, dilation=1):\n",
    "    return int((kernel_size * dilation - dilation) / 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52e281e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "@torch.jit.script\n",
    "def fused_add_tanh_sigmoid_multiply(input_a, input_b, n_channels):\n",
    "    n_channels_int = n_channels[0]\n",
    "    in_act = input_a + input_b\n",
    "    t_act = torch.tanh(in_act[:, :n_channels_int, :])\n",
    "    s_act = torch.sigmoid(in_act[:, n_channels_int:, :])\n",
    "    acts = t_act * s_act\n",
    "    return acts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "032fa9fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "def clip_grad_value_(parameters, clip_value, norm_type=2):\n",
    "    if isinstance(parameters, torch.Tensor):\n",
    "        parameters = [parameters]\n",
    "    parameters = list(filter(lambda p: p.grad is not None, parameters))\n",
    "    norm_type = float(norm_type)\n",
    "    if clip_value is not None:\n",
    "        clip_value = float(clip_value)\n",
    "\n",
    "    total_norm = 0\n",
    "    for p in parameters:\n",
    "        param_norm = p.grad.data.norm(norm_type)\n",
    "        total_norm += param_norm.item() ** norm_type\n",
    "        if clip_value is not None:\n",
    "            p.grad.data.clamp_(min=-clip_value, max=clip_value)\n",
    "    total_norm = total_norm ** (1.0 / norm_type)\n",
    "    return total_norm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87f1ead5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "\n",
    "\n",
    "def intersperse(lst, item):\n",
    "    result = [item] * (len(lst) * 2 + 1)\n",
    "    result[1::2] = lst\n",
    "    return result\n",
    "\n",
    "\n",
    "def intersperse_emphases(emphases):\n",
    "    for n in range(len(emphases)):\n",
    "        emphases[n][0] = 2 * emphases[n][0]\n",
    "        emphases[n][1] = 2 * emphases[n][1] + 1\n",
    "    return emphases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a1ff5b8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "intersperse([1, 2, 3, 4], 0) == [0, 1, 0, 2, 0, 3, 0, 4, 0]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
