{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "535085d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# default_exp trainer.gradtts"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "653d4f95",
   "metadata": {},
   "source": [
    "# Trainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47500540",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "Couldn't build proto file into descriptor pool!\nInvalid proto descriptor for file \"tensorboard/compat/proto/tensor_shape.proto\":\n  tensorboard.TensorShapeProto.dim: \"tensorboard.TensorShapeProto.dim\" is already defined in file \"tensorboardX/src/tensor_shape.proto\".\n  tensorboard.TensorShapeProto.unknown_rank: \"tensorboard.TensorShapeProto.unknown_rank\" is already defined in file \"tensorboardX/src/tensor_shape.proto\".\n  tensorboard.TensorShapeProto.Dim.size: \"tensorboard.TensorShapeProto.Dim.size\" is already defined in file \"tensorboardX/src/tensor_shape.proto\".\n  tensorboard.TensorShapeProto.Dim.name: \"tensorboard.TensorShapeProto.Dim.name\" is already defined in file \"tensorboardX/src/tensor_shape.proto\".\n  tensorboard.TensorShapeProto.Dim: \"tensorboard.TensorShapeProto.Dim\" is already defined in file \"tensorboardX/src/tensor_shape.proto\".\n  tensorboard.TensorShapeProto: \"tensorboard.TensorShapeProto\" is already defined in file \"tensorboardX/src/tensor_shape.proto\".\n  tensorboard.TensorShapeProto.dim: \"tensorboard.TensorShapeProto.Dim\" seems to be defined in \"tensorboardX/src/tensor_shape.proto\", which is not imported by \"tensorboard/compat/proto/tensor_shape.proto\".  To use it here, please add the necessary import.\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-926efa5ed7ea>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0muberduck_ml_dev\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutil\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtext_to_sequence\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrandom_utterance\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0muberduck_ml_dev\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msymbols\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0msymbols_with_ipa\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 27\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0muberduck_ml_dev\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbase\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mTTSTrainer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     28\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m from uberduck_ml_dev.data_loader import (\n",
      "\u001b[0;32m~/code/uberduck-ml-dev/uberduck_ml_dev/trainer/base.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdistributed\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mdist\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensorboard\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mSummaryWriter\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/uberduck/lib/python3.6/site-packages/torch/utils/tensorboard/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;32mdel\u001b[0m \u001b[0mtensorboard\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mwriter\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mFileWriter\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mSummaryWriter\u001b[0m  \u001b[0;31m# noqa F401\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorboard\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msummary\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwriter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecord_writer\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mRecordWriter\u001b[0m  \u001b[0;31m# noqa F401\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/uberduck/lib/python3.6/site-packages/torch/utils/tensorboard/writer.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorboard\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompat\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorboard\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mproto\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevent_pb2\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mSessionLog\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorboard\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mproto\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevent_pb2\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mEvent\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorboard\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mproto\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mevent_pb2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/uberduck/lib/python3.6/site-packages/tensorboard/compat/proto/event_pb2.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorboard\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mproto\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0msummary_pb2\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtensorboard_dot_compat_dot_proto_dot_summary__pb2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/uberduck/lib/python3.6/site-packages/tensorboard/compat/proto/summary_pb2.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorboard\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mproto\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtensor_pb2\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtensorboard_dot_compat_dot_proto_dot_tensor__pb2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/uberduck/lib/python3.6/site-packages/tensorboard/compat/proto/tensor_pb2.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorboard\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mproto\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mresource_handle_pb2\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtensorboard_dot_compat_dot_proto_dot_resource__handle__pb2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorboard\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mproto\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtensor_shape_pb2\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtensorboard_dot_compat_dot_proto_dot_tensor__shape__pb2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorboard\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mproto\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtypes_pb2\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtensorboard_dot_compat_dot_proto_dot_types__pb2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/uberduck/lib/python3.6/site-packages/tensorboard/compat/proto/resource_handle_pb2.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorboard\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mproto\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtensor_shape_pb2\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtensorboard_dot_compat_dot_proto_dot_tensor__shape__pb2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorboard\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mproto\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtypes_pb2\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtensorboard_dot_compat_dot_proto_dot_types__pb2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/uberduck/lib/python3.6/site-packages/tensorboard/compat/proto/tensor_shape_pb2.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     21\u001b[0m   \u001b[0msyntax\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'proto3'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m   \u001b[0mserialized_options\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0m_b\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'\\n\\030org.tensorflow.frameworkB\\021TensorShapeProtosP\\001ZSgithub.com/tensorflow/tensorflow/tensorflow/go/core/framework/tensor_shape_go_proto\\370\\001\\001'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 23\u001b[0;31m   \u001b[0mserialized_pb\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0m_b\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'\\n+tensorboard/compat/proto/tensor_shape.proto\\x12\\x0btensorboard\\\"{\\n\\x10TensorShapeProto\\x12.\\n\\x03\\x64im\\x18\\x02 \\x03(\\x0b\\x32!.tensorboard.TensorShapeProto.Dim\\x12\\x14\\n\\x0cunknown_rank\\x18\\x03 \\x01(\\x08\\x1a!\\n\\x03\\x44im\\x12\\x0c\\n\\x04size\\x18\\x01 \\x01(\\x03\\x12\\x0c\\n\\x04name\\x18\\x02 \\x01(\\tB\\x87\\x01\\n\\x18org.tensorflow.frameworkB\\x11TensorShapeProtosP\\x01ZSgithub.com/tensorflow/tensorflow/tensorflow/go/core/framework/tensor_shape_go_proto\\xf8\\x01\\x01\\x62\\x06proto3'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     24\u001b[0m )\n\u001b[1;32m     25\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/uberduck/lib/python3.6/site-packages/google/protobuf/descriptor.py\u001b[0m in \u001b[0;36m__new__\u001b[0;34m(cls, name, package, options, serialized_options, serialized_pb, dependencies, public_dependencies, syntax, pool, create_key)\u001b[0m\n\u001b[1;32m    963\u001b[0m           \u001b[0;32mraise\u001b[0m \u001b[0mRuntimeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Please link in cpp generated lib for %s'\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    964\u001b[0m       \u001b[0;32melif\u001b[0m \u001b[0mserialized_pb\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 965\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_message\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdefault_pool\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mAddSerializedFile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mserialized_pb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    966\u001b[0m       \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    967\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mFileDescriptor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcls\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__new__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcls\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: Couldn't build proto file into descriptor pool!\nInvalid proto descriptor for file \"tensorboard/compat/proto/tensor_shape.proto\":\n  tensorboard.TensorShapeProto.dim: \"tensorboard.TensorShapeProto.dim\" is already defined in file \"tensorboardX/src/tensor_shape.proto\".\n  tensorboard.TensorShapeProto.unknown_rank: \"tensorboard.TensorShapeProto.unknown_rank\" is already defined in file \"tensorboardX/src/tensor_shape.proto\".\n  tensorboard.TensorShapeProto.Dim.size: \"tensorboard.TensorShapeProto.Dim.size\" is already defined in file \"tensorboardX/src/tensor_shape.proto\".\n  tensorboard.TensorShapeProto.Dim.name: \"tensorboard.TensorShapeProto.Dim.name\" is already defined in file \"tensorboardX/src/tensor_shape.proto\".\n  tensorboard.TensorShapeProto.Dim: \"tensorboard.TensorShapeProto.Dim\" is already defined in file \"tensorboardX/src/tensor_shape.proto\".\n  tensorboard.TensorShapeProto: \"tensorboard.TensorShapeProto\" is already defined in file \"tensorboardX/src/tensor_shape.proto\".\n  tensorboard.TensorShapeProto.dim: \"tensorboard.TensorShapeProto.Dim\" seems to be defined in \"tensorboardX/src/tensor_shape.proto\", which is not imported by \"tensorboard/compat/proto/tensor_shape.proto\".  To use it here, please add the necessary import.\n"
     ]
    }
   ],
   "source": [
    "# export\n",
    "import json\n",
    "import os\n",
    "from pathlib import Path\n",
    "from pprint import pprint\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "from torch.cuda.amp import autocast, GradScaler\n",
    "import torch.distributed as dist\n",
    "from torch.nn import functional as F\n",
    "from torch.nn.parallel import DistributedDataParallel as DDP\n",
    "from torch.optim.lr_scheduler import ExponentialLR\n",
    "from torch.utils.data import DataLoader\n",
    "from tensorboardX import SummaryWriter\n",
    "import time\n",
    "\n",
    "from uberduck_ml_dev.models.common import MelSTFT\n",
    "from uberduck_ml_dev.utils.plot import (\n",
    "    plot_attention,\n",
    "    plot_gate_outputs,\n",
    "    plot_spectrogram,\n",
    "    plot_tensor,\n",
    ")\n",
    "from uberduck_ml_dev.text.util import text_to_sequence, random_utterance\n",
    "from uberduck_ml_dev.text.symbols import symbols_with_ipa\n",
    "from uberduck_ml_dev.trainer.base import TTSTrainer\n",
    "\n",
    "from uberduck_ml_dev.data_loader import (\n",
    "    TextAudioSpeakerLoader,\n",
    "    TextMelCollate,\n",
    "    DistributedBucketSampler,\n",
    "    TextMelDataset,\n",
    ")\n",
    "from uberduck_ml_dev.vendor.tfcompat.hparam import HParams\n",
    "from uberduck_ml_dev.utils.plot import save_figure_to_numpy, plot_spectrogram\n",
    "from uberduck_ml_dev.utils.utils import slice_segments, clip_grad_value_\n",
    "from uberduck_ml_dev.text.symbols import SYMBOL_SETS"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b34fa71",
   "metadata": {},
   "source": [
    "# Grad TTS Trainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90e61d3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "from tqdm import tqdm\n",
    "from uberduck_ml_dev.text.util import text_to_sequence, random_utterance\n",
    "from uberduck_ml_dev.models.gradtts import (\n",
    "    GradTTS,\n",
    ")\n",
    "from uberduck_ml_dev.utils.utils import intersperse\n",
    "\n",
    "\n",
    "class GradTTSTrainer(TTSTrainer):\n",
    "    REQUIRED_HPARAMS = [\n",
    "        \"training_audiopaths_and_text\",\n",
    "        \"test_audiopaths_and_text\",\n",
    "    ]\n",
    "\n",
    "    def __init__(self, *args, **kwargs):\n",
    "        super().__init__(*args, **kwargs)\n",
    "        for param in self.REQUIRED_HPARAMS:\n",
    "            if not hasattr(self, param):\n",
    "                raise Exception(f\"GradTTSTrainer missing a required param: {param}\")\n",
    "        self.sampling_rate = self.hparams.sampling_rate\n",
    "        self.checkpoint_path = self.hparams.log_dir\n",
    "\n",
    "    def sample_inference(self, model, timesteps=10, spk=None):\n",
    "        with torch.no_grad():\n",
    "            sequence = text_to_sequence(\n",
    "                random_utterance(),\n",
    "                self.text_cleaners,\n",
    "                1.0,\n",
    "                symbol_set=self.hparams.symbol_set,\n",
    "            )\n",
    "            if self.hparams.intersperse_text:\n",
    "                sequence = intersperse(\n",
    "                    sequence, (len(SYMBOL_SETS[self.hparams.symbol_set]))\n",
    "                )\n",
    "            x = torch.LongTensor(sequence).cuda()[None]\n",
    "            x_lengths = torch.LongTensor([x.shape[-1]]).cuda()\n",
    "            y_enc, y_dec, attn = model(\n",
    "                x,\n",
    "                x_lengths,\n",
    "                n_timesteps=50,\n",
    "                temperature=1.5,\n",
    "                stoc=False,\n",
    "                spk=spk,\n",
    "                length_scale=0.91,\n",
    "            )\n",
    "            if self.hparams.vocoder_algorithm == \"hifigan\":\n",
    "                audio = self.sample(\n",
    "                    y_dec,\n",
    "                    algorithm=self.hparams.vocoder_algorithm,\n",
    "                    hifigan_config=self.hparams.hifigan_config,\n",
    "                    hifigan_checkpoint=self.hparams.hifigan_checkpoint,\n",
    "                    cudnn_enabled=self.hparams.cudnn_enabled,\n",
    "                )\n",
    "            else:\n",
    "                audio = self.sample(y_dec.cpu()[0])\n",
    "            return audio\n",
    "\n",
    "    def train(self, checkpoint=None):\n",
    "        if self.distributed_run:\n",
    "            self.init_distributed()\n",
    "\n",
    "        train_dataset = TextMelDataset(\n",
    "            self.hparams.training_audiopaths_and_text,\n",
    "            self.hparams.text_cleaners,\n",
    "            1.0,\n",
    "            self.hparams.n_feats,\n",
    "            self.hparams.sampling_rate,\n",
    "            self.hparams.mel_fmin,\n",
    "            self.hparams.mel_fmax,\n",
    "            self.hparams.filter_length,\n",
    "            self.hparams.hop_length,\n",
    "            (self.hparams.filter_length - self.hparams.hop_length) // 2,\n",
    "            self.hparams.win_length,\n",
    "            intersperse_text=self.hparams.intersperse_text,\n",
    "            intersperse_token=(len(SYMBOL_SETS[self.hparams.symbol_set])),\n",
    "            symbol_set=self.hparams.symbol_set,\n",
    "        )\n",
    "        collate_fn = TextMelCollate()\n",
    "\n",
    "        loader = DataLoader(\n",
    "            dataset=train_dataset,\n",
    "            batch_size=self.hparams.batch_size,\n",
    "            collate_fn=collate_fn,\n",
    "            drop_last=True,\n",
    "            num_workers=0,\n",
    "            shuffle=False,\n",
    "        )\n",
    "\n",
    "        test_dataset = TextMelDataset(\n",
    "            self.hparams.test_audiopaths_and_text,\n",
    "            self.hparams.text_cleaners,\n",
    "            1.0,\n",
    "            self.hparams.n_feats,\n",
    "            self.hparams.sampling_rate,\n",
    "            self.hparams.mel_fmin,\n",
    "            self.hparams.mel_fmax,\n",
    "            self.hparams.filter_length,\n",
    "            self.hparams.hop_length,\n",
    "            (self.hparams.filter_length - self.hparams.hop_length) // 2,\n",
    "            self.hparams.win_length,\n",
    "            intersperse_text=self.hparams.intersperse_text,\n",
    "            intersperse_token=(len(SYMBOL_SETS[self.hparams.symbol_set])),\n",
    "            symbol_set=self.hparams.symbol_set,\n",
    "        )\n",
    "\n",
    "        model = GradTTS(self.hparams)\n",
    "\n",
    "        if self.hparams.checkpoint:\n",
    "            model.load_state_dict(torch.load(self.hparams.checkpoint))\n",
    "        model = model.cuda()\n",
    "\n",
    "        print(\n",
    "            \"Number of encoder + duration predictor parameters: %.2fm\"\n",
    "            % (model.encoder.nparams / 1e6)\n",
    "        )\n",
    "        print(\"Number of decoder parameters: %.2fm\" % (model.decoder.nparams / 1e6))\n",
    "        print(\"Total parameters: %.2fm\" % (model.nparams / 1e6))\n",
    "\n",
    "        print(\"Initializing optimizer...\")\n",
    "        optimizer = torch.optim.Adam(\n",
    "            params=model.parameters(), lr=self.hparams.learning_rate\n",
    "        )\n",
    "        test_batch = test_dataset.sample_test_batch(size=self.hparams.test_size)\n",
    "        for i, item in enumerate(test_batch):\n",
    "            text, mel, spk = item\n",
    "            self.log(\n",
    "                f\"image_{i}/ground_truth\",\n",
    "                0,\n",
    "                image=plot_tensor(mel.squeeze()),\n",
    "            )\n",
    "        iteration = 0\n",
    "        last_time = time.time()\n",
    "        for epoch in range(0, self.hparams.n_epochs):\n",
    "            model.train()\n",
    "            dur_losses = []\n",
    "            prior_losses = []\n",
    "            diff_losses = []\n",
    "            for batch_idx, batch in enumerate(loader):\n",
    "                model.zero_grad()\n",
    "                x, x_lengths, y, _, y_lengths, speaker_ids = batch\n",
    "\n",
    "                dur_loss, prior_loss, diff_loss = model.compute_loss(\n",
    "                    x, x_lengths, y, y_lengths, out_size=self.hparams.out_size\n",
    "                )\n",
    "                loss = sum([dur_loss, prior_loss, diff_loss])\n",
    "                loss.backward()\n",
    "\n",
    "                enc_grad_norm = torch.nn.utils.clip_grad_norm_(\n",
    "                    model.encoder.parameters(), max_norm=1\n",
    "                )\n",
    "                dec_grad_norm = torch.nn.utils.clip_grad_norm_(\n",
    "                    model.decoder.parameters(), max_norm=1\n",
    "                )\n",
    "                optimizer.step()\n",
    "\n",
    "                self.log(\"training/duration_loss\", iteration, dur_loss.item())\n",
    "                self.log(\"training/prior_loss\", iteration, prior_loss.item())\n",
    "                self.log(\"training/diffusion_loss\", iteration, diff_loss.item())\n",
    "                self.log(\"training/encoder_grad_norm\", iteration, enc_grad_norm)\n",
    "                self.log(\"training/decoder_grad_norm\", iteration, dec_grad_norm)\n",
    "\n",
    "                dur_losses.append(dur_loss.item())\n",
    "                prior_losses.append(prior_loss.item())\n",
    "                diff_losses.append(diff_loss.item())\n",
    "\n",
    "                iteration += 1\n",
    "\n",
    "            log_msg = f\"Epoch {epoch}, iter: {iteration}: dur_loss: {np.mean(dur_losses):.4f} | prior_loss: {np.mean(prior_losses):.4f} | diff_loss: {np.mean(diff_losses):.4f} | time: {time.time()-last_time:.2f}s\"\n",
    "            last_time = time.time()\n",
    "            with open(f\"{self.hparams.log_dir}/train.log\", \"a\") as f:\n",
    "                f.write(log_msg + \"\\n\")\n",
    "                print(log_msg)\n",
    "\n",
    "            if epoch % self.log_interval == 0:\n",
    "                model.eval()\n",
    "                with torch.no_grad():\n",
    "                    for i, item in enumerate(test_batch):\n",
    "                        x, _y, _speaker_id = item\n",
    "                        x = x.to(torch.long).unsqueeze(0)\n",
    "                        x_lengths = torch.LongTensor([x.shape[-1]])\n",
    "                        y_enc, y_dec, attn = model(x, x_lengths, n_timesteps=50)\n",
    "                        self.log(\n",
    "                            f\"image_{i}/generated_enc\",\n",
    "                            iteration,\n",
    "                            image=plot_tensor(y_enc.squeeze().cpu()),\n",
    "                        )\n",
    "                        self.log(\n",
    "                            f\"image_{i}/generated_dec\",\n",
    "                            iteration,\n",
    "                            image=plot_tensor(y_dec.squeeze().cpu()),\n",
    "                        )\n",
    "                        self.log(\n",
    "                            f\"image_{i}/alignment\",\n",
    "                            iteration,\n",
    "                            image=plot_tensor(attn.squeeze().cpu()),\n",
    "                        )\n",
    "                        self.log(\n",
    "                            f\"audio/inference_{i}\",\n",
    "                            iteration,\n",
    "                            audio=self.sample_inference(model),\n",
    "                        )\n",
    "\n",
    "            if epoch % self.save_every == 0:\n",
    "                torch.save(\n",
    "                    model.state_dict(), f=f\"{self.hparams.log_dir}/{self.checkpoint_name}_{epoch}.pt\"\n",
    "                )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fb6e9a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TTSTrainer start 1311.942060225\n",
      "Initializing trainer with hparams:\n",
      "{'batch_size': 1,\n",
      " 'beta_max': 20.0,\n",
      " 'beta_min': 0.05,\n",
      " 'checkpoint': None,\n",
      " 'cudnn_enabled': True,\n",
      " 'dec_dim': 64,\n",
      " 'distributed_run': False,\n",
      " 'enc_dropout': 0.1,\n",
      " 'enc_kernel': 3,\n",
      " 'filter_channels': 768,\n",
      " 'filter_channels_dp': 256,\n",
      " 'filter_length': 1024,\n",
      " 'hop_length': 256,\n",
      " 'intersperse_text': True,\n",
      " 'learning_rate': 0.0001,\n",
      " 'log_dir': 'output',\n",
      " 'log_interval': 100,\n",
      " 'max_wav_value': 32768.0,\n",
      " 'mel_fmax': 8000,\n",
      " 'mel_fmin': 0.0,\n",
      " 'n_enc_channels': 192,\n",
      " 'n_enc_layers': 6,\n",
      " 'n_epochs': 10000,\n",
      " 'n_feats': 80,\n",
      " 'n_heads': 2,\n",
      " 'n_spks': 1,\n",
      " 'out_size': 172,\n",
      " 'oversample_weights': None,\n",
      " 'pe_scale': 1000,\n",
      " 'rank': 0,\n",
      " 'sampling_rate': 22050,\n",
      " 'save_every': 1000,\n",
      " 'seed': 37,\n",
      " 'spk_emb_dim': 64,\n",
      " 'symbol_set': 'gradtts',\n",
      " 'test_audiopaths_and_text': 'val.txt',\n",
      " 'test_size': 2,\n",
      " 'text_cleaners': ['english_cleaners'],\n",
      " 'training_audiopaths_and_text': 'train.txt',\n",
      " 'win_length': 1024,\n",
      " 'window_size': 4}\n"
     ]
    }
   ],
   "source": [
    "DEFAULTS = HParams(\n",
    "    training_audiopaths_and_text=\"train.txt\",\n",
    "    test_audiopaths_and_text=\"val.txt\",\n",
    "    cudnn_enabled=True,\n",
    "    log_dir=\"output\",\n",
    "    symbol_set=\"gradtts\",\n",
    "    intersperse_text=True,\n",
    "    n_spks=1,\n",
    "    spk_emb_dim=64,\n",
    "    sampling_rate=22050,\n",
    "    hop_length=256,\n",
    "    win_length=1024,\n",
    "    n_enc_channels=192,\n",
    "    filter_channels=768,\n",
    "    filter_channels_dp=256,\n",
    "    n_enc_layers=6,\n",
    "    enc_kernel=3,\n",
    "    enc_dropout=0.1,\n",
    "    n_heads=2,\n",
    "    window_size=4,\n",
    "    dec_dim=64,\n",
    "    beta_min=0.05,\n",
    "    beta_max=20.0,\n",
    "    pe_scale=1000,\n",
    "    test_size=2,\n",
    "    n_epochs=10000,\n",
    "    batch_size=1,\n",
    "    learning_rate=1e-4,\n",
    "    seed=37,\n",
    "    out_size=2 * 22050 // 256,\n",
    "    filter_length=1024,\n",
    "    rank=0,\n",
    "    distributed_run=False,\n",
    "    oversample_weights=None,\n",
    "    text_cleaners=[\"english_cleaners\"],\n",
    "    max_wav_value=32768.0,\n",
    "    n_feats=80,\n",
    "    mel_fmax=8000,\n",
    "    mel_fmin=0.0,\n",
    "    checkpoint=None,\n",
    "    log_interval=100,\n",
    "    save_every=1000,\n",
    ")\n",
    "trainer = GradTTSTrainer(DEFAULTS, rank=0)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
