{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "764ef14d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# default_exp models.base"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bcc6d03",
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "import torch\n",
    "from torch import nn\n",
    "from uberduck_ml_dev.text.symbols import SYMBOL_SETS\n",
    "\n",
    "\n",
    "class TTSModel(nn.Module):\n",
    "    def __init__(self, hparams):\n",
    "\n",
    "        super().__init__()\n",
    "        self.symbol_set = hparams.symbol_set\n",
    "        self.n_symbols = len(SYMBOL_SETS[self.symbol_set])\n",
    "        self.n_speakers = hparams.n_speakers\n",
    "        # symbols = __import__('uberduck_ml_dev.text.' + hparams.symbols)\n",
    "\n",
    "    def infer(self):\n",
    "        raise NotImplemented\n",
    "\n",
    "    def forward(self):\n",
    "        raise NotImplemented\n",
    "\n",
    "    def from_pretrained(\n",
    "        self, warm_start_path=None, device=\"cpu\", ignore_layers=None, model_dict=None\n",
    "    ):\n",
    "\n",
    "        model_dict = model_dict or dict()\n",
    "        if warm_start_path is None and model_dict is None:\n",
    "            raise Exception(\n",
    "                \"TTSModel.from_pretrained requires a warm_start_path or state_dict\"\n",
    "            )\n",
    "        if warm_start_path is not None:\n",
    "            checkpoint = torch.load(warm_start_path, map_location=device)\n",
    "            if (\n",
    "                \"state_dict\" in checkpoint.keys()\n",
    "            ):  # TODO: remove state_dict once off nvidia\n",
    "                model_dict = checkpoint[\"state_dict\"]\n",
    "            if \"model\" in checkpoint.keys():\n",
    "                model_dict = checkpoint[\"model\"]\n",
    "        if ignore_layers:\n",
    "            model_dict = {k: v for k, v in model_dict.items() if k not in ignore_layers}\n",
    "        dummy_dict = self.state_dict()\n",
    "\n",
    "        for k in self.state_dict().keys():\n",
    "            if k not in model_dict.keys():\n",
    "                print(\n",
    "                    f\"WARNING! Attempting to load a model with out the {k} layer. This could lead to unexpected results during evaluation.\"\n",
    "                )\n",
    "\n",
    "        dummy_dict.update(model_dict)\n",
    "        model_dict = dummy_dict\n",
    "        self.load_state_dict(model_dict)\n",
    "        if device == \"cuda\":\n",
    "            self.cuda()\n",
    "\n",
    "    def to_checkpoint(self):\n",
    "        return dict(model=self.state_dict())\n",
    "\n",
    "    @classmethod\n",
    "    def create(cls, name, opts, folders, all_speakers=True):\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10c8c772",
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "from uberduck_ml_dev.vendor.tfcompat.hparam import HParams\n",
    "\n",
    "DEFAULTS = HParams(\n",
    "    p_arpabet=1.0,\n",
    "    seed=1234,\n",
    "    cudnn_enabled=True,\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
