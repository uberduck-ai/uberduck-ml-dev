{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d096a2c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# default_exp exec.train_tacotron2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c96fa8f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "from uberduck_ml_dev.trainer.tacotron2 import Tacotron2Trainer\n",
    "from uberduck_ml_dev.vendor.tfcompat.hparam import HParams\n",
    "from uberduck_ml_dev.models.tacotron2 import DEFAULTS as TACOTRON2_DEFAULTS\n",
    "import argparse\n",
    "import sys\n",
    "import json\n",
    "import torch\n",
    "from torch import multiprocessing as mp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de7bf154",
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "def parse_args(args):\n",
    "    parser = argparse.ArgumentParser()\n",
    "    parser.add_argument(\"--config\", help=\"Path to JSON config\")\n",
    "    args = parser.parse_args(args)\n",
    "    return args\n",
    "\n",
    "\n",
    "def run(rank, device_count, hparams):\n",
    "    trainer = Tacotron2Trainer(hparams, rank=rank, world_size=device_count)\n",
    "    try:\n",
    "        trainer.train()\n",
    "    except Exception as e:\n",
    "        print(f\"Exception raised while training: {e}\")\n",
    "        # TODO: save state.\n",
    "        raise e"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "227b9e39",
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "try:\n",
    "    from nbdev.imports import IN_NOTEBOOK\n",
    "except:\n",
    "    IN_NOTEBOOK = False\n",
    "if __name__ == \"__main__\" and not IN_NOTEBOOK:\n",
    "    args = parse_args(sys.argv[1:])\n",
    "    config = TACOTRON2_DEFAULTS.values()\n",
    "    if args.config:\n",
    "        with open(args.config) as f:\n",
    "            config.update(json.load(f))\n",
    "    config.update(vars(args))\n",
    "    hparams = HParams(**config)\n",
    "    if hparams.distributed_run:\n",
    "        device_count = torch.cuda.device_count()\n",
    "        mp.spawn(run, (device_count, hparams), device_count)\n",
    "    else:\n",
    "        run(None, None, hparams)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58d43232",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('attention_dim', 128), ('attention_location_kernel_size', 31), ('attention_location_n_filters', 32), ('attention_rnn_dim', 1024), ('batch_size', 16), ('checkpoint_name', None), ('checkpoint_path', 'test/fixtures/results/checkpoints'), ('coarse_n_frames_per_step', None), ('cudnn_enabled', True), ('dataset_path', './dataset'), ('debug', False), ('decay_rate', 8000), ('decay_start', 15000), ('decoder_rnn_dim', 1024), ('distributed_run', False), ('encoder_embedding_dim', 512), ('encoder_kernel_size', 5), ('encoder_n_convolutions', 3), ('epochs', 5), ('epochs_per_checkpoint', 4), ('filter_length', 1024), ('fp16_run', False), ('gate_threshold', 0.5), ('grad_clip_thresh', 1.0), ('hop_length', 256), ('ignore_layers', ['speaker_embedding.weight']), ('include_f0', False), ('learning_rate', 0.001), ('log_dir', 'test/fixtures/results/logs'), ('mask_padding', True), ('max_decoder_steps', 1000), ('max_wav_value', 32768.0), ('mel_fmax', 8000), ('mel_fmin', 0), ('n_frames_per_step_initial', 1), ('n_mel_channels', 80), ('n_speakers', 1), ('n_symbols', 148), ('num_heads', 8), ('p_arpabet', 1.0), ('p_attention_dropout', 0.1), ('p_decoder_dropout', 0.1), ('p_teacher_forcing', 1.0), ('pos_weight', None), ('postnet_embedding_dim', 512), ('postnet_kernel_size', 5), ('postnet_n_convolutions', 5), ('prenet_dim', 256), ('prenet_f0_dim', 1), ('prenet_f0_kernel_size', 1), ('prenet_f0_n_layers', 1), ('prenet_fms_kernel_size', 1), ('prenet_rms_dim', 0), ('reduction_window_schedule', [{'until_step': 10000, 'batch_size': 16, 'n_frames_per_step': 1}, {'until_step': 50000, 'batch_size': 16, 'n_frames_per_step': 1}, {'until_step': 60000, 'batch_size': 16, 'n_frames_per_step': 1}, {'until_step': 70000, 'batch_size': 16, 'n_frames_per_step': 1}, {'until_step': None, 'batch_size': 16, 'n_frames_per_step': 1}]), ('ref_enc_filters', [32, 32, 64, 64, 128, 128]), ('ref_enc_gru_size', 128), ('ref_enc_pad', [1, 1]), ('ref_enc_size', [3, 3]), ('ref_enc_strides', [2, 2]), ('sample_inference_speaker_ids', [0]), ('sampling_rate', 22050), ('seed', 1234), ('speaker_embedding_dim', 128), ('steps_per_sample', 100), ('symbol_set', 'nvidia_taco2'), ('symbols_embedding_dim', 512), ('text_cleaners', ['english_cleaners']), ('training_audiopaths_and_text', 'test/fixtures/lj64/list64.txt'), ('val_audiopaths_and_text', 'test/fixtures/lj64/list64.txt'), ('warm_start_name', 'test/fixtures/models/taco2ljdefault'), ('weight_decay', 1e-06), ('win_length', 1024), ('with_gst', True)]\n",
      "TTSTrainer start 512268.648787189\n",
      "Initializing trainer with hparams:\n",
      "{'attention_dim': 128,\n",
      " 'attention_location_kernel_size': 31,\n",
      " 'attention_location_n_filters': 32,\n",
      " 'attention_rnn_dim': 1024,\n",
      " 'batch_size': 16,\n",
      " 'checkpoint_name': None,\n",
      " 'checkpoint_path': 'test/fixtures/results/checkpoints',\n",
      " 'coarse_n_frames_per_step': None,\n",
      " 'cudnn_enabled': True,\n",
      " 'dataset_path': './dataset',\n",
      " 'debug': False,\n",
      " 'decay_rate': 8000,\n",
      " 'decay_start': 15000,\n",
      " 'decoder_rnn_dim': 1024,\n",
      " 'distributed_run': False,\n",
      " 'encoder_embedding_dim': 512,\n",
      " 'encoder_kernel_size': 5,\n",
      " 'encoder_n_convolutions': 3,\n",
      " 'epochs': 5,\n",
      " 'epochs_per_checkpoint': 4,\n",
      " 'filter_length': 1024,\n",
      " 'fp16_run': False,\n",
      " 'gate_threshold': 0.5,\n",
      " 'grad_clip_thresh': 1.0,\n",
      " 'hop_length': 256,\n",
      " 'ignore_layers': ['speaker_embedding.weight'],\n",
      " 'include_f0': False,\n",
      " 'learning_rate': 0.001,\n",
      " 'log_dir': 'test/fixtures/results/logs',\n",
      " 'mask_padding': True,\n",
      " 'max_decoder_steps': 1000,\n",
      " 'max_wav_value': 32768.0,\n",
      " 'mel_fmax': 8000,\n",
      " 'mel_fmin': 0,\n",
      " 'n_frames_per_step_initial': 1,\n",
      " 'n_mel_channels': 80,\n",
      " 'n_speakers': 1,\n",
      " 'n_symbols': 148,\n",
      " 'num_heads': 8,\n",
      " 'p_arpabet': 1.0,\n",
      " 'p_attention_dropout': 0.1,\n",
      " 'p_decoder_dropout': 0.1,\n",
      " 'p_teacher_forcing': 1.0,\n",
      " 'pos_weight': None,\n",
      " 'postnet_embedding_dim': 512,\n",
      " 'postnet_kernel_size': 5,\n",
      " 'postnet_n_convolutions': 5,\n",
      " 'prenet_dim': 256,\n",
      " 'prenet_f0_dim': 1,\n",
      " 'prenet_f0_kernel_size': 1,\n",
      " 'prenet_f0_n_layers': 1,\n",
      " 'prenet_fms_kernel_size': 1,\n",
      " 'prenet_rms_dim': 0,\n",
      " 'reduction_window_schedule': [{'batch_size': 16,\n",
      "                                'n_frames_per_step': 1,\n",
      "                                'until_step': 10000},\n",
      "                               {'batch_size': 16,\n",
      "                                'n_frames_per_step': 1,\n",
      "                                'until_step': 50000},\n",
      "                               {'batch_size': 16,\n",
      "                                'n_frames_per_step': 1,\n",
      "                                'until_step': 60000},\n",
      "                               {'batch_size': 16,\n",
      "                                'n_frames_per_step': 1,\n",
      "                                'until_step': 70000},\n",
      "                               {'batch_size': 16,\n",
      "                                'n_frames_per_step': 1,\n",
      "                                'until_step': None}],\n",
      " 'ref_enc_filters': [32, 32, 64, 64, 128, 128],\n",
      " 'ref_enc_gru_size': 128,\n",
      " 'ref_enc_pad': [1, 1],\n",
      " 'ref_enc_size': [3, 3],\n",
      " 'ref_enc_strides': [2, 2],\n",
      " 'sample_inference_speaker_ids': [0],\n",
      " 'sampling_rate': 22050,\n",
      " 'seed': 1234,\n",
      " 'speaker_embedding_dim': 128,\n",
      " 'steps_per_sample': 100,\n",
      " 'symbol_set': 'nvidia_taco2',\n",
      " 'symbols_embedding_dim': 512,\n",
      " 'text_cleaners': ['english_cleaners'],\n",
      " 'training_audiopaths_and_text': 'test/fixtures/lj64/list64.txt',\n",
      " 'val_audiopaths_and_text': 'test/fixtures/lj64/list64.txt',\n",
      " 'warm_start_name': 'test/fixtures/models/taco2ljdefault',\n",
      " 'weight_decay': 1e-06,\n",
      " 'win_length': 1024,\n",
      " 'with_gst': True}\n",
      "start train 512269.972168209\n",
      "Starting warm_start 512274.328529834\n",
      "Ending warm_start 512274.411756431\n",
      "here\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/torch/nn/_reduction.py:42: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.\n",
      "  warnings.warn(warning.format(ret))\n",
      "/mnt/disks/uberduck-experiments-v0/uberduck-ml-dev/uberduck_ml_dev/trainer/tacotron2.py:444: UserWarning: torch.nn.utils.clip_grad_norm is now deprecated in favor of torch.nn.utils.clip_grad_norm_.\n",
      "  model.parameters(), self.grad_clip_thresh\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 1.4807120403274894\n",
      "logging_time: 0.0081\n",
      "here\n",
      "Loss: 16.083421297371387\n",
      "logging_time: 0.0084\n",
      "here\n",
      "Loss: 3.4663464445620775\n",
      "logging_time: 0.0083\n",
      "here\n",
      "Loss: 5.109222259372473\n",
      "logging_time: 0.0079\n",
      "start validate 512291.396348757\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "Average loss: 2.684908957220614\n",
      "warning: audio amplitude out of range, auto clipped.\n",
      "here\n",
      "Loss: 2.713851787149906\n",
      "logging_time: 0.0081\n",
      "here\n",
      "Loss: 1.562770925462246\n",
      "logging_time: 0.0083\n",
      "here\n",
      "Loss: 1.7748498525470495\n",
      "logging_time: 0.0078\n",
      "here\n",
      "Loss: 1.348441630601883\n",
      "logging_time: 0.0083\n",
      "start validate 512312.866006687\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "Average loss: 1.4870205072220415\n",
      "warning: audio amplitude out of range, auto clipped.\n",
      "here\n",
      "Loss: 1.5133823892101645\n",
      "logging_time: 0.0084\n",
      "here\n",
      "Loss: 1.4889013804495335\n",
      "logging_time: 0.0061\n",
      "here\n",
      "Loss: 1.025931190699339\n",
      "logging_time: 0.0082\n",
      "here\n",
      "Loss: 1.0355854467488825\n",
      "logging_time: 0.0085\n",
      "start validate 512333.495222449\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "Average loss: 1.0223602829501033\n",
      "warning: audio amplitude out of range, auto clipped.\n",
      "here\n",
      "Loss: 0.9582625976763666\n",
      "logging_time: 0.0085\n",
      "here\n",
      "Loss: 0.9869085298851132\n",
      "logging_time: 0.0082\n",
      "here\n",
      "Loss: 0.9209097870625556\n",
      "logging_time: 0.0081\n",
      "here\n",
      "Loss: 0.8260331004858017\n",
      "logging_time: 0.0081\n",
      "start validate 512354.551773858\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "Average loss: 0.8069833561312407\n",
      "warning: audio amplitude out of range, auto clipped.\n",
      "here\n",
      "Loss: 0.8120124554261565\n",
      "logging_time: 0.0081\n",
      "here\n",
      "Loss: 0.7905436782166362\n",
      "logging_time: 0.0081\n",
      "here\n",
      "Loss: 0.8394031524658203\n",
      "logging_time: 0.0077\n",
      "here\n",
      "Loss: 0.7594441412948072\n",
      "logging_time: 0.0083\n",
      "start validate 512378.761158751\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "Average loss: 0.7570176521549001\n",
      "warning: audio amplitude out of range, auto clipped.\n"
     ]
    }
   ],
   "source": [
    "# skip\n",
    "config = TACOTRON2_DEFAULTS.values()\n",
    "with open(\"test/fixtures/ljtest/taco2_lj2lj.json\") as f:\n",
    "    config.update(json.load(f))\n",
    "hparams = HParams(**config)\n",
    "print(hparams)\n",
    "if hparams.distributed_run:\n",
    "    device_count = torch.cuda.device_count()\n",
    "    mp.spawn(run, (device_count, hparams), device_count)\n",
    "else:\n",
    "    run(None, None, hparams)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0b80d84",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
