{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ae7c0345",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pandas as pd\n",
    "# import ray\n",
    "# from ray.data.datasource import FastFileMetadataProvider"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b623f749",
   "metadata": {},
   "outputs": [],
   "source": [
    "# lj_df = pd.read_csv(\n",
    "#     \"https://uberduck-datasets-dirty.s3.us-west-2.amazonaws.com/lj_for_upload/metadata_formatted_100.txt\",\n",
    "#     sep=\"|\",\n",
    "#     header=None,\n",
    "#     quoting=3,\n",
    "#     names=[\"path\", \"transcript\", \"speaker_id\"], # pitch path is implicit - this should be changed\n",
    "# )\n",
    "\n",
    "# paths = lj_df.path.tolist()\n",
    "# transcripts = lj_df.transcript.tolist()\n",
    "# speaker_ids = lj_df.speaker_id.tolist()\n",
    "\n",
    "# parallelism_length = 400\n",
    "# audio_ds = ray.data.read_binary_files(\n",
    "#     paths,\n",
    "#     parallelism=parallelism_length,\n",
    "#     meta_provider=FastFileMetadataProvider(),\n",
    "#     ray_remote_args={\"num_cpus\": 0.2},\n",
    "# )\n",
    "# audio_ds = audio_ds.map_batches(\n",
    "#     lambda x: x, batch_format=\"pyarrow\", batch_size=None\n",
    "# )\n",
    "\n",
    "# paths = ray.data.from_items(paths, parallelism=parallelism_length)\n",
    "# paths_ds = paths.map_batches(lambda x: x, batch_format=\"pyarrow\", batch_size=None)\n",
    "\n",
    "# transcripts = ray.data.from_items(transcripts, parallelism=parallelism_length)\n",
    "# transcripts_ds = transcripts.map_batches(lambda x: x, batch_format=\"pyarrow\", batch_size=None)\n",
    "\n",
    "# speaker_ids_ds = ray.data.from_items(speaker_ids, parallelism=parallelism_length)\n",
    "# speaker_ids_ds = speaker_ids_ds.map_batches(\n",
    "#     lambda x: x, batch_format=\"pyarrow\", batch_size=None\n",
    "# )\n",
    "# output_dataset = (\n",
    "#     transcripts_ds.zip(audio_ds)\n",
    "#     .zip(paths_ds)\n",
    "#     .zip(speaker_ids_ds)\n",
    "# )\n",
    "# output_dataset = output_dataset.map_batches(\n",
    "#     lambda table: table.rename(\n",
    "#         columns={\n",
    "#             \"value_1\": \"transcript\",\n",
    "#             \"value_2\": \"audio_bytes\",\n",
    "#             \"value_3\": \"path\",\n",
    "#             \"value_4\": \"speaker_id\"\n",
    "#         }\n",
    "#     )\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e20c063a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from uberduck_ml_dev.exec.train_radtts_with_ray import get_ray_dataset, train_func\n",
    "from ray.train.torch import TorchTrainer, TorchCheckpoint, TorchTrainer\n",
    "class TorchCheckpointFixed(TorchCheckpoint):\n",
    "    def __setstate__(self, state: dict):\n",
    "        if \"_data_dict\" in state and state[\"_data_dict\"]:\n",
    "            state = state.copy()\n",
    "            state[\"_data_dict\"] = self._decode_data_dict(state[\"_data_dict\"])\n",
    "        super(TorchCheckpoint, self).__setstate__(state)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fbdb4948",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-03-06 17:01:02,368\tINFO worker.py:1360 -- Connecting to existing Ray cluster at address: 10.0.37.211:6379...\n",
      "2023-03-06 17:01:02,376\tINFO worker.py:1548 -- Connected to Ray cluster. View the dashboard at \u001b[1m\u001b[32mhttps://console.anyscale.com/api/v2/sessions/ses_ha6my3r3kl4mn9jdylcqnfutq1/services?redirect_to=dashboard \u001b[39m\u001b[22m\n",
      "2023-03-06 17:01:02,400\tINFO packaging.py:330 -- Pushing file package 'gcs://_ray_pkg_ad1843ca6e36835e76ab0ad145e0012f.zip' (7.10MiB) to Ray cluster...\n",
      "2023-03-06 17:01:02,518\tINFO packaging.py:343 -- Successfully pushed file package 'gcs://_ray_pkg_ad1843ca6e36835e76ab0ad145e0012f.zip'.\n",
      "(_get_read_tasks pid=321, ip=10.0.42.179) 2023-03-06 17:01:04,405\tWARNING file_meta_provider.py:162 -- Expanding 100 path(s). This may be a HIGH LATENCY operation on some cloud storage services. If the specified paths all point to files and never directories, try rerunning this read with `meta_provider=FastFileMetadataProvider()`.\n"
     ]
    }
   ],
   "source": [
    "ray_dataset = get_ray_dataset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "11752029",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(autoscaler +8m59s) Removing 1 nodes of type worker-node-type-1 (idle).\n"
     ]
    }
   ],
   "source": [
    "datum = ray_dataset.take(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a014ad72",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(autoscaler +9m23s) Removing 3 nodes of type worker-node-type-1 (idle).\n",
      "(autoscaler +9m28s) Removing 3 nodes of type worker-node-type-1 (idle).\n",
      "(autoscaler +9m34s) Removing 3 nodes of type worker-node-type-1 (idle).\n",
      "(autoscaler +9m39s) Removing 3 nodes of type worker-node-type-1 (idle).\n",
      "(autoscaler +9m44s) Removing 3 nodes of type worker-node-type-1 (idle).\n",
      "(autoscaler +9m49s) Removing 3 nodes of type worker-node-type-1 (idle).\n",
      "(autoscaler +9m54s) Removing 3 nodes of type worker-node-type-1 (idle).\n",
      "(autoscaler +9m59s) Removing 3 nodes of type worker-node-type-1 (idle).\n",
      "(autoscaler +10m4s) Removing 3 nodes of type worker-node-type-1 (idle).\n",
      "(autoscaler +10m9s) Removing 3 nodes of type worker-node-type-1 (idle).\n",
      "(autoscaler +10m14s) Removing 2 nodes of type worker-node-type-1 (idle).\n",
      "(autoscaler +10m19s) Resized to 156 CPUs, 3 GPUs.\n",
      "(autoscaler +10m19s) Removing 2 nodes of type worker-node-type-1 (idle).\n",
      "(autoscaler +10m24s) Removing 2 nodes of type worker-node-type-1 (idle).\n",
      "(autoscaler +10m29s) Removing 2 nodes of type worker-node-type-1 (idle).\n",
      "(autoscaler +10m34s) Removing 2 nodes of type worker-node-type-1 (idle).\n",
      "(autoscaler +10m39s) Removing 2 nodes of type worker-node-type-1 (idle).\n",
      "(autoscaler +10m49s) Resized to 148 CPUs, 1 GPUs.\n"
     ]
    }
   ],
   "source": [
    "# datum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f4133484",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ray.air.config import ScalingConfig, RunConfig\n",
    "from ray.tune import SyncConfig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e466b247",
   "metadata": {},
   "outputs": [],
   "source": [
    "from uberduck_ml_dev.exec.train_radtts_with_ray import train_config, model_config\n",
    "train_config['n_group_size'] = model_config['n_group_size']\n",
    "train_config['dur_model_config'] = model_config['dur_model_config']\n",
    "train_config['f0_model_config'] = model_config['f0_model_config']\n",
    "train_config['energy_model_config'] = model_config['energy_model_config']\n",
    "train_config['v_model_config']=model_config['v_model_config']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ed5038d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = TorchTrainer(\n",
    "    train_loop_per_worker=train_func,\n",
    "    train_loop_config=train_config,\n",
    "    scaling_config=ScalingConfig(\n",
    "        num_workers=2, use_gpu=True, resources_per_worker=dict(CPU=4, GPU=1)\n",
    "    ),\n",
    "    run_config=RunConfig(\n",
    "        sync_config=SyncConfig(upload_dir=\"s3://uberduck-anyscale-data/checkpoints\")\n",
    "    ),\n",
    "    datasets={\"train\": ray_dataset},\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ce591e8a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div class=\"tuneStatus\">\n",
       "  <div style=\"display: flex;flex-direction: row\">\n",
       "    <div style=\"display: flex;flex-direction: column;\">\n",
       "      <h3>Tune Status</h3>\n",
       "      <table>\n",
       "<tbody>\n",
       "<tr><td>Current time:</td><td>2023-03-06 17:04:35</td></tr>\n",
       "<tr><td>Running for: </td><td>00:02:12.82        </td></tr>\n",
       "<tr><td>Memory:      </td><td>4.3/15.3 GiB       </td></tr>\n",
       "</tbody>\n",
       "</table>\n",
       "    </div>\n",
       "    <div class=\"vDivider\"></div>\n",
       "    <div class=\"systemInfo\">\n",
       "      <h3>System Info</h3>\n",
       "      Using FIFO scheduling algorithm.<br>Resources requested: 0/88 CPUs, 0/2 GPUs, 0.0/231.81 GiB heap, 0.0/99.94 GiB objects (0.0/2.0 accelerator_type:T4)\n",
       "    </div>\n",
       "    <div class=\"vDivider\"></div>\n",
       "<div class=\"messages\">\n",
       "  <h3>Messages</h3>\n",
       "  \n",
       "  \n",
       "  Number of errored trials: 1<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name              </th><th style=\"text-align: right;\">  # failures</th><th>error file                                                                                                     </th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>TorchTrainer_b7d1e_00000</td><td style=\"text-align: right;\">           1</td><td>/home/ray/ray_results/TorchTrainer_2023-03-06_17-02-22/TorchTrainer_b7d1e_00000_0_2023-03-06_17-03-45/error.txt</td></tr>\n",
       "</tbody>\n",
       "</table>\n",
       "</div>\n",
       "<style>\n",
       ".messages {\n",
       "  color: var(--jp-ui-font-color1);\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "  padding-left: 1em;\n",
       "  overflow-y: auto;\n",
       "}\n",
       ".messages h3 {\n",
       "  font-weight: bold;\n",
       "}\n",
       ".vDivider {\n",
       "  border-left-width: var(--jp-border-width);\n",
       "  border-left-color: var(--jp-border-color0);\n",
       "  border-left-style: solid;\n",
       "  margin: 0.5em 1em 0.5em 1em;\n",
       "}\n",
       "</style>\n",
       "\n",
       "  </div>\n",
       "  <div class=\"hDivider\"></div>\n",
       "  <div class=\"trialStatus\">\n",
       "    <h3>Trial Status</h3>\n",
       "    <table>\n",
       "<thead>\n",
       "<tr><th>Trial name              </th><th>status  </th><th>loc            </th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>TorchTrainer_b7d1e_00000</td><td>ERROR   </td><td>10.0.9.152:1713</td></tr>\n",
       "</tbody>\n",
       "</table>\n",
       "  </div>\n",
       "</div>\n",
       "<style>\n",
       ".tuneStatus {\n",
       "  color: var(--jp-ui-font-color1);\n",
       "}\n",
       ".tuneStatus .systemInfo {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       ".tuneStatus td {\n",
       "  white-space: nowrap;\n",
       "}\n",
       ".tuneStatus .trialStatus {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       ".tuneStatus h3 {\n",
       "  font-weight: bold;\n",
       "}\n",
       ".tuneStatus .hDivider {\n",
       "  border-bottom-width: var(--jp-border-width);\n",
       "  border-bottom-color: var(--jp-border-color0);\n",
       "  border-bottom-style: solid;\n",
       "}\n",
       ".tuneStatus .vDivider {\n",
       "  border-left-width: var(--jp-border-width);\n",
       "  border-left-color: var(--jp-border-color0);\n",
       "  border-left-style: solid;\n",
       "  margin: 0.5em 1em 0.5em 1em;\n",
       "}\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(autoscaler +1m31s) Tip: use `ray status` to view detailed cluster status. To disable these messages, set RAY_SCHEDULER_EVENTS=0.\n",
      "(autoscaler +1m31s) Adding 1 node(s) of type worker-node-type-1.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-03-06 17:03:33,074\tWARNING insufficient_resources_manager.py:128 -- Ignore this message if the cluster is autoscaling. You asked for 9.0 cpu and 2.0 gpu per trial, but the cluster only has 84.0 cpu and 1.0 gpu. Stop the tuning job and adjust the resources requested per trial (possibly via `resources_per_trial` or via `num_workers` for rllib) and/or add more resources to your Ray runtime.\n",
      "(raylet, ip=10.0.10.38) /home/ray/anaconda3/lib/python3.10/site-packages/ray/dashboard/agent.py:51: DeprecationWarning: There is no current event loop\n",
      "(raylet, ip=10.0.10.38)   aiogrpc.init_grpc_aio()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(autoscaler +2m47s) Resized to 152 CPUs, 2 GPUs.\n",
      "(autoscaler +2m52s) Adding 2 node(s) of type worker-node-type-1.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(TrainTrainable pid=1713, ip=10.0.9.152) [nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "(TrainTrainable pid=1713, ip=10.0.9.152) [nltk_data]     /home/ray/nltk_data...\n",
      "(TrainTrainable pid=1713, ip=10.0.9.152) [nltk_data]   Unzipping taggers/averaged_perceptron_tagger.zip.\n",
      "(RayTrainWorker pid=192, ip=10.0.10.38) 2023-03-06 17:03:59,920\tINFO config.py:86 -- Setting up process group for: env:// [rank=0, world_size=2]\n",
      "(TorchTrainer pid=1713, ip=10.0.9.152) 2023-03-06 17:04:00,554\tINFO bulk_executor.py:41 -- Executing DAG InputDataBuffer[Input] -> AllToAllOperator[randomize_block_order]\n",
      "(TorchTrainer pid=1713, ip=10.0.9.152) /home/ray/anaconda3/lib/python3.10/site-packages/ray/train/_internal/dataset_iterator.py:64: UserWarning: session.get_dataset_shard returns a ray.data.DatasetIterator instead of a Dataset/DatasetPipeline as of Ray v2.3. Use iter_torch_batches(), to_tf(), or iter_batches() to iterate over one epoch. See https://docs.ray.io/en/latest/data/api/dataset_iterator.html for full DatasetIterator docs.\n",
      "(TorchTrainer pid=1713, ip=10.0.9.152)   warnings.warn(\n",
      "(RayTrainWorker pid=192, ip=10.0.10.38) [nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "(RayTrainWorker pid=192, ip=10.0.10.38) [nltk_data]     /home/ray/nltk_data...\n",
      "(RayTrainWorker pid=192, ip=10.0.10.38) [nltk_data]   Unzipping taggers/averaged_perceptron_tagger.zip.\n",
      "(RayTrainWorker pid=308612) wandb: Currently logged in as: uberduck. Use `wandb login --relogin` to force relogin\n",
      "(RayTrainWorker pid=192, ip=10.0.10.38) wandb: Currently logged in as: uberduck. Use `wandb login --relogin` to force relogin\n",
      "(RayTrainWorker pid=192, ip=10.0.10.38) wandb: Tracking run with wandb version 0.13.10\n",
      "(RayTrainWorker pid=192, ip=10.0.10.38) wandb: Run data is saved locally in /home/ray/ray_results/TorchTrainer_2023-03-06_17-02-22/TorchTrainer_b7d1e_00000_0_2023-03-06_17-03-45/rank_0/wandb/run-20230306_170411-b7d1e_00000\n",
      "(RayTrainWorker pid=192, ip=10.0.10.38) wandb: Run `wandb offline` to turn off syncing.\n",
      "(RayTrainWorker pid=192, ip=10.0.10.38) wandb: Resuming run TorchTrainer_b7d1e_00000\n",
      "(RayTrainWorker pid=192, ip=10.0.10.38) wandb: ‚≠êÔ∏è View project at https://wandb.ai/uberduck/radtts-ray\n",
      "(RayTrainWorker pid=192, ip=10.0.10.38) wandb: üöÄ View run at https://wandb.ai/uberduck/radtts-ray/runs/b7d1e_00000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(RayTrainWorker pid=192, ip=10.0.10.38) CUDA AVAILABLE:  True\n",
      "(RayTrainWorker pid=192, ip=10.0.10.38) Applying spectral norm to text encoder LSTM\n",
      "(RayTrainWorker pid=192, ip=10.0.10.38) Applying spectral norm to context encoder LSTM\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(RayTrainWorker pid=192, ip=10.0.10.38) /tmp/ray/session_2023-03-06_08-59-42_925397_141/runtime_resources/working_dir_files/_ray_pkg_ad1843ca6e36835e76ab0ad145e0012f/uberduck_ml_dev/models/common.py:1506: UserWarning: torch.qr is deprecated in favor of torch.linalg.qr and will be removed in a future PyTorch release.\n",
      "(RayTrainWorker pid=192, ip=10.0.10.38) The boolean parameter 'some' has been replaced with a string parameter 'mode'.\n",
      "(RayTrainWorker pid=192, ip=10.0.10.38) Q, R = torch.qr(A, some)\n",
      "(RayTrainWorker pid=192, ip=10.0.10.38) should be replaced with\n",
      "(RayTrainWorker pid=192, ip=10.0.10.38) Q, R = torch.linalg.qr(A, 'reduced' if some else 'complete') (Triggered internally at ../aten/src/ATen/native/BatchLinearAlgebra.cpp:2349.)\n",
      "(RayTrainWorker pid=192, ip=10.0.10.38)   W = torch.qr(torch.FloatTensor(c, c).normal_())[0]\n",
      "(RayTrainWorker pid=192, ip=10.0.10.38) /home/ray/anaconda3/lib/python3.10/site-packages/torch/functional.py:1682: UserWarning: torch.lu is deprecated in favor of torch.linalg.lu_factor / torch.linalg.lu_factor_ex and will be removed in a future PyTorch release.\n",
      "(RayTrainWorker pid=192, ip=10.0.10.38) LU, pivots = torch.lu(A, compute_pivots)\n",
      "(RayTrainWorker pid=192, ip=10.0.10.38) should be replaced with\n",
      "(RayTrainWorker pid=192, ip=10.0.10.38) LU, pivots = torch.linalg.lu_factor(A, compute_pivots)\n",
      "(RayTrainWorker pid=192, ip=10.0.10.38) and\n",
      "(RayTrainWorker pid=192, ip=10.0.10.38) LU, pivots, info = torch.lu(A, compute_pivots, get_infos=True)\n",
      "(RayTrainWorker pid=192, ip=10.0.10.38) should be replaced with\n",
      "(RayTrainWorker pid=192, ip=10.0.10.38) LU, pivots, info = torch.linalg.lu_factor_ex(A, compute_pivots) (Triggered internally at ../aten/src/ATen/native/BatchLinearAlgebra.cpp:1915.)\n",
      "(RayTrainWorker pid=192, ip=10.0.10.38)   return torch._lu_with_info(A, pivot=pivot, check_errors=(not get_infos))\n",
      "(RayTrainWorker pid=192, ip=10.0.10.38) 2023-03-06 17:04:15,744\tINFO train_loop_utils.py:307 -- Moving model to device: cuda:0\n",
      "(RayTrainWorker pid=192, ip=10.0.10.38) 2023-03-06 17:04:18,533\tINFO train_loop_utils.py:367 -- Wrapping provided model in DistributedDataParallel.\n",
      "(RayTrainWorker pid=308612) wandb: Tracking run with wandb version 0.13.10\n",
      "(RayTrainWorker pid=308612) wandb: Run data is saved locally in /home/ray/ray_results/TorchTrainer_2023-03-06_17-02-22/TorchTrainer_b7d1e_00000_0_2023-03-06_17-03-45/rank_1/wandb/run-20230306_170411-b7d1e_00000\n",
      "(RayTrainWorker pid=308612) wandb: Run `wandb offline` to turn off syncing.\n",
      "(RayTrainWorker pid=308612) wandb: Syncing run TorchTrainer_b7d1e_00000\n",
      "(RayTrainWorker pid=308612) wandb: ‚≠êÔ∏è View project at https://wandb.ai/uberduck/radtts-ray\n",
      "(RayTrainWorker pid=308612) wandb: üöÄ View run at https://wandb.ai/uberduck/radtts-ray/runs/b7d1e_00000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(RayTrainWorker pid=308612) CUDA AVAILABLE:  True\n",
      "(RayTrainWorker pid=308612) Applying spectral norm to text encoder LSTM\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(RayTrainWorker pid=308612) /tmp/ray/session_2023-03-06_08-59-42_925397_141/runtime_resources/working_dir_files/_ray_pkg_ad1843ca6e36835e76ab0ad145e0012f/uberduck_ml_dev/models/common.py:1506: UserWarning: torch.qr is deprecated in favor of torch.linalg.qr and will be removed in a future PyTorch release.\n",
      "(RayTrainWorker pid=308612) The boolean parameter 'some' has been replaced with a string parameter 'mode'.\n",
      "(RayTrainWorker pid=308612) Q, R = torch.qr(A, some)\n",
      "(RayTrainWorker pid=308612) should be replaced with\n",
      "(RayTrainWorker pid=308612) Q, R = torch.linalg.qr(A, 'reduced' if some else 'complete') (Triggered internally at ../aten/src/ATen/native/BatchLinearAlgebra.cpp:2349.)\n",
      "(RayTrainWorker pid=308612)   W = torch.qr(torch.FloatTensor(c, c).normal_())[0]\n",
      "(RayTrainWorker pid=308612) /home/ray/anaconda3/lib/python3.10/site-packages/torch/functional.py:1682: UserWarning: torch.lu is deprecated in favor of torch.linalg.lu_factor / torch.linalg.lu_factor_ex and will be removed in a future PyTorch release.\n",
      "(RayTrainWorker pid=308612) LU, pivots = torch.lu(A, compute_pivots)\n",
      "(RayTrainWorker pid=308612) should be replaced with\n",
      "(RayTrainWorker pid=308612) LU, pivots = torch.linalg.lu_factor(A, compute_pivots)\n",
      "(RayTrainWorker pid=308612) and\n",
      "(RayTrainWorker pid=308612) LU, pivots, info = torch.lu(A, compute_pivots, get_infos=True)\n",
      "(RayTrainWorker pid=308612) should be replaced with\n",
      "(RayTrainWorker pid=308612) LU, pivots, info = torch.linalg.lu_factor_ex(A, compute_pivots) (Triggered internally at ../aten/src/ATen/native/BatchLinearAlgebra.cpp:1915.)\n",
      "(RayTrainWorker pid=308612)   return torch._lu_with_info(A, pivot=pivot, check_errors=(not get_infos))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(RayTrainWorker pid=308612) Applying spectral norm to context encoder LSTM\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(RayTrainWorker pid=308612) 2023-03-06 17:04:29,345\tINFO train_loop_utils.py:307 -- Moving model to device: cuda:0\n",
      "(RayTrainWorker pid=308612) 2023-03-06 17:04:31,262\tINFO train_loop_utils.py:367 -- Wrapping provided model in DistributedDataParallel.\n",
      "(RayTrainWorker pid=192, ip=10.0.10.38) /tmp/ray/session_2023-03-06_08-59-42_925397_141/runtime_resources/working_dir_files/_ray_pkg_ad1843ca6e36835e76ab0ad145e0012f/uberduck_ml_dev/exec/train_radtts_with_ray.py:395: UserWarning: The given NumPy array is not writable, and PyTorch does not support non-writable tensors. This means writing to this tensor will result in undefined behavior. You may want to copy the array to protect its data or make it writable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at ../torch/csrc/utils/tensor_numpy.cpp:199.)\n",
      "(RayTrainWorker pid=192, ip=10.0.10.38)   audio = torch.FloatTensor(wav_data)\n",
      "(RayTrainWorker pid=308612) /tmp/ray/session_2023-03-06_08-59-42_925397_141/runtime_resources/working_dir_files/_ray_pkg_ad1843ca6e36835e76ab0ad145e0012f/uberduck_ml_dev/exec/train_radtts_with_ray.py:395: UserWarning: The given NumPy array is not writable, and PyTorch does not support non-writable tensors. This means writing to this tensor will result in undefined behavior. You may want to copy the array to protect its data or make it writable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at ../torch/csrc/utils/tensor_numpy.cpp:199.)\n",
      "(RayTrainWorker pid=308612)   audio = torch.FloatTensor(wav_data)\n",
      "(RayTrainWorker pid=308612) /home/ray/anaconda3/lib/python3.10/site-packages/torch/functional.py:632: UserWarning: stft will soon require the return_complex parameter be given for real inputs, and will further require that return_complex=True in a future PyTorch release. (Triggered internally at ../aten/src/ATen/native/SpectralOps.cpp:801.)\n",
      "(RayTrainWorker pid=308612)   return _VF.stft(input, n_fft, hop_length, win_length, window,  # type: ignore[attr-defined]\n",
      "(RayTrainWorker pid=192, ip=10.0.10.38) /home/ray/anaconda3/lib/python3.10/site-packages/torch/functional.py:632: UserWarning: stft will soon require the return_complex parameter be given for real inputs, and will further require that return_complex=True in a future PyTorch release. (Triggered internally at ../aten/src/ATen/native/SpectralOps.cpp:801.)\n",
      "(RayTrainWorker pid=192, ip=10.0.10.38)   return _VF.stft(input, n_fft, hop_length, win_length, window,  # type: ignore[attr-defined]\n",
      "2023-03-06 17:04:32,864\tERROR trial_runner.py:705 -- Trial TorchTrainer_b7d1e_00000: Error happened when processing _ExecutorEventType.TRAINING_RESULT.\n",
      "ray.exceptions.RayTaskError(TypeError): \u001b[36mray::_Inner.train()\u001b[39m (pid=1713, ip=10.0.9.152, repr=TorchTrainer)\n",
      "  File \"/home/ray/anaconda3/lib/python3.10/site-packages/ray/tune/trainable/trainable.py\", line 360, in train\n",
      "    raise skipped from exception_cause(skipped)\n",
      "  File \"/home/ray/anaconda3/lib/python3.10/site-packages/ray/train/_internal/utils.py\", line 54, in check_for_failure\n",
      "    ray.get(object_ref)\n",
      "ray.exceptions.RayTaskError(TypeError): \u001b[36mray::RayTrainWorker._RayTrainWorker__execute()\u001b[39m (pid=192, ip=10.0.10.38, repr=<ray.train._internal.worker_group.RayTrainWorker object at 0x7ff4ae83eec0>)\n",
      "  File \"/home/ray/anaconda3/lib/python3.10/site-packages/ray/train/_internal/worker_group.py\", line 31, in __execute\n",
      "    raise skipped from exception_cause(skipped)\n",
      "  File \"/home/ray/anaconda3/lib/python3.10/site-packages/ray/train/_internal/utils.py\", line 129, in discard_return_wrapper\n",
      "    train_func(*args, **kwargs)\n",
      "  File \"/tmp/ray/session_2023-03-06_08-59-42_925397_141/runtime_resources/working_dir_files/_ray_pkg_ad1843ca6e36835e76ab0ad145e0012f/uberduck_ml_dev/exec/train_radtts_with_ray.py\", line 630, in train_func\n",
      "    _train_step(\n",
      "  File \"/tmp/ray/session_2023-03-06_08-59-42_925397_141/runtime_resources/working_dir_files/_ray_pkg_ad1843ca6e36835e76ab0ad145e0012f/uberduck_ml_dev/exec/train_radtts_with_ray.py\", line 513, in _train_step\n",
      "    to_gpu(el) for el in ray_df_to_batch_radtts(batch)\n",
      "  File \"/tmp/ray/session_2023-03-06_08-59-42_925397_141/runtime_resources/working_dir_files/_ray_pkg_ad1843ca6e36835e76ab0ad145e0012f/uberduck_ml_dev/exec/train_radtts_with_ray.py\", line 415, in ray_df_to_batch_radtts\n",
      "    return collate_fn(collate_input)\n",
      "  File \"/tmp/ray/session_2023-03-06_08-59-42_925397_141/runtime_resources/working_dir_files/_ray_pkg_ad1843ca6e36835e76ab0ad145e0012f/uberduck_ml_dev/exec/train_radtts_with_ray.py\", line 296, in __call__\n",
      "    torch.LongTensor([len(x['text_encoded']) for x in batch]),\n",
      "  File \"/tmp/ray/session_2023-03-06_08-59-42_925397_141/runtime_resources/working_dir_files/_ray_pkg_ad1843ca6e36835e76ab0ad145e0012f/uberduck_ml_dev/exec/train_radtts_with_ray.py\", line 296, in <listcomp>\n",
      "    torch.LongTensor([len(x['text_encoded']) for x in batch]),\n",
      "TypeError: tuple indices must be integers or slices, not str\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div class=\"trialProgress\">\n",
       "  <h3>Trial Progress</h3>\n",
       "  <table>\n",
       "<thead>\n",
       "<tr><th>Trial name              </th><th>date               </th><th>hostname     </th><th>node_ip   </th><th style=\"text-align: right;\">  pid</th><th style=\"text-align: right;\">  timestamp</th><th>trial_id   </th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>TorchTrainer_b7d1e_00000</td><td>2023-03-06_17-03-56</td><td>ip-10-0-9-152</td><td>10.0.9.152</td><td style=\"text-align: right;\"> 1713</td><td style=\"text-align: right;\"> 1678151036</td><td>b7d1e_00000</td></tr>\n",
       "</tbody>\n",
       "</table>\n",
       "</div>\n",
       "<style>\n",
       ".trialProgress {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "  color: var(--jp-ui-font-color1);\n",
       "}\n",
       ".trialProgress h3 {\n",
       "  font-weight: bold;\n",
       "}\n",
       ".trialProgress td {\n",
       "  white-space: nowrap;\n",
       "}\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-03-06 17:04:35,823\tERROR tune.py:821 -- Trials did not complete: [TorchTrainer_b7d1e_00000]\n",
      "2023-03-06 17:04:35,824\tINFO tune.py:825 -- Total run time: 132.97 seconds (129.87 seconds for the tuning loop).\n"
     ]
    },
    {
     "ename": "RayTaskError(TypeError)",
     "evalue": "\u001b[36mray::_Inner.train()\u001b[39m (pid=1713, ip=10.0.9.152, repr=TorchTrainer)\n  File \"/home/ray/anaconda3/lib/python3.10/site-packages/ray/tune/trainable/trainable.py\", line 360, in train\n    raise skipped from exception_cause(skipped)\n  File \"/home/ray/anaconda3/lib/python3.10/site-packages/ray/train/_internal/utils.py\", line 54, in check_for_failure\n    ray.get(object_ref)\nray.exceptions.RayTaskError(TypeError): \u001b[36mray::RayTrainWorker._RayTrainWorker__execute()\u001b[39m (pid=192, ip=10.0.10.38, repr=<ray.train._internal.worker_group.RayTrainWorker object at 0x7ff4ae83eec0>)\n  File \"/home/ray/anaconda3/lib/python3.10/site-packages/ray/train/_internal/worker_group.py\", line 31, in __execute\n    raise skipped from exception_cause(skipped)\n  File \"/home/ray/anaconda3/lib/python3.10/site-packages/ray/train/_internal/utils.py\", line 129, in discard_return_wrapper\n    train_func(*args, **kwargs)\n  File \"/tmp/ray/session_2023-03-06_08-59-42_925397_141/runtime_resources/working_dir_files/_ray_pkg_ad1843ca6e36835e76ab0ad145e0012f/uberduck_ml_dev/exec/train_radtts_with_ray.py\", line 630, in train_func\n    _train_step(\n  File \"/tmp/ray/session_2023-03-06_08-59-42_925397_141/runtime_resources/working_dir_files/_ray_pkg_ad1843ca6e36835e76ab0ad145e0012f/uberduck_ml_dev/exec/train_radtts_with_ray.py\", line 513, in _train_step\n    to_gpu(el) for el in ray_df_to_batch_radtts(batch)\n  File \"/tmp/ray/session_2023-03-06_08-59-42_925397_141/runtime_resources/working_dir_files/_ray_pkg_ad1843ca6e36835e76ab0ad145e0012f/uberduck_ml_dev/exec/train_radtts_with_ray.py\", line 415, in ray_df_to_batch_radtts\n    return collate_fn(collate_input)\n  File \"/tmp/ray/session_2023-03-06_08-59-42_925397_141/runtime_resources/working_dir_files/_ray_pkg_ad1843ca6e36835e76ab0ad145e0012f/uberduck_ml_dev/exec/train_radtts_with_ray.py\", line 296, in __call__\n    torch.LongTensor([len(x['text_encoded']) for x in batch]),\n  File \"/tmp/ray/session_2023-03-06_08-59-42_925397_141/runtime_resources/working_dir_files/_ray_pkg_ad1843ca6e36835e76ab0ad145e0012f/uberduck_ml_dev/exec/train_radtts_with_ray.py\", line 296, in <listcomp>\n    torch.LongTensor([len(x['text_encoded']) for x in batch]),\nTypeError: tuple indices must be integers or slices, not str",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRayTaskError(TypeError)\u001b[0m                   Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[7], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[43mtrainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.10/site-packages/ray/train/base_trainer.py:579\u001b[0m, in \u001b[0;36mBaseTrainer.fit\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    577\u001b[0m     result \u001b[38;5;241m=\u001b[39m result_grid[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m    578\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m result\u001b[38;5;241m.\u001b[39merror:\n\u001b[0;32m--> 579\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m result\u001b[38;5;241m.\u001b[39merror\n\u001b[1;32m    580\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m TuneError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    581\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m TrainingFailedError \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01me\u001b[39;00m\n",
      "\u001b[0;31mRayTaskError(TypeError)\u001b[0m: \u001b[36mray::_Inner.train()\u001b[39m (pid=1713, ip=10.0.9.152, repr=TorchTrainer)\n  File \"/home/ray/anaconda3/lib/python3.10/site-packages/ray/tune/trainable/trainable.py\", line 360, in train\n    raise skipped from exception_cause(skipped)\n  File \"/home/ray/anaconda3/lib/python3.10/site-packages/ray/train/_internal/utils.py\", line 54, in check_for_failure\n    ray.get(object_ref)\nray.exceptions.RayTaskError(TypeError): \u001b[36mray::RayTrainWorker._RayTrainWorker__execute()\u001b[39m (pid=192, ip=10.0.10.38, repr=<ray.train._internal.worker_group.RayTrainWorker object at 0x7ff4ae83eec0>)\n  File \"/home/ray/anaconda3/lib/python3.10/site-packages/ray/train/_internal/worker_group.py\", line 31, in __execute\n    raise skipped from exception_cause(skipped)\n  File \"/home/ray/anaconda3/lib/python3.10/site-packages/ray/train/_internal/utils.py\", line 129, in discard_return_wrapper\n    train_func(*args, **kwargs)\n  File \"/tmp/ray/session_2023-03-06_08-59-42_925397_141/runtime_resources/working_dir_files/_ray_pkg_ad1843ca6e36835e76ab0ad145e0012f/uberduck_ml_dev/exec/train_radtts_with_ray.py\", line 630, in train_func\n    _train_step(\n  File \"/tmp/ray/session_2023-03-06_08-59-42_925397_141/runtime_resources/working_dir_files/_ray_pkg_ad1843ca6e36835e76ab0ad145e0012f/uberduck_ml_dev/exec/train_radtts_with_ray.py\", line 513, in _train_step\n    to_gpu(el) for el in ray_df_to_batch_radtts(batch)\n  File \"/tmp/ray/session_2023-03-06_08-59-42_925397_141/runtime_resources/working_dir_files/_ray_pkg_ad1843ca6e36835e76ab0ad145e0012f/uberduck_ml_dev/exec/train_radtts_with_ray.py\", line 415, in ray_df_to_batch_radtts\n    return collate_fn(collate_input)\n  File \"/tmp/ray/session_2023-03-06_08-59-42_925397_141/runtime_resources/working_dir_files/_ray_pkg_ad1843ca6e36835e76ab0ad145e0012f/uberduck_ml_dev/exec/train_radtts_with_ray.py\", line 296, in __call__\n    torch.LongTensor([len(x['text_encoded']) for x in batch]),\n  File \"/tmp/ray/session_2023-03-06_08-59-42_925397_141/runtime_resources/working_dir_files/_ray_pkg_ad1843ca6e36835e76ab0ad145e0012f/uberduck_ml_dev/exec/train_radtts_with_ray.py\", line 296, in <listcomp>\n    torch.LongTensor([len(x['text_encoded']) for x in batch]),\nTypeError: tuple indices must be integers or slices, not str"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(raylet, ip=10.0.50.166) /home/ray/anaconda3/lib/python3.10/site-packages/ray/dashboard/agent.py:51: DeprecationWarning: There is no current event loop\n",
      "(raylet, ip=10.0.50.166)   aiogrpc.init_grpc_aio()\n",
      "(raylet, ip=10.0.53.1) /home/ray/anaconda3/lib/python3.10/site-packages/ray/dashboard/agent.py:51: DeprecationWarning: There is no current event loop\n",
      "(raylet, ip=10.0.53.1)   aiogrpc.init_grpc_aio()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(autoscaler +4m3s) Resized to 160 CPUs, 4 GPUs.\n",
      "(autoscaler +8m33s) Removing 1 nodes of type worker-node-type-1 (idle).\n",
      "(autoscaler +8m38s) Removing 1 nodes of type worker-node-type-1 (idle).\n",
      "(autoscaler +8m43s) Removing 1 nodes of type worker-node-type-1 (idle).\n",
      "(autoscaler +8m48s) Removing 1 nodes of type worker-node-type-1 (idle).\n"
     ]
    }
   ],
   "source": [
    "result = trainer.fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f85ac8e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9e46fa9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import ray\n",
    "parallelism_length = 400"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e355dd64",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-03-06 16:54:26,264\tINFO worker.py:1360 -- Connecting to existing Ray cluster at address: 10.0.37.211:6379...\n",
      "2023-03-06 16:54:26,291\tINFO worker.py:1548 -- Connected to Ray cluster. View the dashboard at \u001b[1m\u001b[32mhttps://console.anyscale.com/api/v2/sessions/ses_ha6my3r3kl4mn9jdylcqnfutq1/services?redirect_to=dashboard \u001b[39m\u001b[22m\n",
      "2023-03-06 16:54:26,316\tINFO packaging.py:330 -- Pushing file package 'gcs://_ray_pkg_c450220a9fe1382fee31ab05c616a7cf.zip' (6.75MiB) to Ray cluster...\n",
      "2023-03-06 16:54:26,438\tINFO packaging.py:343 -- Successfully pushed file package 'gcs://_ray_pkg_c450220a9fe1382fee31ab05c616a7cf.zip'.\n"
     ]
    }
   ],
   "source": [
    "lj_df = pd.read_csv(\n",
    "    \"https://uberduck-datasets-dirty.s3.us-west-2.amazonaws.com/lj_for_upload/metadata_formatted_100_edited.txt\",\n",
    "    sep=\"|\",\n",
    "    header=None,\n",
    "    quoting=3,\n",
    "    names=[\"path\", \"transcript\", \"speaker_id\"], # pitch path is implicit - this should be changed\n",
    ")\n",
    "speaker_ids = lj_df.speaker_id.tolist()\n",
    "speaker_ids_ds = ray.data.from_items(speaker_ids, parallelism=parallelism_length)\n",
    "speaker_ids_ds = speaker_ids_ds.map_batches(\n",
    "    lambda x: x, batch_format=\"pyarrow\", batch_size=None\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d49c9826",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>path</th>\n",
       "      <th>transcript</th>\n",
       "      <th>speaker_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>s3://uberduck-datasets-dirty/lj_for_upload/lj_...</td>\n",
       "      <td>Printing, in the only sense with which we are ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>s3://uberduck-datasets-dirty/lj_for_upload/lj_...</td>\n",
       "      <td>in being comparatively modern.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>s3://uberduck-datasets-dirty/lj_for_upload/lj_...</td>\n",
       "      <td>For although the Chinese took impressions from...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>s3://uberduck-datasets-dirty/lj_for_upload/lj_...</td>\n",
       "      <td>produced the block books, which were the immed...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>s3://uberduck-datasets-dirty/lj_for_upload/lj_...</td>\n",
       "      <td>the invention of movable metal letters in the ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>s3://uberduck-datasets-dirty/lj_for_upload/lj_...</td>\n",
       "      <td>have now come into general use and are obvious...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>s3://uberduck-datasets-dirty/lj_for_upload/lj_...</td>\n",
       "      <td>a little reduced in ugliness. The design of th...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>s3://uberduck-datasets-dirty/lj_for_upload/lj_...</td>\n",
       "      <td>and the whole effect is a little too gray, owi...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>s3://uberduck-datasets-dirty/lj_for_upload/lj_...</td>\n",
       "      <td>It must be remembered, however, that most mode...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>s3://uberduck-datasets-dirty/lj_for_upload/lj_...</td>\n",
       "      <td>and these somewhat wiry letters are suitable f...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows √ó 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 path  \\\n",
       "0   s3://uberduck-datasets-dirty/lj_for_upload/lj_...   \n",
       "1   s3://uberduck-datasets-dirty/lj_for_upload/lj_...   \n",
       "2   s3://uberduck-datasets-dirty/lj_for_upload/lj_...   \n",
       "3   s3://uberduck-datasets-dirty/lj_for_upload/lj_...   \n",
       "4   s3://uberduck-datasets-dirty/lj_for_upload/lj_...   \n",
       "..                                                ...   \n",
       "95  s3://uberduck-datasets-dirty/lj_for_upload/lj_...   \n",
       "96  s3://uberduck-datasets-dirty/lj_for_upload/lj_...   \n",
       "97  s3://uberduck-datasets-dirty/lj_for_upload/lj_...   \n",
       "98  s3://uberduck-datasets-dirty/lj_for_upload/lj_...   \n",
       "99  s3://uberduck-datasets-dirty/lj_for_upload/lj_...   \n",
       "\n",
       "                                           transcript  speaker_id  \n",
       "0   Printing, in the only sense with which we are ...           0  \n",
       "1                      in being comparatively modern.           0  \n",
       "2   For although the Chinese took impressions from...           0  \n",
       "3   produced the block books, which were the immed...           0  \n",
       "4   the invention of movable metal letters in the ...           0  \n",
       "..                                                ...         ...  \n",
       "95  have now come into general use and are obvious...           0  \n",
       "96  a little reduced in ugliness. The design of th...           0  \n",
       "97  and the whole effect is a little too gray, owi...           0  \n",
       "98  It must be remembered, however, that most mode...           0  \n",
       "99  and these somewhat wiry letters are suitable f...           0  \n",
       "\n",
       "[100 rows x 3 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lj_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "96726041",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_dataset = speaker_ids_ds.map_batches(\n",
    "    lambda table: table.rename(\n",
    "        columns={\n",
    "\n",
    "            \"value_1\": \"speaker_id\"\n",
    "        }\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a9d44e5e",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'Dataset' object has no attribute 'speaker_id'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43moutput_dataset\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mspeaker_id\u001b[49m\u001b[38;5;241m.\u001b[39mtolist()\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'Dataset' object has no attribute 'speaker_id'"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(autoscaler +2s) Tip: use `ray status` to view detailed cluster status. To disable these messages, set RAY_SCHEDULER_EVENTS=0.\n",
      "(autoscaler +2s) Removing 2 nodes of type worker-node-type-0 (idle).\n",
      "(autoscaler +7s) Removing 2 nodes of type worker-node-type-0 (idle).\n",
      "(autoscaler +12s) Removing 2 nodes of type worker-node-type-0 (idle).\n"
     ]
    }
   ],
   "source": [
    "output_dataset.speaker_id.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b04a9936",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(output_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dec6b96a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-03-06 16:50:22,749\tINFO bulk_executor.py:41 -- Executing DAG InputDataBuffer[Input] -> TaskPoolMapOperator[MapBatches(<lambda>)->MapBatches(<lambda>)]\n",
      "MapBatches(<lambda>)->MapBatches(<lambda>): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 100/100 [00:03<00:00, 28.88it/s]\n"
     ]
    }
   ],
   "source": [
    "output_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "11bda8c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#     lj_df = pd.read_csv(\n",
    "#         \"https://uberduck-datasets-dirty.s3.us-west-2.amazonaws.com/vctk_mic1/all_with_embs.txt\",\n",
    "#         sep=\"|\",\n",
    "#         header=None,\n",
    "#         quoting=3,\n",
    "#         names=[\"path\", \"speaker_id\", \"transcript\", \"dataset_audio_file_id\", \"emb_path\"],\n",
    "#     )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "12c7eb85",
   "metadata": {},
   "outputs": [],
   "source": [
    "# lj_df['path'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "3c62efcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# transcripts_ds = ray.data.from_items(transcripts, parallelism=parallelism_length)\n",
    "# speaker_ids_ds = ray.data.from_items(speaker_ids, parallelism=parallelism_length)\n",
    "# dataset_audio_file_ids = ray.data.from_items(\n",
    "#     dataset_audio_files, parallelism=parallelism_length\n",
    "# )\n",
    "\n",
    "# pitch_paths_ds = ray.data.read_binary_files(\n",
    "#     pitch_paths,\n",
    "#     parallelism=parallelism_length,\n",
    "#     meta_provider=FastFileMetadataProvider(),\n",
    "#     ray_remote_args={\"num_cpus\": 0.2},\n",
    "# )\n",
    "\n",
    "# audio_ds = audio_ds.map_batches(\n",
    "#     lambda x: x, batch_format=\"pyarrow\", batch_size=None\n",
    "# )\n",
    "# transcripts_ds = transcripts_ds.map_batches(\n",
    "#     lambda x: x, batch_format=\"pyarrow\", batch_size=None\n",
    "# )\n",
    "# dataset_audio_file_ids = dataset_audio_file_ids.map_batches(\n",
    "#     lambda x: x, batch_format=\"pyarrow\", batch_size=None\n",
    "# )\n",
    "# paths_ds = paths.map_batches(lambda x: x, batch_format=\"pyarrow\", batch_size=None)\n",
    "# pitches_paths_ds = pitch_paths_ds.map_batches(\n",
    "#     lambda x: x, batch_format=\"pyarrow\", batch_size=None\n",
    "# )\n",
    "# speaker_ids_ds = speaker_ids_ds.map_batches(\n",
    "#     lambda x: x, batch_format=\"pyarrow\", batch_size=None\n",
    "# )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef63787d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
