{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "45c5ca61",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b2ef8cba",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import torch\n",
    "from io import BytesIO\n",
    "def get_s3_state_dict(s3_url):\n",
    "    response = requests.get(s3_url, stream=True)\n",
    "    bio = BytesIO(response.content)\n",
    "    state_dict = torch.load(bio)\n",
    "    return state_dict\n",
    "#     model.load_state_dict(loaded[\"model\"])\n",
    "\n",
    "# s3_url = \"https://uberduck-models.s3.us-west-1.amazonaws.com/radtts++ljs-dap.pt\"\n",
    "s3_url = \"https://uberduck-models-us-west-2.s3.us-west-2.amazonaws.com/radtts%2B%2Bljs-dap.pt\"\n",
    "pretrained_dict = get_s3_state_dict(s3_url)['state_dict']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b0538b02",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Applying spectral norm to text encoder LSTM\n",
      "Applying spectral norm to context encoder LSTM\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "_IncompatibleKeys(missing_keys=[], unexpected_keys=['dur_pred_layer.bottleneck_layer.projection_fn.conv.bias', 'dur_pred_layer.bottleneck_layer.projection_fn.conv.weight_g', 'dur_pred_layer.bottleneck_layer.projection_fn.conv.weight_v', 'dur_pred_layer.feat_pred_fn.convolutions.0.bias', 'dur_pred_layer.feat_pred_fn.convolutions.0.weight_g', 'dur_pred_layer.feat_pred_fn.convolutions.0.weight_v', 'dur_pred_layer.feat_pred_fn.convolutions.1.bias', 'dur_pred_layer.feat_pred_fn.convolutions.1.weight_g', 'dur_pred_layer.feat_pred_fn.convolutions.1.weight_v', 'dur_pred_layer.feat_pred_fn.bilstm.weight_ih_l0', 'dur_pred_layer.feat_pred_fn.bilstm.bias_ih_l0', 'dur_pred_layer.feat_pred_fn.bilstm.bias_hh_l0', 'dur_pred_layer.feat_pred_fn.bilstm.weight_ih_l0_reverse', 'dur_pred_layer.feat_pred_fn.bilstm.bias_ih_l0_reverse', 'dur_pred_layer.feat_pred_fn.bilstm.bias_hh_l0_reverse', 'dur_pred_layer.feat_pred_fn.bilstm.weight_hh_l0_orig', 'dur_pred_layer.feat_pred_fn.bilstm.weight_hh_l0_reverse_orig', 'dur_pred_layer.feat_pred_fn.bilstm.weight_hh_l0_u', 'dur_pred_layer.feat_pred_fn.bilstm.weight_hh_l0_v', 'dur_pred_layer.feat_pred_fn.bilstm.weight_hh_l0_reverse_u', 'dur_pred_layer.feat_pred_fn.bilstm.weight_hh_l0_reverse_v', 'dur_pred_layer.feat_pred_fn.dense.weight', 'dur_pred_layer.feat_pred_fn.dense.bias', 'f0_pred_module.bottleneck_layer.projection_fn.conv.bias', 'f0_pred_module.bottleneck_layer.projection_fn.conv.weight_g', 'f0_pred_module.bottleneck_layer.projection_fn.conv.weight_v', 'f0_pred_module.feat_pred_fn.convolutions.0.bias', 'f0_pred_module.feat_pred_fn.convolutions.0.weight_g', 'f0_pred_module.feat_pred_fn.convolutions.0.weight_v', 'f0_pred_module.feat_pred_fn.convolutions.1.bias', 'f0_pred_module.feat_pred_fn.convolutions.1.weight_g', 'f0_pred_module.feat_pred_fn.convolutions.1.weight_v', 'f0_pred_module.feat_pred_fn.bilstm.weight_ih_l0', 'f0_pred_module.feat_pred_fn.bilstm.bias_ih_l0', 'f0_pred_module.feat_pred_fn.bilstm.bias_hh_l0', 'f0_pred_module.feat_pred_fn.bilstm.weight_ih_l0_reverse', 'f0_pred_module.feat_pred_fn.bilstm.bias_ih_l0_reverse', 'f0_pred_module.feat_pred_fn.bilstm.bias_hh_l0_reverse', 'f0_pred_module.feat_pred_fn.bilstm.weight_hh_l0_orig', 'f0_pred_module.feat_pred_fn.bilstm.weight_hh_l0_reverse_orig', 'f0_pred_module.feat_pred_fn.bilstm.weight_hh_l0_u', 'f0_pred_module.feat_pred_fn.bilstm.weight_hh_l0_v', 'f0_pred_module.feat_pred_fn.bilstm.weight_hh_l0_reverse_u', 'f0_pred_module.feat_pred_fn.bilstm.weight_hh_l0_reverse_v', 'f0_pred_module.feat_pred_fn.dense.weight', 'f0_pred_module.feat_pred_fn.dense.bias', 'energy_pred_module.bottleneck_layer.projection_fn.conv.bias', 'energy_pred_module.bottleneck_layer.projection_fn.conv.weight_g', 'energy_pred_module.bottleneck_layer.projection_fn.conv.weight_v', 'energy_pred_module.feat_pred_fn.convolutions.0.bias', 'energy_pred_module.feat_pred_fn.convolutions.0.weight_g', 'energy_pred_module.feat_pred_fn.convolutions.0.weight_v', 'energy_pred_module.feat_pred_fn.convolutions.1.bias', 'energy_pred_module.feat_pred_fn.convolutions.1.weight_g', 'energy_pred_module.feat_pred_fn.convolutions.1.weight_v', 'energy_pred_module.feat_pred_fn.bilstm.weight_ih_l0', 'energy_pred_module.feat_pred_fn.bilstm.bias_ih_l0', 'energy_pred_module.feat_pred_fn.bilstm.bias_hh_l0', 'energy_pred_module.feat_pred_fn.bilstm.weight_ih_l0_reverse', 'energy_pred_module.feat_pred_fn.bilstm.bias_ih_l0_reverse', 'energy_pred_module.feat_pred_fn.bilstm.bias_hh_l0_reverse', 'energy_pred_module.feat_pred_fn.bilstm.weight_hh_l0_orig', 'energy_pred_module.feat_pred_fn.bilstm.weight_hh_l0_reverse_orig', 'energy_pred_module.feat_pred_fn.bilstm.weight_hh_l0_u', 'energy_pred_module.feat_pred_fn.bilstm.weight_hh_l0_v', 'energy_pred_module.feat_pred_fn.bilstm.weight_hh_l0_reverse_u', 'energy_pred_module.feat_pred_fn.bilstm.weight_hh_l0_reverse_v', 'energy_pred_module.feat_pred_fn.dense.weight', 'energy_pred_module.feat_pred_fn.dense.bias'])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from uberduck_ml_dev.models.radtts import RADTTS\n",
    "from uberduck_ml_dev.exec.train_radtts_with_ray import model_config\n",
    "\n",
    "include_layers = []\n",
    "ignore_layers_warmstart = []\n",
    "# \"warmstart\"\n",
    "model = RADTTS(\n",
    "    **model_config,\n",
    ")\n",
    "\n",
    "if len(include_layers):\n",
    "    pretrained_dict = {k: v for k, v in pretrained_dict.items()\n",
    "                       if any(l in k for l in include_layers)}\n",
    "\n",
    "if len(ignore_layers_warmstart):\n",
    "    pretrained_dict = {k: v for k, v in pretrained_dict.items()\n",
    "                       if all(l not in k for l in ignore_layers_warmstart)}\n",
    "\n",
    "model_dict = model.state_dict()\n",
    "model_dict.update(pretrained_dict)\n",
    "model.load_state_dict(model_dict, strict=False)\n",
    "# print(\"Warm started from {}\".format(checkpoint_path))\n",
    "# model.load_state_dict(state_dict['state_dict'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3a01e814",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-03-08 14:52:12,052\tINFO worker.py:1360 -- Connecting to existing Ray cluster at address: 10.0.38.167:6379...\n",
      "2023-03-08 14:52:12,059\tINFO worker.py:1548 -- Connected to Ray cluster. View the dashboard at \u001b[1m\u001b[32mhttps://console.anyscale.com/api/v2/sessions/ses_ha6my3r3kl4mn9jdylcqnfutq1/services?redirect_to=dashboard \u001b[39m\u001b[22m\n",
      "2023-03-08 14:52:12,078\tINFO packaging.py:330 -- Pushing file package 'gcs://_ray_pkg_9ec71b75650aa97c22e1aaf3f034b3cf.zip' (7.00MiB) to Ray cluster...\n",
      "2023-03-08 14:52:12,159\tINFO packaging.py:343 -- Successfully pushed file package 'gcs://_ray_pkg_9ec71b75650aa97c22e1aaf3f034b3cf.zip'.\n",
      "(_get_read_tasks pid=40462) 2023-03-08 14:52:13,735\tWARNING file_meta_provider.py:162 -- Expanding 100 path(s). This may be a HIGH LATENCY operation on some cloud storage services. If the specified paths all point to files and never directories, try rerunning this read with `meta_provider=FastFileMetadataProvider()`.\n",
      "2023-03-08 14:52:14,981\tINFO bulk_executor.py:41 -- Executing DAG InputDataBuffer[Input] -> TaskPoolMapOperator[MapBatches(<lambda>)] -> AllToAllOperator[zip] -> AllToAllOperator[zip] -> AllToAllOperator[zip] -> TaskPoolMapOperator[MapBatches(<lambda>)]\n",
      "MapBatches(<lambda>): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 100/100 [00:02<00:00, 37.82it/s]\n",
      "2023-03-08 14:52:17,808\tINFO bulk_executor.py:41 -- Executing DAG InputDataBuffer[Input] -> TaskPoolMapOperator[read] -> TaskPoolMapOperator[MapBatches(<lambda>)]\n",
      "read:   2%|‚ñè         | 2/100 [00:00<00:23,  4.24it/s]2023-03-08 14:52:24,027\tWARNING worker.py:1870 -- WARNING: 16 PYTHON worker processes have been started on node: 0d525869aa4fbe7486608cd1f978cbcab70a1e9b9f62ca8f1ab55815 with address: 10.0.38.167. This could be a result of using a large number of actors, or due to tasks blocked in ray.get() calls (see https://github.com/ray-project/ray/issues/3644 for some discussion of workarounds).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(autoscaler +15m23s) Tip: use `ray status` to view detailed cluster status. To disable these messages, set RAY_SCHEDULER_EVENTS=0.\n",
      "(autoscaler +15m23s) Adding 2 node(s) of type worker-node-type-0.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-03-08 14:52:26,517\tWARNING worker.py:1870 -- WARNING: 20 PYTHON worker processes have been started on node: 0d525869aa4fbe7486608cd1f978cbcab70a1e9b9f62ca8f1ab55815 with address: 10.0.38.167. This could be a result of using a large number of actors, or due to tasks blocked in ray.get() calls (see https://github.com/ray-project/ray/issues/3644 for some discussion of workarounds).\n",
      "2023-03-08 14:52:26,981\tWARNING worker.py:1870 -- WARNING: 24 PYTHON worker processes have been started on node: 0d525869aa4fbe7486608cd1f978cbcab70a1e9b9f62ca8f1ab55815 with address: 10.0.38.167. This could be a result of using a large number of actors, or due to tasks blocked in ray.get() calls (see https://github.com/ray-project/ray/issues/3644 for some discussion of workarounds).\n",
      "read: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 100/100 [00:15<00:00,  6.32it/s]\n",
      "MapBatches(<lambda>): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 100/100 [00:00<00:00, 390.35it/s]\n",
      "2023-03-08 14:52:34,218\tWARNING plan.py:528 -- Warning: The Ray cluster currently does not have any available CPUs. The Dataset job will hang unless more CPUs are freed up. A common reason is that cluster resources are used by Actors or Tune trials; see the following link for more details: https://docs.ray.io/en/master/data/dataset-internals.html#datasets-and-tune\n",
      "2023-03-08 14:52:34,219\tINFO bulk_executor.py:41 -- Executing DAG InputDataBuffer[Input] -> TaskPoolMapOperator[MapBatches(<lambda>)]\n",
      "MapBatches(<lambda>): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 100/100 [00:00<00:00, 416.24it/s]\n",
      "2023-03-08 14:52:35,036\tINFO bulk_executor.py:41 -- Executing DAG InputDataBuffer[Input] -> TaskPoolMapOperator[MapBatches(<lambda>)]\n",
      "MapBatches(<lambda>): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 100/100 [00:00<00:00, 196.19it/s]\n",
      "MapBatches(<lambda>): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 100/100 [00:00<00:00, 125.30it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(autoscaler +15m38s) Adding 2 node(s) of type worker-node-type-0.\n"
     ]
    }
   ],
   "source": [
    "from uberduck_ml_dev.exec.train_radtts_with_ray import get_ray_dataset\n",
    "ray_dataset = get_ray_dataset()\n",
    "datum = ray_dataset.take(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "79be04ed",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'session' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[18], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m dataset_shard \u001b[38;5;241m=\u001b[39m \u001b[43msession\u001b[49m\u001b[38;5;241m.\u001b[39mget_dataset_shard(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtrain\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'session' is not defined"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(autoscaler +21m25s) Removing 2 nodes of type worker-node-type-0 (idle).\n",
      "(autoscaler +21m30s) Removing 2 nodes of type worker-node-type-0 (idle).\n",
      "(autoscaler +21m35s) Removing 2 nodes of type worker-node-type-0 (idle).\n",
      "(autoscaler +21m40s) Removing 4 nodes of type worker-node-type-0 (idle).\n",
      "(autoscaler +21m45s) Removing 4 nodes of type worker-node-type-0 (idle).\n",
      "(autoscaler +21m50s) Removing 4 nodes of type worker-node-type-0 (idle).\n",
      "(autoscaler +21m55s) Removing 4 nodes of type worker-node-type-0 (idle).\n",
      "(autoscaler +22m0s) Removing 4 nodes of type worker-node-type-0 (idle).\n",
      "(autoscaler +22m5s) Removing 4 nodes of type worker-node-type-0 (idle).\n",
      "(autoscaler +22m9s) Removing 4 nodes of type worker-node-type-0 (idle).\n",
      "(autoscaler +22m15s) Removing 4 nodes of type worker-node-type-0 (idle).\n",
      "(autoscaler +22m20s) Removing 4 nodes of type worker-node-type-0 (idle).\n",
      "(autoscaler +22m25s) Removing 4 nodes of type worker-node-type-0 (idle).\n",
      "(autoscaler +22m30s) Removing 4 nodes of type worker-node-type-0 (idle).\n",
      "(autoscaler +22m35s) Removing 4 nodes of type worker-node-type-0 (idle).\n",
      "(autoscaler +22m40s) Removing 4 nodes of type worker-node-type-0 (idle).\n",
      "(autoscaler +22m45s) Removing 4 nodes of type worker-node-type-0 (idle).\n",
      "(autoscaler +22m50s) Removing 4 nodes of type worker-node-type-0 (idle).\n",
      "(autoscaler +22m55s) Removing 4 nodes of type worker-node-type-0 (idle).\n",
      "(autoscaler +23m0s) Removing 4 nodes of type worker-node-type-0 (idle).\n",
      "(autoscaler +23m5s) Removing 2 nodes of type worker-node-type-0 (idle).\n",
      "(autoscaler +23m10s) Resized to 36 CPUs, 1 GPUs.\n",
      "(autoscaler +23m10s) Removing 2 nodes of type worker-node-type-0 (idle).\n",
      "(autoscaler +23m15s) Removing 2 nodes of type worker-node-type-0 (idle).\n",
      "(autoscaler +23m20s) Removing 2 nodes of type worker-node-type-0 (idle).\n",
      "(autoscaler +23m25s) Removing 2 nodes of type worker-node-type-0 (idle).\n",
      "(autoscaler +23m30s) Removing 2 nodes of type worker-node-type-0 (idle).\n",
      "(autoscaler +23m41s) Resized to 4 CPUs, 1 GPUs.\n"
     ]
    }
   ],
   "source": [
    "from ray.air import session\n",
    "dataset_shard = session.get_dataset_shard(\"train\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "4e965737",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(raylet, ip=10.0.35.179) /home/ray/anaconda3/lib/python3.10/site-packages/ray/dashboard/agent.py:51: DeprecationWarning: There is no current event loop\n",
      "(raylet, ip=10.0.35.179)   aiogrpc.init_grpc_aio()\n",
      "(raylet, ip=10.0.19.249) /home/ray/anaconda3/lib/python3.10/site-packages/ray/dashboard/agent.py:51: DeprecationWarning: There is no current event loop\n",
      "(raylet, ip=10.0.19.249)   aiogrpc.init_grpc_aio()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(autoscaler +16m23s) Resized to 36 CPUs, 1 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(raylet, ip=10.0.48.237) /home/ray/anaconda3/lib/python3.10/site-packages/ray/dashboard/agent.py:51: DeprecationWarning: There is no current event loop\n",
      "(raylet, ip=10.0.48.237)   aiogrpc.init_grpc_aio()\n",
      "(raylet, ip=10.0.28.173) /home/ray/anaconda3/lib/python3.10/site-packages/ray/dashboard/agent.py:51: DeprecationWarning: There is no current event loop\n",
      "(raylet, ip=10.0.28.173)   aiogrpc.init_grpc_aio()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(autoscaler +16m38s) Resized to 68 CPUs, 1 GPUs.\n"
     ]
    }
   ],
   "source": [
    "# datum\n",
    "batch = next(enumerate(\n",
    "            dataset_shard.iter_batches(batch_size=batch_size)\n",
    "        ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b29787ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_dict = ray_df_to_batch_radtts(batch)\n",
    "mel = to_gpu(batch_dict['mel'])\n",
    "speaker_ids = to_gpu(batch_dict['speaker_ids'])\n",
    "attn_prior = to_gpu(batch_dict['attn_prior'])\n",
    "f0 = to_gpu(batch_dict['f0'])\n",
    "voiced_mask = to_gpu(batch_dict['voiced_mask'])\n",
    "p_voiced = to_gpu(batch_dict['p_voiced'])\n",
    "text = to_gpu(batch_dict['text'])\n",
    "in_lens = to_gpu(batch_dict['input_lengths'])\n",
    "out_lens = to_gpu(batch_dict['output_lengths'])\n",
    "energy_avg = to_gpu(batch_dict['energy_avg'])\n",
    "\n",
    "outputs = model(\n",
    "            mel, speaker_ids, text, in_lens, out_lens,\n",
    "            binarize_attention=binarize, attn_prior=attn_prior,\n",
    "            f0=f0, energy_avg=energy_avg,\n",
    "            voiced_mask=voiced_mask, p_voiced=p_voiced)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "213201fc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e24f0c2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "951523ab",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf0f86c4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "031f6262",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4b823014",
   "metadata": {},
   "outputs": [],
   "source": [
    "from uberduck_ml_dev.exec.train_radtts_with_ray import get_ray_dataset, train_func, train_config, model_config\n",
    "from ray.train.torch import TorchTrainer, TorchCheckpoint, TorchTrainer\n",
    "from ray.air.config import ScalingConfig, RunConfig\n",
    "from ray.tune import SyncConfig\n",
    "\n",
    "class TorchCheckpointFixed(TorchCheckpoint):\n",
    "    def __setstate__(self, state: dict):\n",
    "        if \"_data_dict\" in state and state[\"_data_dict\"]:\n",
    "            state = state.copy()\n",
    "            state[\"_data_dict\"] = self._decode_data_dict(state[\"_data_dict\"])\n",
    "        super(TorchCheckpoint, self).__setstate__(state)\n",
    "\n",
    "\n",
    "# result = trainer.fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3c27e559",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ray.air.integrations.wandb import  setup_wandb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9f3b6a1a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-03-08 14:27:33,779\tINFO worker.py:1360 -- Connecting to existing Ray cluster at address: 10.0.38.167:6379...\n",
      "2023-03-08 14:27:33,828\tINFO worker.py:1548 -- Connected to Ray cluster. View the dashboard at \u001b[1m\u001b[32mhttps://console.anyscale.com/api/v2/sessions/ses_ha6my3r3kl4mn9jdylcqnfutq1/services?redirect_to=dashboard \u001b[39m\u001b[22m\n",
      "2023-03-08 14:27:34,150\tINFO packaging.py:330 -- Pushing file package 'gcs://_ray_pkg_78efb00b2d4bf87cf2071ad4d319358d.zip' (7.03MiB) to Ray cluster...\n",
      "2023-03-08 14:27:34,245\tINFO packaging.py:343 -- Successfully pushed file package 'gcs://_ray_pkg_78efb00b2d4bf87cf2071ad4d319358d.zip'.\n",
      "(_get_read_tasks pid=25299) 2023-03-08 14:27:35,903\tWARNING file_meta_provider.py:162 -- Expanding 100 path(s). This may be a HIGH LATENCY operation on some cloud storage services. If the specified paths all point to files and never directories, try rerunning this read with `meta_provider=FastFileMetadataProvider()`.\n"
     ]
    }
   ],
   "source": [
    "ray_dataset = get_ray_dataset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "91ea33c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "train_config['n_group_size'] = model_config['n_group_size']\n",
    "train_config['dur_model_config'] = model_config['dur_model_config']\n",
    "train_config['f0_model_config'] = model_config['f0_model_config']\n",
    "train_config['energy_model_config'] = model_config['energy_model_config']\n",
    "train_config['v_model_config']=model_config['v_model_config']\n",
    "\n",
    "trainer = TorchTrainer(\n",
    "    train_loop_per_worker=train_func,\n",
    "    train_loop_config=train_config,\n",
    "    scaling_config=ScalingConfig(\n",
    "        num_workers=2, use_gpu=True, resources_per_worker=dict(CPU=4, GPU=1)\n",
    "    ),\n",
    "    run_config=RunConfig(\n",
    "        sync_config=SyncConfig(upload_dir=\"s3://uberduck-anyscale-data/checkpoints\")\n",
    "    ),\n",
    "    datasets={\"train\": ray_dataset},\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1525d483",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-03-07 16:35:52,269\tWARNING session.py:100 -- In neither tune session nor train session!\n",
      "/home/ray/anaconda3/lib/python3.10/site-packages/ray/air/session.py:28: UserWarning: `get_trial_id` is meant to only be called inside a function that is executed by a Tuner or Trainer. Returning `None`.\n",
      "  warnings.warn(\n",
      "2023-03-07 16:35:52,271\tWARNING session.py:100 -- In neither tune session nor train session!\n",
      "/home/ray/anaconda3/lib/python3.10/site-packages/ray/air/session.py:28: UserWarning: `get_trial_name` is meant to only be called inside a function that is executed by a Tuner or Trainer. Returning `None`.\n",
      "  warnings.warn(\n",
      "2023-03-07 16:35:52,272\tWARNING session.py:100 -- In neither tune session nor train session!\n",
      "/home/ray/anaconda3/lib/python3.10/site-packages/ray/air/session.py:28: UserWarning: `get_experiment_name` is meant to only be called inside a function that is executed by a Tuner or Trainer. Returning `None`.\n",
      "  warnings.warn(\n",
      "wandb: Currently logged in as: uberduck. Use `wandb login --relogin` to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.13.11 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.13.10"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/ray/default/wandb/run-20230307_163553-e0id39cs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/uberduck/radtts-ray/runs/e0id39cs' target=\"_blank\">fresh-brook-47</a></strong> to <a href='https://wandb.ai/uberduck/radtts-ray' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/uberduck/radtts-ray' target=\"_blank\">https://wandb.ai/uberduck/radtts-ray</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/uberduck/radtts-ray/runs/e0id39cs' target=\"_blank\">https://wandb.ai/uberduck/radtts-ray/runs/e0id39cs</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<button onClick=\"this.nextSibling.style.display='block';this.style.display='none';\">Display W&B run</button><iframe src='https://wandb.ai/uberduck/radtts-ray/runs/e0id39cs?jupyter=true' style='border:none;width:100%;height:420px;display:none;'></iframe>"
      ],
      "text/plain": [
       "<wandb.sdk.wandb_run.Run at 0x7f0524702da0>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "config = train_config\n",
    "setup_wandb(config, project=\"radtts-ray\", rank_zero_only=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "bd79c795",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA AVAILABLE:  True\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'RADTTS' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[8], line 11\u001b[0m\n\u001b[1;32m      9\u001b[0m kl_loss_start_iter \u001b[38;5;241m=\u001b[39m config[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mkl_loss_start_iter\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[1;32m     10\u001b[0m binarization_start_iter \u001b[38;5;241m=\u001b[39m config[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbinarization_start_iter\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[0;32m---> 11\u001b[0m model \u001b[38;5;241m=\u001b[39m \u001b[43mRADTTS\u001b[49m(\n\u001b[1;32m     12\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mmodel_config,\n\u001b[1;32m     13\u001b[0m )\n\u001b[1;32m     14\u001b[0m model \u001b[38;5;241m=\u001b[39m train\u001b[38;5;241m.\u001b[39mtorch\u001b[38;5;241m.\u001b[39mprepare_model(model, parallel_strategy_kwargs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mdict\u001b[39m(find_unused_parameters\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m))\n",
      "\u001b[0;31mNameError\u001b[0m: name 'RADTTS' is not defined"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "print(\"CUDA AVAILABLE: \", torch.cuda.is_available())\n",
    "epochs = config[\"epochs\"]\n",
    "batch_size = config[\"batch_size\"]\n",
    "steps_per_sample = config[\"steps_per_sample\"]\n",
    "# gin_channels = config[\"gin_channels\"]\n",
    "sigma = config['sigma']\n",
    "kl_loss_start_iter = config['kl_loss_start_iter']\n",
    "binarization_start_iter = config['binarization_start_iter']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "64e696bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Applying spectral norm to text encoder LSTM\n",
      "Applying spectral norm to context encoder LSTM\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ray/default/uberduck_ml_dev/models/common.py:1516: UserWarning: torch.qr is deprecated in favor of torch.linalg.qr and will be removed in a future PyTorch release.\n",
      "The boolean parameter 'some' has been replaced with a string parameter 'mode'.\n",
      "Q, R = torch.qr(A, some)\n",
      "should be replaced with\n",
      "Q, R = torch.linalg.qr(A, 'reduced' if some else 'complete') (Triggered internally at ../aten/src/ATen/native/BatchLinearAlgebra.cpp:2349.)\n",
      "  W = torch.qr(torch.FloatTensor(c, c).normal_())[0]\n",
      "/home/ray/anaconda3/lib/python3.10/site-packages/torch/functional.py:1682: UserWarning: torch.lu is deprecated in favor of torch.linalg.lu_factor / torch.linalg.lu_factor_ex and will be removed in a future PyTorch release.\n",
      "LU, pivots = torch.lu(A, compute_pivots)\n",
      "should be replaced with\n",
      "LU, pivots = torch.linalg.lu_factor(A, compute_pivots)\n",
      "and\n",
      "LU, pivots, info = torch.lu(A, compute_pivots, get_infos=True)\n",
      "should be replaced with\n",
      "LU, pivots, info = torch.linalg.lu_factor_ex(A, compute_pivots) (Triggered internally at ../aten/src/ATen/native/BatchLinearAlgebra.cpp:1915.)\n",
      "  return torch._lu_with_info(A, pivot=pivot, check_errors=(not get_infos))\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# import ray.train as train\n",
    "# model = train.torch.prepare_model(model, parallel_strategy_kwargs = dict(find_unused_parameters=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a16bf912",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'state_dict' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[7], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m model\u001b[38;5;241m.\u001b[39mload_state_dict(\u001b[43mstate_dict\u001b[49m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'state_dict' is not defined"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebdf4558",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# discriminator = MultiPeriodDiscriminator(MODEL_CONFIG[\"use_spectral_norm\"])\n",
    "# discriminator = train.torch.prepare_model(discriminator)\n",
    "\n",
    "checkpoint_dict = _load_checkpoint_dict()\n",
    "if checkpoint_dict is None:\n",
    "    global_step = 0\n",
    "    start_epoch = 0\n",
    "else:\n",
    "    global_step = checkpoint_dict[\"global_step\"]\n",
    "    start_epoch = checkpoint_dict[\"epoch\"]\n",
    "    if session.get_world_size() > 1:\n",
    "        model_sd = checkpoint_dict[\"model\"]\n",
    "        # NOTE(zach): Add audio embedding state dict if it is not present.\n",
    "        # NOTE(zach): Pass strict=False due to different nuber of gin_channels\n",
    "        model.load_state_dict(model_sd, strict=False)\n",
    "    else:\n",
    "        model_sd = _fix_state_dict(checkpoint_dict[\"model\"])\n",
    "        # NOTE(zach): Pass strict=False due to different nuber of gin_channels\n",
    "        model.load_state_dict(model_sd, strict=False)\n",
    "    del checkpoint_dict\n",
    "\n",
    "# NOTE (Sam): replace with RAdam\n",
    "optim = torch.optim.Adam(\n",
    "    model.parameters(),\n",
    "    lr = config[\"learning_rate\"],\n",
    "    weight_decay = config[\"weight_decay\"]\n",
    ")\n",
    "scheduler = ExponentialLR(\n",
    "    optim,\n",
    "    config[\"weight_decay\"],\n",
    "    last_epoch=-1,\n",
    ")\n",
    "dataset_shard = session.get_dataset_shard(\"train\")\n",
    "global_step = 0\n",
    "scaler = GradScaler()\n",
    "\n",
    "criterion = RADTTSLoss(\n",
    "    sigma,\n",
    "    config['n_group_size'],\n",
    "    config['dur_model_config'],\n",
    "    config['f0_model_config'],\n",
    "    config['energy_model_config'],\n",
    "    vpred_model_config=config['v_model_config'],\n",
    "    loss_weights=config['loss_weights']\n",
    ")\n",
    "attention_kl_loss = AttentionBinarizationLoss()\n",
    "iteration = 0\n",
    "for epoch in range(start_epoch, start_epoch + epochs):\n",
    "    for batch_idx, ray_batch_df in enumerate(\n",
    "        dataset_shard.iter_batches(batch_size=batch_size)\n",
    "    ):\n",
    "        torch.cuda.empty_cache()\n",
    "        _train_step(\n",
    "            ray_batch_df,\n",
    "            model,\n",
    "            optim,\n",
    "            global_step,\n",
    "            steps_per_sample,\n",
    "            scaler,\n",
    "            scheduler,\n",
    "            criterion,\n",
    "            attention_kl_loss,\n",
    "            iteration,\n",
    "            kl_loss_start_iter,\n",
    "            binarization_start_iter,\n",
    "        )\n",
    "        global_step += 1\n",
    "    if session.get_world_rank() == 0:\n",
    "        # TODO(zach): Also save wandb artifact here.\n",
    "        checkpoint = Checkpoint.from_dict(\n",
    "            dict(\n",
    "                epoch=epoch,\n",
    "                global_step=global_step,\n",
    "                model=model.state_dict(),\n",
    "            )\n",
    "        )\n",
    "        session.report({}, checkpoint=checkpoint)\n",
    "        artifact = wandb.Artifact(\n",
    "            f\"artifact_epoch{epoch}_step{global_step}\", \"model\"\n",
    "        )\n",
    "        with tempfile.TemporaryDirectory() as tempdirname:\n",
    "            checkpoint.to_directory(tempdirname)\n",
    "            artifact.add_dir(tempdirname)\n",
    "            wandb.log_artifact(artifact)\n",
    "        iteration += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7645e389",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-03-07 16:19:08,608\tINFO worker.py:1360 -- Connecting to existing Ray cluster at address: 10.0.37.211:6379...\n",
      "2023-03-07 16:19:08,633\tINFO worker.py:1548 -- Connected to Ray cluster. View the dashboard at \u001b[1m\u001b[32mhttps://console.anyscale.com/api/v2/sessions/ses_ha6my3r3kl4mn9jdylcqnfutq1/services?redirect_to=dashboard \u001b[39m\u001b[22m\n",
      "2023-03-07 16:19:08,653\tINFO packaging.py:330 -- Pushing file package 'gcs://_ray_pkg_ee2356972b78dbfda1fe20807a72a9e9.zip' (6.85MiB) to Ray cluster...\n",
      "2023-03-07 16:19:08,744\tINFO packaging.py:343 -- Successfully pushed file package 'gcs://_ray_pkg_ee2356972b78dbfda1fe20807a72a9e9.zip'.\n",
      "(_get_read_tasks pid=5467, ip=10.0.46.245) 2023-03-07 16:19:10,287\tWARNING file_meta_provider.py:162 -- Expanding 100 path(s). This may be a HIGH LATENCY operation on some cloud storage services. If the specified paths all point to files and never directories, try rerunning this read with `meta_provider=FastFileMetadataProvider()`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div class=\"tuneStatus\">\n",
       "  <div style=\"display: flex;flex-direction: row\">\n",
       "    <div style=\"display: flex;flex-direction: column;\">\n",
       "      <h3>Tune Status</h3>\n",
       "      <table>\n",
       "<tbody>\n",
       "<tr><td>Current time:</td><td>2023-03-07 16:23:56</td></tr>\n",
       "<tr><td>Running for: </td><td>00:04:44.92        </td></tr>\n",
       "<tr><td>Memory:      </td><td>7.1/15.3 GiB       </td></tr>\n",
       "</tbody>\n",
       "</table>\n",
       "    </div>\n",
       "    <div class=\"vDivider\"></div>\n",
       "    <div class=\"systemInfo\">\n",
       "      <h3>System Info</h3>\n",
       "      Using FIFO scheduling algorithm.<br>Resources requested: 9.0/184 CPUs, 2.0/6 GPUs, 0.0/484.53 GiB heap, 0.0/208.25 GiB objects (0.0/6.0 accelerator_type:T4)\n",
       "    </div>\n",
       "    \n",
       "  </div>\n",
       "  <div class=\"hDivider\"></div>\n",
       "  <div class=\"trialStatus\">\n",
       "    <h3>Trial Status</h3>\n",
       "    <table>\n",
       "<thead>\n",
       "<tr><th>Trial name              </th><th>status  </th><th>loc             </th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>TorchTrainer_d9af1_00000</td><td>RUNNING </td><td>10.0.46.245:5550</td></tr>\n",
       "</tbody>\n",
       "</table>\n",
       "  </div>\n",
       "</div>\n",
       "<style>\n",
       ".tuneStatus {\n",
       "  color: var(--jp-ui-font-color1);\n",
       "}\n",
       ".tuneStatus .systemInfo {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       ".tuneStatus td {\n",
       "  white-space: nowrap;\n",
       "}\n",
       ".tuneStatus .trialStatus {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       ".tuneStatus h3 {\n",
       "  font-weight: bold;\n",
       "}\n",
       ".tuneStatus .hDivider {\n",
       "  border-bottom-width: var(--jp-border-width);\n",
       "  border-bottom-color: var(--jp-border-color0);\n",
       "  border-bottom-style: solid;\n",
       "}\n",
       ".tuneStatus .vDivider {\n",
       "  border-left-width: var(--jp-border-width);\n",
       "  border-left-color: var(--jp-border-color0);\n",
       "  border-left-style: solid;\n",
       "  margin: 0.5em 1em 0.5em 1em;\n",
       "}\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-03-07 16:19:11,683\tWARNING trial_runner.py:1333 -- The maximum number of pending trials has been automatically set to the number of available cluster CPUs, which is high (202 CPUs/pending trials). If you're running an experiment with a large number of trials, this could lead to scheduling overhead. In this case, consider setting the `TUNE_MAX_PENDING_TRIALS_PG` environment variable to the desired maximum number of concurrent trials.\n",
      "(RayTrainWorker pid=235, ip=10.0.45.178) 2023-03-07 16:19:23,587\tINFO config.py:86 -- Setting up process group for: env:// [rank=0, world_size=2]\n",
      "(TorchTrainer pid=5550, ip=10.0.46.245) 2023-03-07 16:19:24,250\tINFO bulk_executor.py:41 -- Executing DAG InputDataBuffer[Input] -> TaskPoolMapOperator[MapBatches(<lambda>)] -> AllToAllOperator[zip] -> AllToAllOperator[zip] -> AllToAllOperator[zip] -> TaskPoolMapOperator[MapBatches(<lambda>)] -> AllToAllOperator[randomize_block_order]\n",
      "(TorchTrainer pid=5550, ip=10.0.46.245) 2023-03-07 16:19:27,668\tINFO bulk_executor.py:41 -- Executing DAG InputDataBuffer[Input] -> TaskPoolMapOperator[read] -> TaskPoolMapOperator[MapBatches(<lambda>)]\n",
      "(TorchTrainer pid=5550, ip=10.0.46.245) 2023-03-07 16:19:33,962\tINFO bulk_executor.py:41 -- Executing DAG InputDataBuffer[Input] -> TaskPoolMapOperator[MapBatches(<lambda>)]\n",
      "(TorchTrainer pid=5550, ip=10.0.46.245) 2023-03-07 16:19:34,065\tINFO bulk_executor.py:41 -- Executing DAG InputDataBuffer[Input] -> TaskPoolMapOperator[MapBatches(<lambda>)]\n",
      "(TorchTrainer pid=5550, ip=10.0.46.245) /home/ray/anaconda3/lib/python3.10/site-packages/ray/train/_internal/dataset_iterator.py:64: UserWarning: session.get_dataset_shard returns a ray.data.DatasetIterator instead of a Dataset/DatasetPipeline as of Ray v2.3. Use iter_torch_batches(), to_tf(), or iter_batches() to iterate over one epoch. See https://docs.ray.io/en/latest/data/api/dataset_iterator.html for full DatasetIterator docs.\n",
      "(TorchTrainer pid=5550, ip=10.0.46.245)   warnings.warn(\n",
      "(RayTrainWorker pid=235, ip=10.0.45.178) [nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "(RayTrainWorker pid=235, ip=10.0.45.178) [nltk_data]     /home/ray/nltk_data...\n",
      "(RayTrainWorker pid=235, ip=10.0.45.178) [nltk_data]   Unzipping taggers/averaged_perceptron_tagger.zip.\n",
      "(RayTrainWorker pid=417, ip=10.0.17.31) wandb: Currently logged in as: uberduck. Use `wandb login --relogin` to force relogin\n",
      "(RayTrainWorker pid=235, ip=10.0.45.178) wandb: Currently logged in as: uberduck. Use `wandb login --relogin` to force relogin\n",
      "(RayTrainWorker pid=417, ip=10.0.17.31) wandb: wandb version 0.13.11 is available!  To upgrade, please run:\n",
      "(RayTrainWorker pid=417, ip=10.0.17.31) wandb:  $ pip install wandb --upgrade\n",
      "(RayTrainWorker pid=417, ip=10.0.17.31) wandb: Tracking run with wandb version 0.13.10\n",
      "(RayTrainWorker pid=417, ip=10.0.17.31) wandb: Run data is saved locally in /home/ray/ray_results/TorchTrainer_2023-03-07_16-19-11/TorchTrainer_d9af1_00000_0_2023-03-07_16-19-13/rank_1/wandb/run-20230307_161948-d9af1_00000\n",
      "(RayTrainWorker pid=417, ip=10.0.17.31) wandb: Run `wandb offline` to turn off syncing.\n",
      "(RayTrainWorker pid=417, ip=10.0.17.31) wandb: Syncing run TorchTrainer_d9af1_00000\n",
      "(RayTrainWorker pid=417, ip=10.0.17.31) wandb: ‚≠êÔ∏è View project at https://wandb.ai/uberduck/radtts-ray\n",
      "(RayTrainWorker pid=417, ip=10.0.17.31) wandb: üöÄ View run at https://wandb.ai/uberduck/radtts-ray/runs/d9af1_00000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(RayTrainWorker pid=417, ip=10.0.17.31) CUDA AVAILABLE:  True\n",
      "(RayTrainWorker pid=417, ip=10.0.17.31) Applying spectral norm to text encoder LSTM\n",
      "(RayTrainWorker pid=417, ip=10.0.17.31) Applying spectral norm to context encoder LSTM\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(RayTrainWorker pid=417, ip=10.0.17.31) /tmp/ray/session_2023-03-06_08-59-42_925397_141/runtime_resources/working_dir_files/_ray_pkg_ee2356972b78dbfda1fe20807a72a9e9/uberduck_ml_dev/models/common.py:1516: UserWarning: torch.qr is deprecated in favor of torch.linalg.qr and will be removed in a future PyTorch release.\n",
      "(RayTrainWorker pid=417, ip=10.0.17.31) The boolean parameter 'some' has been replaced with a string parameter 'mode'.\n",
      "(RayTrainWorker pid=417, ip=10.0.17.31) Q, R = torch.qr(A, some)\n",
      "(RayTrainWorker pid=417, ip=10.0.17.31) should be replaced with\n",
      "(RayTrainWorker pid=417, ip=10.0.17.31) Q, R = torch.linalg.qr(A, 'reduced' if some else 'complete') (Triggered internally at ../aten/src/ATen/native/BatchLinearAlgebra.cpp:2349.)\n",
      "(RayTrainWorker pid=417, ip=10.0.17.31)   W = torch.qr(torch.FloatTensor(c, c).normal_())[0]\n",
      "(RayTrainWorker pid=417, ip=10.0.17.31) /home/ray/anaconda3/lib/python3.10/site-packages/torch/functional.py:1682: UserWarning: torch.lu is deprecated in favor of torch.linalg.lu_factor / torch.linalg.lu_factor_ex and will be removed in a future PyTorch release.\n",
      "(RayTrainWorker pid=417, ip=10.0.17.31) LU, pivots = torch.lu(A, compute_pivots)\n",
      "(RayTrainWorker pid=417, ip=10.0.17.31) should be replaced with\n",
      "(RayTrainWorker pid=417, ip=10.0.17.31) LU, pivots = torch.linalg.lu_factor(A, compute_pivots)\n",
      "(RayTrainWorker pid=417, ip=10.0.17.31) and\n",
      "(RayTrainWorker pid=417, ip=10.0.17.31) LU, pivots, info = torch.lu(A, compute_pivots, get_infos=True)\n",
      "(RayTrainWorker pid=417, ip=10.0.17.31) should be replaced with\n",
      "(RayTrainWorker pid=417, ip=10.0.17.31) LU, pivots, info = torch.linalg.lu_factor_ex(A, compute_pivots) (Triggered internally at ../aten/src/ATen/native/BatchLinearAlgebra.cpp:1915.)\n",
      "(RayTrainWorker pid=417, ip=10.0.17.31)   return torch._lu_with_info(A, pivot=pivot, check_errors=(not get_infos))\n",
      "(RayTrainWorker pid=235, ip=10.0.45.178) wandb: wandb version 0.13.11 is available!  To upgrade, please run:\n",
      "(RayTrainWorker pid=235, ip=10.0.45.178) wandb:  $ pip install wandb --upgrade\n",
      "(RayTrainWorker pid=235, ip=10.0.45.178) wandb: Tracking run with wandb version 0.13.10\n",
      "(RayTrainWorker pid=235, ip=10.0.45.178) wandb: Run data is saved locally in /home/ray/ray_results/TorchTrainer_2023-03-07_16-19-11/TorchTrainer_d9af1_00000_0_2023-03-07_16-19-13/rank_0/wandb/run-20230307_161948-d9af1_00000\n",
      "(RayTrainWorker pid=235, ip=10.0.45.178) wandb: Run `wandb offline` to turn off syncing.\n",
      "(RayTrainWorker pid=235, ip=10.0.45.178) wandb: Syncing run TorchTrainer_d9af1_00000\n",
      "(RayTrainWorker pid=235, ip=10.0.45.178) wandb: ‚≠êÔ∏è View project at https://wandb.ai/uberduck/radtts-ray\n",
      "(RayTrainWorker pid=235, ip=10.0.45.178) wandb: üöÄ View run at https://wandb.ai/uberduck/radtts-ray/runs/d9af1_00000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(RayTrainWorker pid=235, ip=10.0.45.178) CUDA AVAILABLE:  True\n",
      "(RayTrainWorker pid=235, ip=10.0.45.178) Applying spectral norm to text encoder LSTM\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(RayTrainWorker pid=235, ip=10.0.45.178) /tmp/ray/session_2023-03-06_08-59-42_925397_141/runtime_resources/working_dir_files/_ray_pkg_ee2356972b78dbfda1fe20807a72a9e9/uberduck_ml_dev/models/common.py:1516: UserWarning: torch.qr is deprecated in favor of torch.linalg.qr and will be removed in a future PyTorch release.\n",
      "(RayTrainWorker pid=235, ip=10.0.45.178) The boolean parameter 'some' has been replaced with a string parameter 'mode'.\n",
      "(RayTrainWorker pid=235, ip=10.0.45.178) Q, R = torch.qr(A, some)\n",
      "(RayTrainWorker pid=235, ip=10.0.45.178) should be replaced with\n",
      "(RayTrainWorker pid=235, ip=10.0.45.178) Q, R = torch.linalg.qr(A, 'reduced' if some else 'complete') (Triggered internally at ../aten/src/ATen/native/BatchLinearAlgebra.cpp:2349.)\n",
      "(RayTrainWorker pid=235, ip=10.0.45.178)   W = torch.qr(torch.FloatTensor(c, c).normal_())[0]\n",
      "(RayTrainWorker pid=235, ip=10.0.45.178) /home/ray/anaconda3/lib/python3.10/site-packages/torch/functional.py:1682: UserWarning: torch.lu is deprecated in favor of torch.linalg.lu_factor / torch.linalg.lu_factor_ex and will be removed in a future PyTorch release.\n",
      "(RayTrainWorker pid=235, ip=10.0.45.178) LU, pivots = torch.lu(A, compute_pivots)\n",
      "(RayTrainWorker pid=235, ip=10.0.45.178) should be replaced with\n",
      "(RayTrainWorker pid=235, ip=10.0.45.178) LU, pivots = torch.linalg.lu_factor(A, compute_pivots)\n",
      "(RayTrainWorker pid=235, ip=10.0.45.178) and\n",
      "(RayTrainWorker pid=235, ip=10.0.45.178) LU, pivots, info = torch.lu(A, compute_pivots, get_infos=True)\n",
      "(RayTrainWorker pid=235, ip=10.0.45.178) should be replaced with\n",
      "(RayTrainWorker pid=235, ip=10.0.45.178) LU, pivots, info = torch.linalg.lu_factor_ex(A, compute_pivots) (Triggered internally at ../aten/src/ATen/native/BatchLinearAlgebra.cpp:1915.)\n",
      "(RayTrainWorker pid=235, ip=10.0.45.178)   return torch._lu_with_info(A, pivot=pivot, check_errors=(not get_infos))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(RayTrainWorker pid=235, ip=10.0.45.178) Applying spectral norm to context encoder LSTM\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(RayTrainWorker pid=417, ip=10.0.17.31) 2023-03-07 16:20:06,289\tINFO train_loop_utils.py:307 -- Moving model to device: cuda:0\n",
      "(RayTrainWorker pid=235, ip=10.0.45.178) 2023-03-07 16:20:06,824\tINFO train_loop_utils.py:307 -- Moving model to device: cuda:0\n",
      "(RayTrainWorker pid=417, ip=10.0.17.31) 2023-03-07 16:20:08,136\tINFO train_loop_utils.py:367 -- Wrapping provided model in DistributedDataParallel.\n",
      "(RayTrainWorker pid=235, ip=10.0.45.178) 2023-03-07 16:20:09,592\tINFO train_loop_utils.py:367 -- Wrapping provided model in DistributedDataParallel.\n",
      "(RayTrainWorker pid=417, ip=10.0.17.31) /tmp/ray/session_2023-03-06_08-59-42_925397_141/runtime_resources/working_dir_files/_ray_pkg_ee2356972b78dbfda1fe20807a72a9e9/uberduck_ml_dev/exec/train_radtts_with_ray.py:492: UserWarning: The given NumPy array is not writable, and PyTorch does not support non-writable tensors. This means writing to this tensor will result in undefined behavior. You may want to copy the array to protect its data or make it writable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at ../torch/csrc/utils/tensor_numpy.cpp:199.)\n",
      "(RayTrainWorker pid=417, ip=10.0.17.31)   audio = torch.FloatTensor(wav_data)\n",
      "(RayTrainWorker pid=235, ip=10.0.45.178) /tmp/ray/session_2023-03-06_08-59-42_925397_141/runtime_resources/working_dir_files/_ray_pkg_ee2356972b78dbfda1fe20807a72a9e9/uberduck_ml_dev/exec/train_radtts_with_ray.py:492: UserWarning: The given NumPy array is not writable, and PyTorch does not support non-writable tensors. This means writing to this tensor will result in undefined behavior. You may want to copy the array to protect its data or make it writable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at ../torch/csrc/utils/tensor_numpy.cpp:199.)\n",
      "(RayTrainWorker pid=235, ip=10.0.45.178)   audio = torch.FloatTensor(wav_data)\n",
      "(RayTrainWorker pid=417, ip=10.0.17.31) /home/ray/anaconda3/lib/python3.10/site-packages/torch/nn/modules/rnn.py:777: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:968.)\n",
      "(RayTrainWorker pid=417, ip=10.0.17.31)   result = _VF.lstm(input, batch_sizes, hx, self._flat_weights, self.bias,\n",
      "(RayTrainWorker pid=235, ip=10.0.45.178) /home/ray/anaconda3/lib/python3.10/site-packages/torch/nn/modules/rnn.py:777: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:968.)\n",
      "(RayTrainWorker pid=235, ip=10.0.45.178)   result = _VF.lstm(input, batch_sizes, hx, self._flat_weights, self.bias,\n",
      "(RayTrainWorker pid=417, ip=10.0.17.31) /home/ray/anaconda3/lib/python3.10/site-packages/torch/autograd/__init__.py:197: UserWarning: Grad strides do not match bucket view strides. This may indicate grad was not created according to the gradient layout contract, or that the param's strides changed since DDP was constructed.  This is not an error, but may impair performance.\n",
      "(RayTrainWorker pid=417, ip=10.0.17.31) grad.sizes() = [1, 512], strides() = [1, 1]\n",
      "(RayTrainWorker pid=417, ip=10.0.17.31) bucket_view.sizes() = [1, 512], strides() = [512, 1] (Triggered internally at ../torch/csrc/distributed/c10d/reducer.cpp:325.)\n",
      "(RayTrainWorker pid=417, ip=10.0.17.31)   Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "(RayTrainWorker pid=235, ip=10.0.45.178) /home/ray/anaconda3/lib/python3.10/site-packages/torch/autograd/__init__.py:197: UserWarning: Grad strides do not match bucket view strides. This may indicate grad was not created according to the gradient layout contract, or that the param's strides changed since DDP was constructed.  This is not an error, but may impair performance.\n",
      "(RayTrainWorker pid=235, ip=10.0.45.178) grad.sizes() = [1, 512], strides() = [1, 1]\n",
      "(RayTrainWorker pid=235, ip=10.0.45.178) bucket_view.sizes() = [1, 512], strides() = [512, 1] (Triggered internally at ../torch/csrc/distributed/c10d/reducer.cpp:325.)\n",
      "(RayTrainWorker pid=235, ip=10.0.45.178)   Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(RayTrainWorker pid=235, ip=10.0.45.178) Loss: 66.75837707519531\n",
      "(RayTrainWorker pid=417, ip=10.0.17.31) Loss: 66.7209243774414\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(RayTrainWorker pid=235, ip=10.0.45.178) /home/ray/anaconda3/lib/python3.10/site-packages/torch/nn/modules/rnn.py:777: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:968.)\n",
      "(RayTrainWorker pid=235, ip=10.0.45.178)   result = _VF.lstm(input, batch_sizes, hx, self._flat_weights, self.bias,\n",
      "(RayTrainWorker pid=417, ip=10.0.17.31) /home/ray/anaconda3/lib/python3.10/site-packages/torch/nn/modules/rnn.py:777: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:968.)\n",
      "(RayTrainWorker pid=417, ip=10.0.17.31)   result = _VF.lstm(input, batch_sizes, hx, self._flat_weights, self.bias,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(RayTrainWorker pid=417, ip=10.0.17.31) Loss: 5.840334415435791\n",
      "(RayTrainWorker pid=235, ip=10.0.45.178) Loss: 5.75288200378418\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(RayTrainWorker pid=235, ip=10.0.45.178) /home/ray/anaconda3/lib/python3.10/site-packages/torch/nn/modules/rnn.py:777: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:968.)\n",
      "(RayTrainWorker pid=235, ip=10.0.45.178)   result = _VF.lstm(input, batch_sizes, hx, self._flat_weights, self.bias,\n",
      "(RayTrainWorker pid=417, ip=10.0.17.31) /home/ray/anaconda3/lib/python3.10/site-packages/torch/nn/modules/rnn.py:777: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:968.)\n",
      "(RayTrainWorker pid=417, ip=10.0.17.31)   result = _VF.lstm(input, batch_sizes, hx, self._flat_weights, self.bias,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(RayTrainWorker pid=417, ip=10.0.17.31) Loss: 5.8561625480651855\n",
      "(RayTrainWorker pid=235, ip=10.0.45.178) Loss: 5.837704658508301\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(RayTrainWorker pid=235, ip=10.0.45.178) /home/ray/anaconda3/lib/python3.10/site-packages/torch/nn/modules/rnn.py:777: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:968.)\n",
      "(RayTrainWorker pid=235, ip=10.0.45.178)   result = _VF.lstm(input, batch_sizes, hx, self._flat_weights, self.bias,\n",
      "(RayTrainWorker pid=417, ip=10.0.17.31) /home/ray/anaconda3/lib/python3.10/site-packages/torch/nn/modules/rnn.py:777: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:968.)\n",
      "(RayTrainWorker pid=417, ip=10.0.17.31)   result = _VF.lstm(input, batch_sizes, hx, self._flat_weights, self.bias,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(RayTrainWorker pid=235, ip=10.0.45.178) Loss: 5.733274459838867\n",
      "(RayTrainWorker pid=417, ip=10.0.17.31) Loss: 5.9500956535339355\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-03-07 16:23:53,988\tWARNING tune.py:150 -- Stop signal received (e.g. via SIGINT/Ctrl+C), ending Ray Tune run. This will try to checkpoint the experiment state one last time. Press CTRL+C (or send SIGINT/SIGKILL/SIGTERM) to skip. \n",
      "2023-03-07 16:23:56,613\tERROR tune.py:821 -- Trials did not complete: [TorchTrainer_d9af1_00000]\n",
      "2023-03-07 16:23:56,614\tINFO tune.py:825 -- Total run time: 285.09 seconds (283.31 seconds for the tuning loop).\n",
      "2023-03-07 16:23:56,614\tWARNING tune.py:831 -- Experiment has been interrupted, but the most recent state was saved. You can continue running this experiment by passing `resume=True` to `tune.run()`\n",
      "(TorchTrainer pid=5550, ip=10.0.46.245) 2023-03-07 16:23:56,616\tINFO utils.py:57 -- Worker 1 has failed.\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "011cda1c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b07e4975",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d677912c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\n",
    "        \"TORCH_DISTRIBUTED_DEBUG\"\n",
    "    ] = \"DETAIL\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "11bb47aa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div class=\"tuneStatus\">\n",
       "  <div style=\"display: flex;flex-direction: row\">\n",
       "    <div style=\"display: flex;flex-direction: column;\">\n",
       "      <h3>Tune Status</h3>\n",
       "      <table>\n",
       "<tbody>\n",
       "<tr><td>Current time:</td><td>2023-03-07 15:42:30</td></tr>\n",
       "<tr><td>Running for: </td><td>00:32:54.52        </td></tr>\n",
       "<tr><td>Memory:      </td><td>5.6/15.3 GiB       </td></tr>\n",
       "</tbody>\n",
       "</table>\n",
       "    </div>\n",
       "    <div class=\"vDivider\"></div>\n",
       "    <div class=\"systemInfo\">\n",
       "      <h3>System Info</h3>\n",
       "      Using FIFO scheduling algorithm.<br>Resources requested: 0/24 CPUs, 0/2 GPUs, 0.0/61.09 GiB heap, 0.0/26.77 GiB objects (0.0/2.0 accelerator_type:T4)\n",
       "    </div>\n",
       "    <div class=\"vDivider\"></div>\n",
       "<div class=\"messages\">\n",
       "  <h3>Messages</h3>\n",
       "  \n",
       "  \n",
       "  Number of errored trials: 1<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name              </th><th style=\"text-align: right;\">  # failures</th><th>error file                                                                                                     </th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>TorchTrainer_209d8_00000</td><td style=\"text-align: right;\">           1</td><td>/home/ray/ray_results/TorchTrainer_2023-03-07_15-09-35/TorchTrainer_209d8_00000_0_2023-03-07_15-09-37/error.txt</td></tr>\n",
       "</tbody>\n",
       "</table>\n",
       "</div>\n",
       "<style>\n",
       ".messages {\n",
       "  color: var(--jp-ui-font-color1);\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "  padding-left: 1em;\n",
       "  overflow-y: auto;\n",
       "}\n",
       ".messages h3 {\n",
       "  font-weight: bold;\n",
       "}\n",
       ".vDivider {\n",
       "  border-left-width: var(--jp-border-width);\n",
       "  border-left-color: var(--jp-border-color0);\n",
       "  border-left-style: solid;\n",
       "  margin: 0.5em 1em 0.5em 1em;\n",
       "}\n",
       "</style>\n",
       "\n",
       "  </div>\n",
       "  <div class=\"hDivider\"></div>\n",
       "  <div class=\"trialStatus\">\n",
       "    <h3>Trial Status</h3>\n",
       "    <table>\n",
       "<thead>\n",
       "<tr><th>Trial name              </th><th>status  </th><th>loc            </th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>TorchTrainer_209d8_00000</td><td>ERROR   </td><td>10.0.48.48:3738</td></tr>\n",
       "</tbody>\n",
       "</table>\n",
       "  </div>\n",
       "</div>\n",
       "<style>\n",
       ".tuneStatus {\n",
       "  color: var(--jp-ui-font-color1);\n",
       "}\n",
       ".tuneStatus .systemInfo {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       ".tuneStatus td {\n",
       "  white-space: nowrap;\n",
       "}\n",
       ".tuneStatus .trialStatus {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       ".tuneStatus h3 {\n",
       "  font-weight: bold;\n",
       "}\n",
       ".tuneStatus .hDivider {\n",
       "  border-bottom-width: var(--jp-border-width);\n",
       "  border-bottom-color: var(--jp-border-color0);\n",
       "  border-bottom-style: solid;\n",
       "}\n",
       ".tuneStatus .vDivider {\n",
       "  border-left-width: var(--jp-border-width);\n",
       "  border-left-color: var(--jp-border-color0);\n",
       "  border-left-style: solid;\n",
       "  margin: 0.5em 1em 0.5em 1em;\n",
       "}\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(RayTrainWorker pid=303, ip=10.0.5.7) 2023-03-07 15:09:46,491\tINFO config.py:86 -- Setting up process group for: env:// [rank=0, world_size=2]\n",
      "(TorchTrainer pid=3738, ip=10.0.48.48) 2023-03-07 15:09:46,610\tINFO bulk_executor.py:41 -- Executing DAG InputDataBuffer[Input] -> TaskPoolMapOperator[MapBatches(<lambda>)] -> AllToAllOperator[zip] -> AllToAllOperator[zip] -> AllToAllOperator[zip] -> TaskPoolMapOperator[MapBatches(<lambda>)] -> AllToAllOperator[randomize_block_order]\n",
      "(TorchTrainer pid=3738, ip=10.0.48.48) 2023-03-07 15:09:49,880\tINFO bulk_executor.py:41 -- Executing DAG InputDataBuffer[Input] -> TaskPoolMapOperator[read] -> TaskPoolMapOperator[MapBatches(<lambda>)]\n",
      "(TorchTrainer pid=3738, ip=10.0.48.48) 2023-03-07 15:09:55,809\tWARNING plan.py:528 -- Warning: The Ray cluster currently does not have any available CPUs. The Dataset job will hang unless more CPUs are freed up. A common reason is that cluster resources are used by Actors or Tune trials; see the following link for more details: https://docs.ray.io/en/master/data/dataset-internals.html#datasets-and-tune\n",
      "(TorchTrainer pid=3738, ip=10.0.48.48) 2023-03-07 15:09:55,809\tINFO bulk_executor.py:41 -- Executing DAG InputDataBuffer[Input] -> TaskPoolMapOperator[MapBatches(<lambda>)]\n",
      "(TorchTrainer pid=3738, ip=10.0.48.48) 2023-03-07 15:09:55,955\tINFO bulk_executor.py:41 -- Executing DAG InputDataBuffer[Input] -> TaskPoolMapOperator[MapBatches(<lambda>)]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(autoscaler +26s) Tip: use `ray status` to view detailed cluster status. To disable these messages, set RAY_SCHEDULER_EVENTS=0.\n",
      "(autoscaler +26s) Adding 5 node(s) of type worker-node-type-0.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(TorchTrainer pid=3738, ip=10.0.48.48) /home/ray/anaconda3/lib/python3.10/site-packages/ray/train/_internal/dataset_iterator.py:64: UserWarning: session.get_dataset_shard returns a ray.data.DatasetIterator instead of a Dataset/DatasetPipeline as of Ray v2.3. Use iter_torch_batches(), to_tf(), or iter_batches() to iterate over one epoch. See https://docs.ray.io/en/latest/data/api/dataset_iterator.html for full DatasetIterator docs.\n",
      "(TorchTrainer pid=3738, ip=10.0.48.48)   warnings.warn(\n",
      "(RayTrainWorker pid=1124519) wandb: Currently logged in as: uberduck. Use `wandb login --relogin` to force relogin\n",
      "(RayTrainWorker pid=303, ip=10.0.5.7) wandb: Currently logged in as: uberduck. Use `wandb login --relogin` to force relogin\n",
      "(RayTrainWorker pid=1124519) wandb: wandb version 0.13.11 is available!  To upgrade, please run:\n",
      "(RayTrainWorker pid=1124519) wandb:  $ pip install wandb --upgrade\n",
      "(RayTrainWorker pid=1124519) wandb: Tracking run with wandb version 0.13.10\n",
      "(RayTrainWorker pid=1124519) wandb: Run data is saved locally in /home/ray/ray_results/TorchTrainer_2023-03-07_15-09-35/TorchTrainer_209d8_00000_0_2023-03-07_15-09-37/rank_1/wandb/run-20230307_151001-209d8_00000\n",
      "(RayTrainWorker pid=1124519) wandb: Run `wandb offline` to turn off syncing.\n",
      "(RayTrainWorker pid=1124519) wandb: Syncing run TorchTrainer_209d8_00000\n",
      "(RayTrainWorker pid=1124519) wandb: ‚≠êÔ∏è View project at https://wandb.ai/uberduck/radtts-ray\n",
      "(RayTrainWorker pid=1124519) wandb: üöÄ View run at https://wandb.ai/uberduck/radtts-ray/runs/209d8_00000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(RayTrainWorker pid=1124519) CUDA AVAILABLE:  True\n",
      "(RayTrainWorker pid=1124519) Applying spectral norm to text encoder LSTM\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(RayTrainWorker pid=1124519) /tmp/ray/session_2023-03-06_08-59-42_925397_141/runtime_resources/working_dir_files/_ray_pkg_eccc6979c79037b7d167507f1405cae4/uberduck_ml_dev/models/common.py:1516: UserWarning: torch.qr is deprecated in favor of torch.linalg.qr and will be removed in a future PyTorch release.\n",
      "(RayTrainWorker pid=1124519) The boolean parameter 'some' has been replaced with a string parameter 'mode'.\n",
      "(RayTrainWorker pid=1124519) Q, R = torch.qr(A, some)\n",
      "(RayTrainWorker pid=1124519) should be replaced with\n",
      "(RayTrainWorker pid=1124519) Q, R = torch.linalg.qr(A, 'reduced' if some else 'complete') (Triggered internally at ../aten/src/ATen/native/BatchLinearAlgebra.cpp:2349.)\n",
      "(RayTrainWorker pid=1124519)   W = torch.qr(torch.FloatTensor(c, c).normal_())[0]\n",
      "(RayTrainWorker pid=1124519) /home/ray/anaconda3/lib/python3.10/site-packages/torch/functional.py:1682: UserWarning: torch.lu is deprecated in favor of torch.linalg.lu_factor / torch.linalg.lu_factor_ex and will be removed in a future PyTorch release.\n",
      "(RayTrainWorker pid=1124519) LU, pivots = torch.lu(A, compute_pivots)\n",
      "(RayTrainWorker pid=1124519) should be replaced with\n",
      "(RayTrainWorker pid=1124519) LU, pivots = torch.linalg.lu_factor(A, compute_pivots)\n",
      "(RayTrainWorker pid=1124519) and\n",
      "(RayTrainWorker pid=1124519) LU, pivots, info = torch.lu(A, compute_pivots, get_infos=True)\n",
      "(RayTrainWorker pid=1124519) should be replaced with\n",
      "(RayTrainWorker pid=1124519) LU, pivots, info = torch.linalg.lu_factor_ex(A, compute_pivots) (Triggered internally at ../aten/src/ATen/native/BatchLinearAlgebra.cpp:1915.)\n",
      "(RayTrainWorker pid=1124519)   return torch._lu_with_info(A, pivot=pivot, check_errors=(not get_infos))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(RayTrainWorker pid=1124519) Applying spectral norm to context encoder LSTM\n",
      "(RayTrainWorker pid=303, ip=10.0.5.7) CUDA AVAILABLE:  True\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(RayTrainWorker pid=303, ip=10.0.5.7) wandb: wandb version 0.13.11 is available!  To upgrade, please run:\n",
      "(RayTrainWorker pid=303, ip=10.0.5.7) wandb:  $ pip install wandb --upgrade\n",
      "(RayTrainWorker pid=303, ip=10.0.5.7) wandb: Tracking run with wandb version 0.13.10\n",
      "(RayTrainWorker pid=303, ip=10.0.5.7) wandb: Run data is saved locally in /home/ray/ray_results/TorchTrainer_2023-03-07_15-09-35/TorchTrainer_209d8_00000_0_2023-03-07_15-09-37/rank_0/wandb/run-20230307_151002-209d8_00000\n",
      "(RayTrainWorker pid=303, ip=10.0.5.7) wandb: Run `wandb offline` to turn off syncing.\n",
      "(RayTrainWorker pid=303, ip=10.0.5.7) wandb: Syncing run TorchTrainer_209d8_00000\n",
      "(RayTrainWorker pid=303, ip=10.0.5.7) wandb: ‚≠êÔ∏è View project at https://wandb.ai/uberduck/radtts-ray\n",
      "(RayTrainWorker pid=303, ip=10.0.5.7) wandb: üöÄ View run at https://wandb.ai/uberduck/radtts-ray/runs/209d8_00000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(RayTrainWorker pid=303, ip=10.0.5.7) Applying spectral norm to text encoder LSTM\n",
      "(RayTrainWorker pid=303, ip=10.0.5.7) Applying spectral norm to context encoder LSTM\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(RayTrainWorker pid=303, ip=10.0.5.7) /tmp/ray/session_2023-03-06_08-59-42_925397_141/runtime_resources/working_dir_files/_ray_pkg_eccc6979c79037b7d167507f1405cae4/uberduck_ml_dev/models/common.py:1516: UserWarning: torch.qr is deprecated in favor of torch.linalg.qr and will be removed in a future PyTorch release.\n",
      "(RayTrainWorker pid=303, ip=10.0.5.7) The boolean parameter 'some' has been replaced with a string parameter 'mode'.\n",
      "(RayTrainWorker pid=303, ip=10.0.5.7) Q, R = torch.qr(A, some)\n",
      "(RayTrainWorker pid=303, ip=10.0.5.7) should be replaced with\n",
      "(RayTrainWorker pid=303, ip=10.0.5.7) Q, R = torch.linalg.qr(A, 'reduced' if some else 'complete') (Triggered internally at ../aten/src/ATen/native/BatchLinearAlgebra.cpp:2349.)\n",
      "(RayTrainWorker pid=303, ip=10.0.5.7)   W = torch.qr(torch.FloatTensor(c, c).normal_())[0]\n",
      "(RayTrainWorker pid=303, ip=10.0.5.7) /home/ray/anaconda3/lib/python3.10/site-packages/torch/functional.py:1682: UserWarning: torch.lu is deprecated in favor of torch.linalg.lu_factor / torch.linalg.lu_factor_ex and will be removed in a future PyTorch release.\n",
      "(RayTrainWorker pid=303, ip=10.0.5.7) LU, pivots = torch.lu(A, compute_pivots)\n",
      "(RayTrainWorker pid=303, ip=10.0.5.7) should be replaced with\n",
      "(RayTrainWorker pid=303, ip=10.0.5.7) LU, pivots = torch.linalg.lu_factor(A, compute_pivots)\n",
      "(RayTrainWorker pid=303, ip=10.0.5.7) and\n",
      "(RayTrainWorker pid=303, ip=10.0.5.7) LU, pivots, info = torch.lu(A, compute_pivots, get_infos=True)\n",
      "(RayTrainWorker pid=303, ip=10.0.5.7) should be replaced with\n",
      "(RayTrainWorker pid=303, ip=10.0.5.7) LU, pivots, info = torch.linalg.lu_factor_ex(A, compute_pivots) (Triggered internally at ../aten/src/ATen/native/BatchLinearAlgebra.cpp:1915.)\n",
      "(RayTrainWorker pid=303, ip=10.0.5.7)   return torch._lu_with_info(A, pivot=pivot, check_errors=(not get_infos))\n",
      "(RayTrainWorker pid=1124519) 2023-03-07 15:10:19,948\tINFO train_loop_utils.py:307 -- Moving model to device: cuda:0\n",
      "(RayTrainWorker pid=303, ip=10.0.5.7) 2023-03-07 15:10:20,219\tINFO train_loop_utils.py:307 -- Moving model to device: cuda:0\n",
      "(RayTrainWorker pid=1124519) 2023-03-07 15:10:21,843\tINFO train_loop_utils.py:367 -- Wrapping provided model in DistributedDataParallel.\n",
      "(RayTrainWorker pid=303, ip=10.0.5.7) 2023-03-07 15:10:22,005\tINFO train_loop_utils.py:367 -- Wrapping provided model in DistributedDataParallel.\n",
      "(RayTrainWorker pid=1124519) /tmp/ray/session_2023-03-06_08-59-42_925397_141/runtime_resources/working_dir_files/_ray_pkg_eccc6979c79037b7d167507f1405cae4/uberduck_ml_dev/exec/train_radtts_with_ray.py:492: UserWarning: The given NumPy array is not writable, and PyTorch does not support non-writable tensors. This means writing to this tensor will result in undefined behavior. You may want to copy the array to protect its data or make it writable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at ../torch/csrc/utils/tensor_numpy.cpp:199.)\n",
      "(RayTrainWorker pid=1124519)   audio = torch.FloatTensor(wav_data)\n",
      "(RayTrainWorker pid=303, ip=10.0.5.7) /tmp/ray/session_2023-03-06_08-59-42_925397_141/runtime_resources/working_dir_files/_ray_pkg_eccc6979c79037b7d167507f1405cae4/uberduck_ml_dev/exec/train_radtts_with_ray.py:492: UserWarning: The given NumPy array is not writable, and PyTorch does not support non-writable tensors. This means writing to this tensor will result in undefined behavior. You may want to copy the array to protect its data or make it writable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at ../torch/csrc/utils/tensor_numpy.cpp:199.)\n",
      "(RayTrainWorker pid=303, ip=10.0.5.7)   audio = torch.FloatTensor(wav_data)\n",
      "(RayTrainWorker pid=303, ip=10.0.5.7) /home/ray/anaconda3/lib/python3.10/site-packages/torch/nn/modules/rnn.py:777: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:968.)\n",
      "(RayTrainWorker pid=303, ip=10.0.5.7)   result = _VF.lstm(input, batch_sizes, hx, self._flat_weights, self.bias,\n",
      "(raylet, ip=10.0.14.59) /home/ray/anaconda3/lib/python3.10/site-packages/ray/dashboard/agent.py:51: DeprecationWarning: There is no current event loop\n",
      "(raylet, ip=10.0.14.59)   aiogrpc.init_grpc_aio()\n",
      "(raylet, ip=10.0.12.220) /home/ray/anaconda3/lib/python3.10/site-packages/ray/dashboard/agent.py:51: DeprecationWarning: There is no current event loop\n",
      "(raylet, ip=10.0.12.220)   aiogrpc.init_grpc_aio()\n",
      "(raylet, ip=10.0.57.173) /home/ray/anaconda3/lib/python3.10/site-packages/ray/dashboard/agent.py:51: DeprecationWarning: There is no current event loop\n",
      "(raylet, ip=10.0.57.173)   aiogrpc.init_grpc_aio()\n",
      "(RayTrainWorker pid=1124519) /home/ray/anaconda3/lib/python3.10/site-packages/torch/nn/modules/rnn.py:777: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:968.)\n",
      "(RayTrainWorker pid=1124519)   result = _VF.lstm(input, batch_sizes, hx, self._flat_weights, self.bias,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(autoscaler +1m22s) Resized to 136 CPUs, 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(raylet, ip=10.0.21.18) /home/ray/anaconda3/lib/python3.10/site-packages/ray/dashboard/agent.py:51: DeprecationWarning: There is no current event loop\n",
      "(raylet, ip=10.0.21.18)   aiogrpc.init_grpc_aio()\n",
      "(raylet, ip=10.0.55.4) /home/ray/anaconda3/lib/python3.10/site-packages/ray/dashboard/agent.py:51: DeprecationWarning: There is no current event loop\n",
      "(raylet, ip=10.0.55.4)   aiogrpc.init_grpc_aio()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(RayTrainWorker pid=303, ip=10.0.5.7) Loss: 66.58922576904297\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(RayTrainWorker pid=303, ip=10.0.5.7) /home/ray/anaconda3/lib/python3.10/site-packages/torch/autograd/__init__.py:197: UserWarning: Grad strides do not match bucket view strides. This may indicate grad was not created according to the gradient layout contract, or that the param's strides changed since DDP was constructed.  This is not an error, but may impair performance.\n",
      "(RayTrainWorker pid=303, ip=10.0.5.7) grad.sizes() = [1, 512], strides() = [1, 1]\n",
      "(RayTrainWorker pid=303, ip=10.0.5.7) bucket_view.sizes() = [1, 512], strides() = [512, 1] (Triggered internally at ../torch/csrc/distributed/c10d/reducer.cpp:325.)\n",
      "(RayTrainWorker pid=303, ip=10.0.5.7)   Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "(RayTrainWorker pid=303, ip=10.0.5.7) /home/ray/anaconda3/lib/python3.10/site-packages/torch/optim/lr_scheduler.py:138: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\n",
      "(RayTrainWorker pid=303, ip=10.0.5.7)   warnings.warn(\"Detected call of `lr_scheduler.step()` before `optimizer.step()`. \"\n",
      "(RayTrainWorker pid=1124519) /home/ray/anaconda3/lib/python3.10/site-packages/torch/autograd/__init__.py:197: UserWarning: Grad strides do not match bucket view strides. This may indicate grad was not created according to the gradient layout contract, or that the param's strides changed since DDP was constructed.  This is not an error, but may impair performance.\n",
      "(RayTrainWorker pid=1124519) grad.sizes() = [1, 512], strides() = [1, 1]\n",
      "(RayTrainWorker pid=1124519) bucket_view.sizes() = [1, 512], strides() = [512, 1] (Triggered internally at ../torch/csrc/distributed/c10d/reducer.cpp:325.)\n",
      "(RayTrainWorker pid=1124519)   Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "(RayTrainWorker pid=1124519) /home/ray/anaconda3/lib/python3.10/site-packages/torch/optim/lr_scheduler.py:138: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\n",
      "(RayTrainWorker pid=1124519)   warnings.warn(\"Detected call of `lr_scheduler.step()` before `optimizer.step()`. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(RayTrainWorker pid=1124519) Loss: 66.71593475341797\n",
      "(autoscaler +1m26s) Resized to 184 CPUs, 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(RayTrainWorker pid=1124519) /home/ray/anaconda3/lib/python3.10/site-packages/torch/nn/modules/rnn.py:777: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:968.)\n",
      "(RayTrainWorker pid=1124519)   result = _VF.lstm(input, batch_sizes, hx, self._flat_weights, self.bias,\n",
      "(RayTrainWorker pid=303, ip=10.0.5.7) /home/ray/anaconda3/lib/python3.10/site-packages/torch/nn/modules/rnn.py:777: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:968.)\n",
      "(RayTrainWorker pid=303, ip=10.0.5.7)   result = _VF.lstm(input, batch_sizes, hx, self._flat_weights, self.bias,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(RayTrainWorker pid=303, ip=10.0.5.7) Loss: 66.75285339355469\n",
      "(RayTrainWorker pid=1124519) Loss: 66.76640319824219\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(RayTrainWorker pid=1124519) /home/ray/anaconda3/lib/python3.10/site-packages/torch/nn/modules/rnn.py:777: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:968.)\n",
      "(RayTrainWorker pid=1124519)   result = _VF.lstm(input, batch_sizes, hx, self._flat_weights, self.bias,\n",
      "(RayTrainWorker pid=303, ip=10.0.5.7) /home/ray/anaconda3/lib/python3.10/site-packages/torch/nn/modules/rnn.py:777: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:968.)\n",
      "(RayTrainWorker pid=303, ip=10.0.5.7)   result = _VF.lstm(input, batch_sizes, hx, self._flat_weights, self.bias,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(RayTrainWorker pid=303, ip=10.0.5.7) Loss: 66.75389099121094\n",
      "(RayTrainWorker pid=1124519) Loss: 66.77154541015625\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(RayTrainWorker pid=303, ip=10.0.5.7) /home/ray/anaconda3/lib/python3.10/site-packages/torch/nn/modules/rnn.py:777: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:968.)\n",
      "(RayTrainWorker pid=303, ip=10.0.5.7)   result = _VF.lstm(input, batch_sizes, hx, self._flat_weights, self.bias,\n",
      "(RayTrainWorker pid=1124519) /home/ray/anaconda3/lib/python3.10/site-packages/torch/nn/modules/rnn.py:777: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:968.)\n",
      "(RayTrainWorker pid=1124519)   result = _VF.lstm(input, batch_sizes, hx, self._flat_weights, self.bias,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(RayTrainWorker pid=303, ip=10.0.5.7) Loss: 66.65056610107422\n",
      "(RayTrainWorker pid=1124519) Loss: 66.45819854736328\n",
      "(autoscaler +6m24s) Removing 2 nodes of type worker-node-type-0 (idle).\n",
      "(autoscaler +6m28s) Removing 5 nodes of type worker-node-type-0 (idle).\n",
      "(autoscaler +6m34s) Removing 5 nodes of type worker-node-type-0 (idle).\n",
      "(autoscaler +6m38s) Removing 5 nodes of type worker-node-type-0 (idle).\n",
      "(autoscaler +6m44s) Removing 5 nodes of type worker-node-type-0 (idle).\n",
      "(autoscaler +6m48s) Removing 5 nodes of type worker-node-type-0 (idle).\n",
      "(autoscaler +6m54s) Removing 5 nodes of type worker-node-type-0 (idle).\n",
      "(autoscaler +6m59s) Removing 5 nodes of type worker-node-type-0 (idle).\n",
      "(autoscaler +7m4s) Removing 5 nodes of type worker-node-type-0 (idle).\n",
      "(autoscaler +7m8s) Removing 5 nodes of type worker-node-type-0 (idle).\n",
      "(autoscaler +7m14s) Removing 5 nodes of type worker-node-type-0 (idle).\n",
      "(autoscaler +7m18s) Removing 5 nodes of type worker-node-type-0 (idle).\n",
      "(autoscaler +7m24s) Removing 5 nodes of type worker-node-type-0 (idle).\n",
      "(autoscaler +7m29s) Removing 5 nodes of type worker-node-type-0 (idle).\n",
      "(autoscaler +7m34s) Removing 5 nodes of type worker-node-type-0 (idle).\n",
      "(autoscaler +7m39s) Removing 5 nodes of type worker-node-type-0 (idle).\n",
      "(autoscaler +7m44s) Removing 5 nodes of type worker-node-type-0 (idle).\n",
      "(autoscaler +7m49s) Removing 5 nodes of type worker-node-type-0 (idle).\n",
      "(autoscaler +7m54s) Removing 5 nodes of type worker-node-type-0 (idle).\n",
      "(autoscaler +7m59s) Removing 1 nodes of type worker-node-type-0 (idle).\n",
      "(autoscaler +8m4s) Resized to 120 CPUs, 2 GPUs.\n",
      "(autoscaler +8m4s) Removing 1 nodes of type worker-node-type-0 (idle).\n",
      "(autoscaler +8m9s) Removing 1 nodes of type worker-node-type-0 (idle).\n",
      "(autoscaler +8m14s) Removing 1 nodes of type worker-node-type-0 (idle).\n",
      "(autoscaler +8m19s) Removing 1 nodes of type worker-node-type-0 (idle).\n",
      "(autoscaler +8m25s) Removing 1 nodes of type worker-node-type-0 (idle).\n",
      "(autoscaler +8m35s) Resized to 104 CPUs, 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(RayTrainWorker pid=1124519) [E ProcessGroupNCCL.cpp:821] [Rank 1] Watchdog caught collective operation timeout: WorkNCCL(SeqNum=123, OpType=BROADCAST, Timeout(ms)=1800000) ran for 1800693 milliseconds before timing out.\n",
      "(RayTrainWorker pid=1124519) [E ProcessGroupNCCL.cpp:456] Some NCCL operations have failed or timed out. Due to the asynchronous nature of CUDA kernels, subsequent GPU operations might run on corrupted/incomplete data.\n",
      "(RayTrainWorker pid=1124519) [E ProcessGroupNCCL.cpp:461] To avoid data inconsistency, we are taking the entire process down.\n",
      "(RayTrainWorker pid=1124519) [2023-03-07 15:42:17,362 E 1124519 1124595] logging.cc:97: Unhandled exception: St13runtime_error. what(): [Rank 1] Watchdog caught collective operation timeout: WorkNCCL(SeqNum=123, OpType=BROADCAST, Timeout(ms)=1800000) ran for 1800693 milliseconds before timing out.\n",
      "(RayTrainWorker pid=1124519) /home/ray/anaconda3/lib/python3.10/site-packages/torch/nn/modules/rnn.py:777: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:968.)\n",
      "(RayTrainWorker pid=1124519)   result = _VF.lstm(input, batch_sizes, hx, self._flat_weights, self.bias,\n",
      "(RayTrainWorker pid=1124519) [2023-03-07 15:42:17,404 E 1124519 1124595] logging.cc:104: Stack trace: \n",
      "(RayTrainWorker pid=1124519)  /home/ray/anaconda3/lib/python3.10/site-packages/ray/_raylet.so(+0xd5105a) [0x7faa7d9ff05a] ray::operator<<()\n",
      "(RayTrainWorker pid=1124519) /home/ray/anaconda3/lib/python3.10/site-packages/ray/_raylet.so(+0xd53818) [0x7faa7da01818] ray::TerminateHandler()\n",
      "(RayTrainWorker pid=1124519) /home/ray/anaconda3/bin/../lib/libstdc++.so.6(+0xb135a) [0x7faa7cb4135a] __cxxabiv1::__terminate()\n",
      "(RayTrainWorker pid=1124519) /home/ray/anaconda3/bin/../lib/libstdc++.so.6(+0xb13c5) [0x7faa7cb413c5]\n",
      "(RayTrainWorker pid=1124519) /home/ray/anaconda3/bin/../lib/libstdc++.so.6(+0xb134f) [0x7faa7cb4134f]\n",
      "(RayTrainWorker pid=1124519) /home/ray/anaconda3/lib/python3.10/site-packages/torch/lib/libtorch_cuda_cpp.so(_ZN4c10d16ProcessGroupNCCL8WorkNCCL15handleNCCLGuardENS_17ErrorHandlingModeE+0x278) [0x7fa8b398f8b8] c10d::ProcessGroupNCCL::WorkNCCL::handleNCCLGuard()\n",
      "(RayTrainWorker pid=1124519) /home/ray/anaconda3/lib/python3.10/site-packages/torch/lib/libtorch_cuda_cpp.so(_ZN4c10d16ProcessGroupNCCL15workCleanupLoopEv+0x19f) [0x7fa8b39938cf] c10d::ProcessGroupNCCL::workCleanupLoop()\n",
      "(RayTrainWorker pid=1124519) /home/ray/anaconda3/bin/../lib/libstdc++.so.6(+0xdbbf4) [0x7faa7cb6bbf4] execute_native_thread_routine\n",
      "(RayTrainWorker pid=1124519) /usr/lib/x86_64-linux-gnu/libpthread.so.0(+0x8609) [0x7faa7e7e0609] start_thread\n",
      "(RayTrainWorker pid=1124519) /usr/lib/x86_64-linux-gnu/libc.so.6(clone+0x43) [0x7faa7e5ab133] __clone\n",
      "(RayTrainWorker pid=1124519) \n",
      "(RayTrainWorker pid=1124519) *** SIGABRT received at time=1678232537 on cpu 2 ***\n",
      "(RayTrainWorker pid=1124519) PC: @     0x7faa7e4cf00b  (unknown)  raise\n",
      "(RayTrainWorker pid=1124519)     @     0x7faa7e7ec420       4016  (unknown)\n",
      "(RayTrainWorker pid=1124519)     @     0x7faa7cb4135a  (unknown)  __cxxabiv1::__terminate()\n",
      "(RayTrainWorker pid=1124519)     @     0x7faa7cb41070  (unknown)  (unknown)\n",
      "(RayTrainWorker pid=1124519) [2023-03-07 15:42:17,406 E 1124519 1124595] logging.cc:361: *** SIGABRT received at time=1678232537 on cpu 2 ***\n",
      "(RayTrainWorker pid=1124519) [2023-03-07 15:42:17,406 E 1124519 1124595] logging.cc:361: PC: @     0x7faa7e4cf00b  (unknown)  raise\n",
      "(RayTrainWorker pid=1124519) [2023-03-07 15:42:17,406 E 1124519 1124595] logging.cc:361:     @     0x7faa7e7ec420       4016  (unknown)\n",
      "(RayTrainWorker pid=1124519) [2023-03-07 15:42:17,406 E 1124519 1124595] logging.cc:361:     @     0x7faa7cb4135a  (unknown)  __cxxabiv1::__terminate()\n",
      "(RayTrainWorker pid=1124519) [2023-03-07 15:42:17,406 E 1124519 1124595] logging.cc:361:     @     0x7faa7cb41070  (unknown)  (unknown)\n",
      "(RayTrainWorker pid=1124519) Fatal Python error: Aborted\n",
      "(RayTrainWorker pid=1124519) \n",
      "(RayTrainWorker pid=1124519) \n",
      "(RayTrainWorker pid=1124519) Extension modules: msgpack._cmsgpack, setproctitle, google.protobuf.pyext._message, psutil._psutil_linux, psutil._psutil_posix, grpc._cython.cygrpc, numpy.core._multiarray_umath, numpy.core._multiarray_tests, numpy.linalg._umath_linalg, numpy.fft._pocketfft_internal, numpy.random._common, numpy.random.bit_generator, numpy.random._bounded_integers, numpy.random._mt19937, numpy.random.mtrand, numpy.random._philox, numpy.random._pcg64, numpy.random._sfc64, numpy.random._generator, yaml._yaml, ray._raylet, _cffi_backend, charset_normalizer.md, lz4._version, lz4.frame._frame, zstandard.backend_c, pyarrow.lib, pyarrow._hdfsio, pyarrow._fs, pyarrow._hdfs, pyarrow._gcsfs, pyarrow._s3fs, pandas._libs.tslibs.np_datetime, pandas._libs.tslibs.dtypes, pandas._libs.tslibs.base, pandas._libs.tslibs.nattype, pandas._libs.tslibs.timezones, pandas._libs.tslibs.tzconversion, pandas._libs.tslibs.ccalendar, pandas._libs.tslibs.fields, pandas._libs.tslibs.timedeltas, pandas._libs.tslibs.timestamps, pandas._libs.properties, pandas._libs.tslibs.offsets, pandas._libs.tslibs.parsing, pandas._libs.tslibs.conversion, pandas._libs.tslibs.period, pandas._libs.tslibs.vectorized, pandas._libs.ops_dispatch, pandas._libs.missing, pandas._libs.hashtable, pandas._libs.algos, pandas._libs.interval, pandas._libs.tslib, pandas._libs.lib, pandas._libs.hashing, pandas._libs.ops, pyarrow._compute, pandas._libs.arrays, pandas._libs.index, pandas._libs.join, pandas._libs.sparse, pandas._libs.reduction, pandas._libs.indexing, pandas._libs.internals, pandas._libs.writers, pandas._libs.window.aggregations, pandas._libs.window.indexers, pandas._libs.reshape, pandas._libs.tslibs.strptime, pandas._libs.groupby, pandas._libs.testing, pandas._libs.parsers, pandas._libs.json, pydantic.typing, pydantic.errors, pydantic.version, pydantic.utils, pydantic.class_validators, pydantic.config, pydantic.color, pydantic.datetime_parse, pydantic.validators, pydantic.networks, pydantic.types, pydantic.json, pydantic.error_wrappers, pydantic.fields, pydantic.parse, pydantic.schema, pydantic.main, pydantic.dataclasses, pydantic.annotated_types, pydantic.decorator, pydantic.env_settings, pydantic.tools, pydantic, pyarrow._json, torch._C, torch._C._fft, torch._C._linalg, torch._C._nested, torch._C._nn, torch._C._sparse, torch._C._special, scipy._lib._ccallback_c, scipy.sparse._sparsetools, _csparsetools, scipy.sparse._csparsetools, scipy.sparse.linalg._isolve._iterative, scipy.linalg._fblas, scipy.linalg._flapack, scipy.linalg._cythonized_array_utils, scipy.linalg._flinalg, scipy.linalg._solve_toeplitz, scipy.linalg._matfuncs_sqrtm_triu, scipy.linalg.cython_lapack\n",
      "(RayTrainWorker pid=1124519) , scipy.linalg.cython_blas\n",
      "(RayTrainWorker pid=1124519) , scipy.linalg._matfuncs_expm, scipy.linalg._decomp_update, scipy.sparse.linalg._dsolve._superlu, scipy.sparse.linalg._eigen.arpack._arpack, scipy.sparse.csgraph._tools, scipy.sparse.csgraph._shortest_path, scipy.sparse.csgraph._traversal, scipy.sparse.csgraph._min_spanning_tree, scipy.sparse.csgraph._flow, scipy.sparse.csgraph._matching, scipy.sparse.csgraph._reordering, scipy.io.matlab._mio_utils, scipy.io.matlab._streams, scipy.io.matlab._mio5_utils, scipy.signal._sigtools, scipy.special._ufuncs_cxx, scipy.special._ufuncs, scipy.special._specfun, scipy.special._comb, scipy.special._ellip_harm_2, scipy._lib._uarray._uarray, scipy.signal._max_len_seq_inner, scipy.signal._upfirdn_apply, scipy.signal._spline, scipy.optimize._minpack2, scipy.optimize._group_columns, scipy._lib.messagestream, scipy.optimize._trlib._trlib, numpy.linalg.lapack_lite, scipy.optimize._lbfgsb, _moduleTNC, scipy.optimize._moduleTNC, scipy.optimize._cobyla, scipy.optimize._slsqp, scipy.optimize._minpack, scipy.optimize._lsq.givens_elimination, scipy.optimize._zeros, scipy.optimize.__nnls, scipy.optimize._highs.cython.src._highs_wrapper, scipy.optimize._highs._highs_wrapper, scipy.optimize._highs.cython.src._highs_constants, scipy.optimize._highs._highs_constants, scipy.linalg._interpolative, scipy.optimize._bglu_dense, scipy.optimize._lsap, scipy.spatial._ckdtree, scipy.spatial._qhull, scipy.spatial._voronoi, scipy.spatial._distance_wrap, scipy.spatial._hausdorff, scipy.spatial.transform._rotation, scipy.optimize._direct, scipy.integrate._odepack, scipy.integrate._quadpack, scipy.integrate._vode, scipy.integrate._dop, scipy.integrate._lsoda, scipy.interpolate._fitpack, scipy.interpolate.dfitpack, scipy.interpolate._bspl, scipy.interpolate._ppoly, scipy.interpolate.interpnd, scipy.interpolate._rbfinterp_pythran, scipy.interpolate._rgi_cython, scipy.signal._sosfilt, scipy.ndimage._nd_image, _ni_label, scipy.ndimage._ni_label, scipy.signal._spectral, scipy.special.cython_special, scipy.stats._stats, scipy.stats.beta_ufunc, scipy.stats._boost.beta_ufunc, scipy.stats.binom_ufunc, scipy.stats._boost.binom_ufunc, scipy.stats.nbinom_ufunc, scipy.stats._boost.nbinom_ufunc, scipy.stats.hypergeom_ufunc, scipy.stats._boost.hypergeom_ufunc, scipy.stats.ncf_ufunc, scipy.stats._boost.ncf_ufunc, scipy.stats.ncx2_ufunc, scipy.stats._boost.ncx2_ufunc, scipy.stats.nct_ufunc, scipy.stats._boost.nct_ufunc, scipy.stats.skewnorm_ufunc, scipy.stats._boost.skewnorm_ufunc, scipy.stats.invgauss_ufunc, scipy.stats._boost.invgauss_ufunc, scipy.stats._biasedurn, scipy.stats._levy_stable.levyst, scipy.stats._stats_pythran, scipy.stats._statlib, scipy.stats._mvn, scipy.stats._sobol, scipy.stats._qmc_cy, scipy.stats._rcont.rcont, scipy.signal._peak_finding_utils, numba.core.typeconv._typeconv, numba._helperlib, numba._dynfunc, numba._dispatcher, numba.core.runtime._nrt_python, numba.np.ufunc._internal, xxhash._xxhash, scipy.fftpack.convolve, sklearn.__check_build._check_build, sklearn.utils.murmurhash, sklearn.utils._isfinite, sklearn.utils._openmp_helpers, sklearn.decomposition._cdnmf_fast, sklearn.utils._logistic_sigmoid, sklearn.utils.sparsefuncs_fast, sklearn.preprocessing._csr_polynomial_expansion, sklearn.utils._typedefs, sklearn.utils._readonly_array_wrapper, sklearn.metrics._dist_metrics, sklearn.metrics.cluster._expected_mutual_info_fast, sklearn.metrics._pairwise_distances_reduction._datasets_pair, sklearn.utils._cython_blas, sklearn.metrics._pairwise_distances_reduction._base, sklearn.metrics._pairwise_distances_reduction._middle_term_computer, sklearn.utils._heap, sklearn.utils._sorting, sklearn.metrics._pairwise_distances_reduction._argkmin, sklearn.utils._vector_sentinel, sklearn.metrics._pairwise_distances_reduction._radius_neighbors, sklearn.metrics._pairwise_fast, sklearn.utils._random, sklearn.utils._seq_dataset, sklearn.utils.arrayfuncs, sklearn.linear_model._cd_fast, sklearn._loss._loss, sklearn.utils._weight_vector, sklearn.linear_model._sgd_fast, sklearn.linear_model._sag_fast, sklearn.svm._libsvm, sklearn.svm._liblinear, sklearn.svm._libsvm_sparse, sklearn.decomposition._online_lda_fast, sklearn.neighbors._partition_nodes, sklearn.neighbors._ball_tree, sklearn.neighbors._kd_tree, sklearn._isotonic, sklearn.manifold._utils, sklearn.tree._utils, sklearn.tree._tree, sklearn.tree._splitter, sklearn.tree._criterion, sklearn.neighbors._quad_tree, sklearn.manifold._barnes_hut_tsne, sklearn.cluster._k_means_common, sklearn.cluster._k_means_minibatch, sklearn.cluster._k_means_lloyd, sklearn.cluster._k_means_elkan, sklearn.utils._fast_dict, sklearn.cluster._hierarchical_fast, sklearn.cluster._dbscan_inner, sklearn.feature_extraction._hashing_fast, matplotlib._c_internal_utils, PIL._imaging, matplotlib._path, kiwisolver._cext, matplotlib._image, regex._regex, pycrfsuite._pycrfsuite, sklearn.datasets._svmlight_format_fast, lxml._elementpath, lxml.etree, numba.experimental.jitclass._box (total: 288)\n",
      "2023-03-07 15:42:17,840\tWARNING worker.py:1870 -- A worker died or was killed while executing a task by an unexpected system error. To troubleshoot the problem, check the logs for the dead worker. RayTask ID: ffffffffffffffffd92daefe0821b2bbe7d2ce9537000000 Worker ID: 41ed1214279d48f74be588edf9b2dad3b8af30a3d1b82a89f8748441 Node ID: c896a1f2d49a841de85d9f4ade62b71676469b02e6133224652550d8 Worker IP address: 10.0.37.211 Worker port: 10459 Worker PID: 1124519 Worker exit type: SYSTEM_ERROR Worker exit detail: Worker unexpectedly exits with a connection error code 2. End of file. There are some potential root causes. (1) The process is killed by SIGKILL by OOM killer due to high memory usage. (2) ray stop --force is called. (3) The worker is crashed unexpectedly due to SIGSEGV or other unexpected errors.\n",
      "(TorchTrainer pid=3738, ip=10.0.48.48) 2023-03-07 15:42:17,840\tINFO utils.py:57 -- Worker 1 has failed.2023-03-07 15:42:17,865\tERROR trial_runner.py:705 -- Trial TorchTrainer_209d8_00000: Error happened when processing _ExecutorEventType.TRAINING_RESULT.\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/ray/anaconda3/lib/python3.10/site-packages/ray/tune/execution/ray_trial_executor.py\", line 1311, in get_next_executor_event\n",
      "    future_result = ray.get(ready_future)\n",
      "  File \"/home/ray/anaconda3/lib/python3.10/site-packages/ray/_private/client_mode_hook.py\", line 105, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/home/ray/anaconda3/lib/python3.10/site-packages/ray/_private/worker.py\", line 2384, in get\n",
      "    raise value.as_instanceof_cause()\n",
      "ray.exceptions.RayTaskError: \u001b[36mray::_Inner.train()\u001b[39m (pid=3738, ip=10.0.48.48, repr=TorchTrainer)\n",
      "  File \"/home/ray/anaconda3/lib/python3.10/site-packages/ray/tune/trainable/trainable.py\", line 360, in train\n",
      "    raise skipped from exception_cause(skipped)\n",
      "  File \"/home/ray/anaconda3/lib/python3.10/site-packages/ray/tune/trainable/function_trainable.py\", line 336, in entrypoint\n",
      "    return self._trainable_func(\n",
      "  File \"/home/ray/anaconda3/lib/python3.10/site-packages/ray/train/base_trainer.py\", line 737, in _trainable_func\n",
      "    super()._trainable_func(self._merged_config, reporter, checkpoint_dir)\n",
      "  File \"/home/ray/anaconda3/lib/python3.10/site-packages/ray/tune/trainable/function_trainable.py\", line 653, in _trainable_func\n",
      "    output = fn()\n",
      "  File \"/home/ray/anaconda3/lib/python3.10/site-packages/ray/train/base_trainer.py\", line 647, in train_func\n",
      "    trainer.training_loop()\n",
      "  File \"/home/ray/anaconda3/lib/python3.10/site-packages/ray/train/data_parallel_trainer.py\", line 433, in training_loop\n",
      "    self._report(training_iterator)\n",
      "  File \"/home/ray/anaconda3/lib/python3.10/site-packages/ray/train/data_parallel_trainer.py\", line 380, in _report\n",
      "    for results in training_iterator:\n",
      "  File \"/home/ray/anaconda3/lib/python3.10/site-packages/ray/train/trainer.py\", line 134, in __next__\n",
      "    next_results = self._run_with_error_handling(self._fetch_next_result)\n",
      "  File \"/home/ray/anaconda3/lib/python3.10/site-packages/ray/train/trainer.py\", line 97, in _run_with_error_handling\n",
      "    return func()\n",
      "  File \"/home/ray/anaconda3/lib/python3.10/site-packages/ray/train/trainer.py\", line 168, in _fetch_next_result\n",
      "    results = self._backend_executor.get_next_results()\n",
      "  File \"/home/ray/anaconda3/lib/python3.10/site-packages/ray/train/_internal/backend_executor.py\", line 444, in get_next_results\n",
      "    results = self.get_with_failure_handling(futures)\n",
      "  File \"/home/ray/anaconda3/lib/python3.10/site-packages/ray/train/_internal/backend_executor.py\", line 533, in get_with_failure_handling\n",
      "    self._increment_failures()\n",
      "  File \"/home/ray/anaconda3/lib/python3.10/site-packages/ray/train/_internal/backend_executor.py\", line 595, in _increment_failures\n",
      "    raise failure\n",
      "  File \"/home/ray/anaconda3/lib/python3.10/site-packages/ray/train/_internal/utils.py\", line 54, in check_for_failure\n",
      "    ray.get(object_ref)\n",
      "ray.exceptions.RayActorError: The actor died unexpectedly before finishing this task.\n",
      "\tclass_name: RayTrainWorker\n",
      "\tactor_id: d92daefe0821b2bbe7d2ce9537000000\n",
      "\tpid: 1124519\n",
      "\tnamespace: 3cec299d-7eb2-44ca-a17e-0e4e4c288f63\n",
      "\tip: 10.0.37.211\n",
      "The actor is dead because its worker process has died. Worker exit type: SYSTEM_ERROR Worker exit detail: Worker unexpectedly exits with a connection error code 2. End of file. There are some potential root causes. (1) The process is killed by SIGKILL by OOM killer due to high memory usage. (2) ray stop --force is called. (3) The worker is crashed unexpectedly due to SIGSEGV or other unexpected errors.\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div class=\"trialProgress\">\n",
       "  <h3>Trial Progress</h3>\n",
       "  <table>\n",
       "<thead>\n",
       "<tr><th>Trial name              </th><th>date               </th><th>hostname     </th><th>node_ip   </th><th style=\"text-align: right;\">  pid</th><th style=\"text-align: right;\">  timestamp</th><th>trial_id   </th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>TorchTrainer_209d8_00000</td><td>2023-03-07_15-09-43</td><td>ip-10-0-48-48</td><td>10.0.48.48</td><td style=\"text-align: right;\"> 3738</td><td style=\"text-align: right;\"> 1678230583</td><td>209d8_00000</td></tr>\n",
       "</tbody>\n",
       "</table>\n",
       "</div>\n",
       "<style>\n",
       ".trialProgress {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "  color: var(--jp-ui-font-color1);\n",
       "}\n",
       ".trialProgress h3 {\n",
       "  font-weight: bold;\n",
       "}\n",
       ".trialProgress td {\n",
       "  white-space: nowrap;\n",
       "}\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-03-07 15:42:30,245\tERROR tune.py:821 -- Trials did not complete: [TorchTrainer_209d8_00000]\n",
      "2023-03-07 15:42:30,246\tINFO tune.py:825 -- Total run time: 1974.69 seconds (1962.16 seconds for the tuning loop).\n"
     ]
    },
    {
     "ename": "RayTaskError",
     "evalue": "\u001b[36mray::_Inner.train()\u001b[39m (pid=3738, ip=10.0.48.48, repr=TorchTrainer)\n  File \"/home/ray/anaconda3/lib/python3.10/site-packages/ray/tune/trainable/trainable.py\", line 360, in train\n    raise skipped from exception_cause(skipped)\n  File \"/home/ray/anaconda3/lib/python3.10/site-packages/ray/tune/trainable/function_trainable.py\", line 336, in entrypoint\n    return self._trainable_func(\n  File \"/home/ray/anaconda3/lib/python3.10/site-packages/ray/train/base_trainer.py\", line 737, in _trainable_func\n    super()._trainable_func(self._merged_config, reporter, checkpoint_dir)\n  File \"/home/ray/anaconda3/lib/python3.10/site-packages/ray/tune/trainable/function_trainable.py\", line 653, in _trainable_func\n    output = fn()\n  File \"/home/ray/anaconda3/lib/python3.10/site-packages/ray/train/base_trainer.py\", line 647, in train_func\n    trainer.training_loop()\n  File \"/home/ray/anaconda3/lib/python3.10/site-packages/ray/train/data_parallel_trainer.py\", line 433, in training_loop\n    self._report(training_iterator)\n  File \"/home/ray/anaconda3/lib/python3.10/site-packages/ray/train/data_parallel_trainer.py\", line 380, in _report\n    for results in training_iterator:\n  File \"/home/ray/anaconda3/lib/python3.10/site-packages/ray/train/trainer.py\", line 134, in __next__\n    next_results = self._run_with_error_handling(self._fetch_next_result)\n  File \"/home/ray/anaconda3/lib/python3.10/site-packages/ray/train/trainer.py\", line 97, in _run_with_error_handling\n    return func()\n  File \"/home/ray/anaconda3/lib/python3.10/site-packages/ray/train/trainer.py\", line 168, in _fetch_next_result\n    results = self._backend_executor.get_next_results()\n  File \"/home/ray/anaconda3/lib/python3.10/site-packages/ray/train/_internal/backend_executor.py\", line 444, in get_next_results\n    results = self.get_with_failure_handling(futures)\n  File \"/home/ray/anaconda3/lib/python3.10/site-packages/ray/train/_internal/backend_executor.py\", line 533, in get_with_failure_handling\n    self._increment_failures()\n  File \"/home/ray/anaconda3/lib/python3.10/site-packages/ray/train/_internal/backend_executor.py\", line 595, in _increment_failures\n    raise failure\n  File \"/home/ray/anaconda3/lib/python3.10/site-packages/ray/train/_internal/utils.py\", line 54, in check_for_failure\n    ray.get(object_ref)\nray.exceptions.RayActorError: The actor died unexpectedly before finishing this task.\n\tclass_name: RayTrainWorker\n\tactor_id: d92daefe0821b2bbe7d2ce9537000000\n\tpid: 1124519\n\tnamespace: 3cec299d-7eb2-44ca-a17e-0e4e4c288f63\n\tip: 10.0.37.211\nThe actor is dead because its worker process has died. Worker exit type: SYSTEM_ERROR Worker exit detail: Worker unexpectedly exits with a connection error code 2. End of file. There are some potential root causes. (1) The process is killed by SIGKILL by OOM killer due to high memory usage. (2) ray stop --force is called. (3) The worker is crashed unexpectedly due to SIGSEGV or other unexpected errors.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRayTaskError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[8], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[43mtrainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.10/site-packages/ray/train/base_trainer.py:579\u001b[0m, in \u001b[0;36mBaseTrainer.fit\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    577\u001b[0m     result \u001b[38;5;241m=\u001b[39m result_grid[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m    578\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m result\u001b[38;5;241m.\u001b[39merror:\n\u001b[0;32m--> 579\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m result\u001b[38;5;241m.\u001b[39merror\n\u001b[1;32m    580\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m TuneError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    581\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m TrainingFailedError \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01me\u001b[39;00m\n",
      "\u001b[0;31mRayTaskError\u001b[0m: \u001b[36mray::_Inner.train()\u001b[39m (pid=3738, ip=10.0.48.48, repr=TorchTrainer)\n  File \"/home/ray/anaconda3/lib/python3.10/site-packages/ray/tune/trainable/trainable.py\", line 360, in train\n    raise skipped from exception_cause(skipped)\n  File \"/home/ray/anaconda3/lib/python3.10/site-packages/ray/tune/trainable/function_trainable.py\", line 336, in entrypoint\n    return self._trainable_func(\n  File \"/home/ray/anaconda3/lib/python3.10/site-packages/ray/train/base_trainer.py\", line 737, in _trainable_func\n    super()._trainable_func(self._merged_config, reporter, checkpoint_dir)\n  File \"/home/ray/anaconda3/lib/python3.10/site-packages/ray/tune/trainable/function_trainable.py\", line 653, in _trainable_func\n    output = fn()\n  File \"/home/ray/anaconda3/lib/python3.10/site-packages/ray/train/base_trainer.py\", line 647, in train_func\n    trainer.training_loop()\n  File \"/home/ray/anaconda3/lib/python3.10/site-packages/ray/train/data_parallel_trainer.py\", line 433, in training_loop\n    self._report(training_iterator)\n  File \"/home/ray/anaconda3/lib/python3.10/site-packages/ray/train/data_parallel_trainer.py\", line 380, in _report\n    for results in training_iterator:\n  File \"/home/ray/anaconda3/lib/python3.10/site-packages/ray/train/trainer.py\", line 134, in __next__\n    next_results = self._run_with_error_handling(self._fetch_next_result)\n  File \"/home/ray/anaconda3/lib/python3.10/site-packages/ray/train/trainer.py\", line 97, in _run_with_error_handling\n    return func()\n  File \"/home/ray/anaconda3/lib/python3.10/site-packages/ray/train/trainer.py\", line 168, in _fetch_next_result\n    results = self._backend_executor.get_next_results()\n  File \"/home/ray/anaconda3/lib/python3.10/site-packages/ray/train/_internal/backend_executor.py\", line 444, in get_next_results\n    results = self.get_with_failure_handling(futures)\n  File \"/home/ray/anaconda3/lib/python3.10/site-packages/ray/train/_internal/backend_executor.py\", line 533, in get_with_failure_handling\n    self._increment_failures()\n  File \"/home/ray/anaconda3/lib/python3.10/site-packages/ray/train/_internal/backend_executor.py\", line 595, in _increment_failures\n    raise failure\n  File \"/home/ray/anaconda3/lib/python3.10/site-packages/ray/train/_internal/utils.py\", line 54, in check_for_failure\n    ray.get(object_ref)\nray.exceptions.RayActorError: The actor died unexpectedly before finishing this task.\n\tclass_name: RayTrainWorker\n\tactor_id: d92daefe0821b2bbe7d2ce9537000000\n\tpid: 1124519\n\tnamespace: 3cec299d-7eb2-44ca-a17e-0e4e4c288f63\n\tip: 10.0.37.211\nThe actor is dead because its worker process has died. Worker exit type: SYSTEM_ERROR Worker exit detail: Worker unexpectedly exits with a connection error code 2. End of file. There are some potential root causes. (1) The process is killed by SIGKILL by OOM killer due to high memory usage. (2) ray stop --force is called. (3) The worker is crashed unexpectedly due to SIGSEGV or other unexpected errors."
     ]
    }
   ],
   "source": [
    "result = trainer.fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2d91c7fc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[0;31mSignature:\u001b[0m\n",
       "\u001b[0mlibrosa_mel_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0msr\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mn_fft\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mn_mels\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m128\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mfmin\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mfmax\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mhtk\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mnorm\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'slaney'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m<\u001b[0m\u001b[0;32mclass\u001b[0m \u001b[0;34m'numpy.float32'\u001b[0m\u001b[0;34m>\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
       "\u001b[0;31mSource:\u001b[0m   \n",
       "\u001b[0;34m@\u001b[0m\u001b[0mcache\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlevel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\u001b[0;32mdef\u001b[0m \u001b[0mmel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0msr\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mn_fft\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mn_mels\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m128\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mfmin\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mfmax\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mhtk\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mnorm\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"slaney\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0;34m\"\"\"Create a Mel filter-bank.\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m    This produces a linear transformation matrix to project\u001b[0m\n",
       "\u001b[0;34m    FFT bins onto Mel-frequency bins.\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m    Parameters\u001b[0m\n",
       "\u001b[0;34m    ----------\u001b[0m\n",
       "\u001b[0;34m    sr        : number > 0 [scalar]\u001b[0m\n",
       "\u001b[0;34m        sampling rate of the incoming signal\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m    n_fft     : int > 0 [scalar]\u001b[0m\n",
       "\u001b[0;34m        number of FFT components\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m    n_mels    : int > 0 [scalar]\u001b[0m\n",
       "\u001b[0;34m        number of Mel bands to generate\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m    fmin      : float >= 0 [scalar]\u001b[0m\n",
       "\u001b[0;34m        lowest frequency (in Hz)\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m    fmax      : float >= 0 [scalar]\u001b[0m\n",
       "\u001b[0;34m        highest frequency (in Hz).\u001b[0m\n",
       "\u001b[0;34m        If `None`, use ``fmax = sr / 2.0``\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m    htk       : bool [scalar]\u001b[0m\n",
       "\u001b[0;34m        use HTK formula instead of Slaney\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m    norm : {None, 'slaney', or number} [scalar]\u001b[0m\n",
       "\u001b[0;34m        If 'slaney', divide the triangular mel weights by the width of the mel band\u001b[0m\n",
       "\u001b[0;34m        (area normalization).\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m        If numeric, use `librosa.util.normalize` to normalize each filter by to unit l_p norm.\u001b[0m\n",
       "\u001b[0;34m        See `librosa.util.normalize` for a full description of supported norm values\u001b[0m\n",
       "\u001b[0;34m        (including `+-np.inf`).\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m        Otherwise, leave all the triangles aiming for a peak value of 1.0\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m    dtype : np.dtype\u001b[0m\n",
       "\u001b[0;34m        The data type of the output basis.\u001b[0m\n",
       "\u001b[0;34m        By default, uses 32-bit (single-precision) floating point.\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m    Returns\u001b[0m\n",
       "\u001b[0;34m    -------\u001b[0m\n",
       "\u001b[0;34m    M         : np.ndarray [shape=(n_mels, 1 + n_fft/2)]\u001b[0m\n",
       "\u001b[0;34m        Mel transform matrix\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m    See also\u001b[0m\n",
       "\u001b[0;34m    --------\u001b[0m\n",
       "\u001b[0;34m    librosa.util.normalize\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m    Notes\u001b[0m\n",
       "\u001b[0;34m    -----\u001b[0m\n",
       "\u001b[0;34m    This function caches at level 10.\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m    Examples\u001b[0m\n",
       "\u001b[0;34m    --------\u001b[0m\n",
       "\u001b[0;34m    >>> melfb = librosa.filters.mel(22050, 2048)\u001b[0m\n",
       "\u001b[0;34m    >>> melfb\u001b[0m\n",
       "\u001b[0;34m    array([[ 0.   ,  0.016, ...,  0.   ,  0.   ],\u001b[0m\n",
       "\u001b[0;34m           [ 0.   ,  0.   , ...,  0.   ,  0.   ],\u001b[0m\n",
       "\u001b[0;34m           ...,\u001b[0m\n",
       "\u001b[0;34m           [ 0.   ,  0.   , ...,  0.   ,  0.   ],\u001b[0m\n",
       "\u001b[0;34m           [ 0.   ,  0.   , ...,  0.   ,  0.   ]])\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m    Clip the maximum frequency to 8KHz\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m    >>> librosa.filters.mel(22050, 2048, fmax=8000)\u001b[0m\n",
       "\u001b[0;34m    array([[ 0.  ,  0.02, ...,  0.  ,  0.  ],\u001b[0m\n",
       "\u001b[0;34m           [ 0.  ,  0.  , ...,  0.  ,  0.  ],\u001b[0m\n",
       "\u001b[0;34m           ...,\u001b[0m\n",
       "\u001b[0;34m           [ 0.  ,  0.  , ...,  0.  ,  0.  ],\u001b[0m\n",
       "\u001b[0;34m           [ 0.  ,  0.  , ...,  0.  ,  0.  ]])\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m    >>> import matplotlib.pyplot as plt\u001b[0m\n",
       "\u001b[0;34m    >>> fig, ax = plt.subplots()\u001b[0m\n",
       "\u001b[0;34m    >>> img = librosa.display.specshow(melfb, x_axis='linear', ax=ax)\u001b[0m\n",
       "\u001b[0;34m    >>> ax.set(ylabel='Mel filter', title='Mel filter bank')\u001b[0m\n",
       "\u001b[0;34m    >>> fig.colorbar(img, ax=ax)\u001b[0m\n",
       "\u001b[0;34m    \"\"\"\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0;32mif\u001b[0m \u001b[0mfmax\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0mfmax\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msr\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0;31m# Initialize the weights\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mn_mels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_mels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mweights\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_mels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mn_fft\u001b[0m \u001b[0;34m//\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0;31m# Center freqs of each FFT bin\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mfftfreqs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfft_frequencies\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_fft\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mn_fft\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0;31m# 'Center freqs' of mel bands - uniformly spaced between limits\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mmel_f\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmel_frequencies\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_mels\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfmin\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfmin\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfmax\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfmax\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhtk\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mhtk\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mfdiff\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdiff\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmel_f\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mramps\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msubtract\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mouter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmel_f\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfftfreqs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_mels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0;31m# lower and upper slopes for all bins\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0mlower\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0mramps\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mfdiff\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0mupper\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mramps\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mfdiff\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0;31m# .. then intersect them with each other and zero\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0mweights\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmaximum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mminimum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlower\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mupper\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0;32mif\u001b[0m \u001b[0mnorm\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"slaney\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0;31m# Slaney-style mel is scaled to be approx constant energy per channel\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0menorm\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m2.0\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mmel_f\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m \u001b[0;34m:\u001b[0m \u001b[0mn_mels\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mmel_f\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mn_mels\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0mweights\u001b[0m \u001b[0;34m*=\u001b[0m \u001b[0menorm\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnewaxis\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0mweights\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mutil\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnormalize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mweights\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnorm\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnorm\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0;31m# Only check weights if f_mel[0] is positive\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmel_f\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m|\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mweights\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0;31m# This means we have an empty channel somewhere\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0mwarnings\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwarn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m            \u001b[0;34m\"Empty filters detected in mel frequency basis. \"\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m            \u001b[0;34m\"Some channels will produce empty responses. \"\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m            \u001b[0;34m\"Try increasing your sampling rate (and fmax) or \"\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m            \u001b[0;34m\"reducing n_mels.\"\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0;32mreturn\u001b[0m \u001b[0mweights\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
       "\u001b[0;31mFile:\u001b[0m      ~/anaconda3/lib/python3.10/site-packages/librosa/filters.py\n",
       "\u001b[0;31mType:\u001b[0m      function"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "??librosa_mel_fn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "17feefde",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on function mel in module librosa.filters:\n",
      "\n",
      "mel(sr, n_fft, n_mels=128, fmin=0.0, fmax=None, htk=False, norm='slaney', dtype=<class 'numpy.float32'>)\n",
      "    Create a Mel filter-bank.\n",
      "    \n",
      "    This produces a linear transformation matrix to project\n",
      "    FFT bins onto Mel-frequency bins.\n",
      "    \n",
      "    Parameters\n",
      "    ----------\n",
      "    sr        : number > 0 [scalar]\n",
      "        sampling rate of the incoming signal\n",
      "    \n",
      "    n_fft     : int > 0 [scalar]\n",
      "        number of FFT components\n",
      "    \n",
      "    n_mels    : int > 0 [scalar]\n",
      "        number of Mel bands to generate\n",
      "    \n",
      "    fmin      : float >= 0 [scalar]\n",
      "        lowest frequency (in Hz)\n",
      "    \n",
      "    fmax      : float >= 0 [scalar]\n",
      "        highest frequency (in Hz).\n",
      "        If `None`, use ``fmax = sr / 2.0``\n",
      "    \n",
      "    htk       : bool [scalar]\n",
      "        use HTK formula instead of Slaney\n",
      "    \n",
      "    norm : {None, 'slaney', or number} [scalar]\n",
      "        If 'slaney', divide the triangular mel weights by the width of the mel band\n",
      "        (area normalization).\n",
      "    \n",
      "        If numeric, use `librosa.util.normalize` to normalize each filter by to unit l_p norm.\n",
      "        See `librosa.util.normalize` for a full description of supported norm values\n",
      "        (including `+-np.inf`).\n",
      "    \n",
      "        Otherwise, leave all the triangles aiming for a peak value of 1.0\n",
      "    \n",
      "    dtype : np.dtype\n",
      "        The data type of the output basis.\n",
      "        By default, uses 32-bit (single-precision) floating point.\n",
      "    \n",
      "    Returns\n",
      "    -------\n",
      "    M         : np.ndarray [shape=(n_mels, 1 + n_fft/2)]\n",
      "        Mel transform matrix\n",
      "    \n",
      "    See also\n",
      "    --------\n",
      "    librosa.util.normalize\n",
      "    \n",
      "    Notes\n",
      "    -----\n",
      "    This function caches at level 10.\n",
      "    \n",
      "    Examples\n",
      "    --------\n",
      "    >>> melfb = librosa.filters.mel(22050, 2048)\n",
      "    >>> melfb\n",
      "    array([[ 0.   ,  0.016, ...,  0.   ,  0.   ],\n",
      "           [ 0.   ,  0.   , ...,  0.   ,  0.   ],\n",
      "           ...,\n",
      "           [ 0.   ,  0.   , ...,  0.   ,  0.   ],\n",
      "           [ 0.   ,  0.   , ...,  0.   ,  0.   ]])\n",
      "    \n",
      "    \n",
      "    Clip the maximum frequency to 8KHz\n",
      "    \n",
      "    >>> librosa.filters.mel(22050, 2048, fmax=8000)\n",
      "    array([[ 0.  ,  0.02, ...,  0.  ,  0.  ],\n",
      "           [ 0.  ,  0.  , ...,  0.  ,  0.  ],\n",
      "           ...,\n",
      "           [ 0.  ,  0.  , ...,  0.  ,  0.  ],\n",
      "           [ 0.  ,  0.  , ...,  0.  ,  0.  ]])\n",
      "    \n",
      "    \n",
      "    >>> import matplotlib.pyplot as plt\n",
      "    >>> fig, ax = plt.subplots()\n",
      "    >>> img = librosa.display.specshow(melfb, x_axis='linear', ax=ax)\n",
      "    >>> ax.set(ylabel='Mel filter', title='Mel filter bank')\n",
      "    >>> fig.colorbar(img, ax=ax)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from librosa.filters import mel as librosa_mel_fn\n",
    "help(librosa_mel_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c78b5763",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'0.10.0'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import librosa\n",
    "from librosa.util import pad_center\n",
    "librosa.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "40963f2f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on function pad_center in module librosa.util.utils:\n",
      "\n",
      "pad_center(data: 'np.ndarray', *, size: 'int', axis: 'int' = -1, **kwargs: 'Any') -> 'np.ndarray'\n",
      "    Pad an array to a target length along a target axis.\n",
      "    \n",
      "    This differs from `np.pad` by centering the data prior to padding,\n",
      "    analogous to `str.center`\n",
      "    \n",
      "    Examples\n",
      "    --------\n",
      "    >>> # Generate a vector\n",
      "    >>> data = np.ones(5)\n",
      "    >>> librosa.util.pad_center(data, size=10, mode='constant')\n",
      "    array([ 0.,  0.,  1.,  1.,  1.,  1.,  1.,  0.,  0.,  0.])\n",
      "    \n",
      "    >>> # Pad a matrix along its first dimension\n",
      "    >>> data = np.ones((3, 5))\n",
      "    >>> librosa.util.pad_center(data, size=7, axis=0)\n",
      "    array([[ 0.,  0.,  0.,  0.,  0.],\n",
      "           [ 0.,  0.,  0.,  0.,  0.],\n",
      "           [ 1.,  1.,  1.,  1.,  1.],\n",
      "           [ 1.,  1.,  1.,  1.,  1.],\n",
      "           [ 1.,  1.,  1.,  1.,  1.],\n",
      "           [ 0.,  0.,  0.,  0.,  0.],\n",
      "           [ 0.,  0.,  0.,  0.,  0.]])\n",
      "    >>> # Or its second dimension\n",
      "    >>> librosa.util.pad_center(data, size=7, axis=1)\n",
      "    array([[ 0.,  1.,  1.,  1.,  1.,  1.,  0.],\n",
      "           [ 0.,  1.,  1.,  1.,  1.,  1.,  0.],\n",
      "           [ 0.,  1.,  1.,  1.,  1.,  1.,  0.]])\n",
      "    \n",
      "    Parameters\n",
      "    ----------\n",
      "    data : np.ndarray\n",
      "        Vector to be padded and centered\n",
      "    size : int >= len(data) [scalar]\n",
      "        Length to pad ``data``\n",
      "    axis : int\n",
      "        Axis along which to pad and center the data\n",
      "    **kwargs : additional keyword arguments\n",
      "        arguments passed to `np.pad`\n",
      "    \n",
      "    Returns\n",
      "    -------\n",
      "    data_padded : np.ndarray\n",
      "        ``data`` centered and padded to length ``size`` along the\n",
      "        specified axis\n",
      "    \n",
      "    Raises\n",
      "    ------\n",
      "    ParameterError\n",
      "        If ``size < data.shape[axis]``\n",
      "    \n",
      "    See Also\n",
      "    --------\n",
      "    numpy.pad\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# import pad_center\n",
    "help(pad_center)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f464211e",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "pad_center() takes 1 positional argument but 2 were given",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnp\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m \u001b[43mpad_center\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mones\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m1000\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m5000\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mTypeError\u001b[0m: pad_center() takes 1 positional argument but 2 were given"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "pad_center(np.ones(1000), 5000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fa86c839",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting librosa==0.8.1\n",
      "  Using cached librosa-0.8.1-py3-none-any.whl (203 kB)\n",
      "Requirement already satisfied: numpy>=1.15.0 in /home/ray/anaconda3/lib/python3.10/site-packages (from librosa==0.8.1) (1.22.0)\n",
      "Requirement already satisfied: joblib>=0.14 in /home/ray/anaconda3/lib/python3.10/site-packages (from librosa==0.8.1) (1.2.0)\n",
      "Requirement already satisfied: soundfile>=0.10.2 in /home/ray/anaconda3/lib/python3.10/site-packages (from librosa==0.8.1) (0.12.1)\n",
      "Requirement already satisfied: pooch>=1.0 in /home/ray/anaconda3/lib/python3.10/site-packages (from librosa==0.8.1) (1.6.0)\n",
      "Requirement already satisfied: packaging>=20.0 in /home/ray/anaconda3/lib/python3.10/site-packages (from librosa==0.8.1) (23.0)\n",
      "Requirement already satisfied: numba>=0.43.0 in /home/ray/anaconda3/lib/python3.10/site-packages (from librosa==0.8.1) (0.55.2)\n",
      "Requirement already satisfied: resampy>=0.2.2 in /home/ray/anaconda3/lib/python3.10/site-packages (from librosa==0.8.1) (0.4.2)\n",
      "Requirement already satisfied: scipy>=1.0.0 in /home/ray/anaconda3/lib/python3.10/site-packages (from librosa==0.8.1) (1.10.1)\n",
      "Requirement already satisfied: audioread>=2.0.0 in /home/ray/anaconda3/lib/python3.10/site-packages (from librosa==0.8.1) (3.0.0)\n",
      "Requirement already satisfied: scikit-learn!=0.19.0,>=0.14.0 in /home/ray/anaconda3/lib/python3.10/site-packages (from librosa==0.8.1) (1.2.1)\n",
      "Requirement already satisfied: decorator>=3.0.0 in /home/ray/anaconda3/lib/python3.10/site-packages (from librosa==0.8.1) (5.1.1)\n",
      "Requirement already satisfied: setuptools in /home/ray/anaconda3/lib/python3.10/site-packages (from numba>=0.43.0->librosa==0.8.1) (67.4.0)\n",
      "Requirement already satisfied: llvmlite<0.39,>=0.38.0rc1 in /home/ray/anaconda3/lib/python3.10/site-packages (from numba>=0.43.0->librosa==0.8.1) (0.38.1)\n",
      "Requirement already satisfied: requests>=2.19.0 in /home/ray/anaconda3/lib/python3.10/site-packages (from pooch>=1.0->librosa==0.8.1) (2.28.2)\n",
      "Requirement already satisfied: appdirs>=1.3.0 in /home/ray/anaconda3/lib/python3.10/site-packages (from pooch>=1.0->librosa==0.8.1) (1.4.4)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /home/ray/anaconda3/lib/python3.10/site-packages (from scikit-learn!=0.19.0,>=0.14.0->librosa==0.8.1) (3.1.0)\n",
      "Requirement already satisfied: cffi>=1.0 in /home/ray/anaconda3/lib/python3.10/site-packages (from soundfile>=0.10.2->librosa==0.8.1) (1.15.1)\n",
      "Requirement already satisfied: pycparser in /home/ray/anaconda3/lib/python3.10/site-packages (from cffi>=1.0->soundfile>=0.10.2->librosa==0.8.1) (2.21)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /home/ray/anaconda3/lib/python3.10/site-packages (from requests>=2.19.0->pooch>=1.0->librosa==0.8.1) (3.0.1)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /home/ray/anaconda3/lib/python3.10/site-packages (from requests>=2.19.0->pooch>=1.0->librosa==0.8.1) (1.26.14)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/ray/anaconda3/lib/python3.10/site-packages (from requests>=2.19.0->pooch>=1.0->librosa==0.8.1) (3.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/ray/anaconda3/lib/python3.10/site-packages (from requests>=2.19.0->pooch>=1.0->librosa==0.8.1) (2022.12.7)\n",
      "Installing collected packages: librosa\n",
      "  Attempting uninstall: librosa\n",
      "    Found existing installation: librosa 0.10.0\n",
      "    Uninstalling librosa-0.10.0:\n",
      "      Successfully uninstalled librosa-0.10.0\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "tts 0.11.1 requires cython==0.29.28, but you have cython 0.29.33 which is incompatible.\n",
      "tts 0.11.1 requires inflect==5.6.0, but you have inflect 6.0.2 which is incompatible.\n",
      "tts 0.11.1 requires librosa==0.8.0, but you have librosa 0.8.1 which is incompatible.\n",
      "tts 0.11.1 requires numpy==1.22.4; python_version == \"3.10\", but you have numpy 1.22.0 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0mSuccessfully installed librosa-0.8.1\n"
     ]
    }
   ],
   "source": [
    "# Install a pip package in the current Jupyter kernel\n",
    "import sys\n",
    "!{sys.executable} -m pip install librosa==0.8.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fbeea3d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import ray\n",
    "parallelism_length = 400"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "34888fb9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-03-06 16:54:26,264\tINFO worker.py:1360 -- Connecting to existing Ray cluster at address: 10.0.37.211:6379...\n",
      "2023-03-06 16:54:26,291\tINFO worker.py:1548 -- Connected to Ray cluster. View the dashboard at \u001b[1m\u001b[32mhttps://console.anyscale.com/api/v2/sessions/ses_ha6my3r3kl4mn9jdylcqnfutq1/services?redirect_to=dashboard \u001b[39m\u001b[22m\n",
      "2023-03-06 16:54:26,316\tINFO packaging.py:330 -- Pushing file package 'gcs://_ray_pkg_c450220a9fe1382fee31ab05c616a7cf.zip' (6.75MiB) to Ray cluster...\n",
      "2023-03-06 16:54:26,438\tINFO packaging.py:343 -- Successfully pushed file package 'gcs://_ray_pkg_c450220a9fe1382fee31ab05c616a7cf.zip'.\n"
     ]
    }
   ],
   "source": [
    "lj_df = pd.read_csv(\n",
    "    \"https://uberduck-datasets-dirty.s3.us-west-2.amazonaws.com/lj_for_upload/metadata_formatted_100_edited.txt\",\n",
    "    sep=\"|\",\n",
    "    header=None,\n",
    "    quoting=3,\n",
    "    names=[\"path\", \"transcript\", \"speaker_id\"], # pitch path is implicit - this should be changed\n",
    ")\n",
    "speaker_ids = lj_df.speaker_id.tolist()\n",
    "speaker_ids_ds = ray.data.from_items(speaker_ids, parallelism=parallelism_length)\n",
    "speaker_ids_ds = speaker_ids_ds.map_batches(\n",
    "    lambda x: x, batch_format=\"pyarrow\", batch_size=None\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7b55340c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>path</th>\n",
       "      <th>transcript</th>\n",
       "      <th>speaker_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>s3://uberduck-datasets-dirty/lj_for_upload/lj_...</td>\n",
       "      <td>Printing, in the only sense with which we are ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>s3://uberduck-datasets-dirty/lj_for_upload/lj_...</td>\n",
       "      <td>in being comparatively modern.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>s3://uberduck-datasets-dirty/lj_for_upload/lj_...</td>\n",
       "      <td>For although the Chinese took impressions from...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>s3://uberduck-datasets-dirty/lj_for_upload/lj_...</td>\n",
       "      <td>produced the block books, which were the immed...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>s3://uberduck-datasets-dirty/lj_for_upload/lj_...</td>\n",
       "      <td>the invention of movable metal letters in the ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>s3://uberduck-datasets-dirty/lj_for_upload/lj_...</td>\n",
       "      <td>have now come into general use and are obvious...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>s3://uberduck-datasets-dirty/lj_for_upload/lj_...</td>\n",
       "      <td>a little reduced in ugliness. The design of th...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>s3://uberduck-datasets-dirty/lj_for_upload/lj_...</td>\n",
       "      <td>and the whole effect is a little too gray, owi...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>s3://uberduck-datasets-dirty/lj_for_upload/lj_...</td>\n",
       "      <td>It must be remembered, however, that most mode...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>s3://uberduck-datasets-dirty/lj_for_upload/lj_...</td>\n",
       "      <td>and these somewhat wiry letters are suitable f...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows √ó 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 path  \\\n",
       "0   s3://uberduck-datasets-dirty/lj_for_upload/lj_...   \n",
       "1   s3://uberduck-datasets-dirty/lj_for_upload/lj_...   \n",
       "2   s3://uberduck-datasets-dirty/lj_for_upload/lj_...   \n",
       "3   s3://uberduck-datasets-dirty/lj_for_upload/lj_...   \n",
       "4   s3://uberduck-datasets-dirty/lj_for_upload/lj_...   \n",
       "..                                                ...   \n",
       "95  s3://uberduck-datasets-dirty/lj_for_upload/lj_...   \n",
       "96  s3://uberduck-datasets-dirty/lj_for_upload/lj_...   \n",
       "97  s3://uberduck-datasets-dirty/lj_for_upload/lj_...   \n",
       "98  s3://uberduck-datasets-dirty/lj_for_upload/lj_...   \n",
       "99  s3://uberduck-datasets-dirty/lj_for_upload/lj_...   \n",
       "\n",
       "                                           transcript  speaker_id  \n",
       "0   Printing, in the only sense with which we are ...           0  \n",
       "1                      in being comparatively modern.           0  \n",
       "2   For although the Chinese took impressions from...           0  \n",
       "3   produced the block books, which were the immed...           0  \n",
       "4   the invention of movable metal letters in the ...           0  \n",
       "..                                                ...         ...  \n",
       "95  have now come into general use and are obvious...           0  \n",
       "96  a little reduced in ugliness. The design of th...           0  \n",
       "97  and the whole effect is a little too gray, owi...           0  \n",
       "98  It must be remembered, however, that most mode...           0  \n",
       "99  and these somewhat wiry letters are suitable f...           0  \n",
       "\n",
       "[100 rows x 3 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lj_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "51ff3bfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_dataset = speaker_ids_ds.map_batches(\n",
    "    lambda table: table.rename(\n",
    "        columns={\n",
    "\n",
    "            \"value_1\": \"speaker_id\"\n",
    "        }\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3f6e7280",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'Dataset' object has no attribute 'speaker_id'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43moutput_dataset\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mspeaker_id\u001b[49m\u001b[38;5;241m.\u001b[39mtolist()\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'Dataset' object has no attribute 'speaker_id'"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(autoscaler +2s) Tip: use `ray status` to view detailed cluster status. To disable these messages, set RAY_SCHEDULER_EVENTS=0.\n",
      "(autoscaler +2s) Removing 2 nodes of type worker-node-type-0 (idle).\n",
      "(autoscaler +7s) Removing 2 nodes of type worker-node-type-0 (idle).\n",
      "(autoscaler +12s) Removing 2 nodes of type worker-node-type-0 (idle).\n"
     ]
    }
   ],
   "source": [
    "output_dataset.speaker_id.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ad74882",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(output_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c9f6b20",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-03-06 16:50:22,749\tINFO bulk_executor.py:41 -- Executing DAG InputDataBuffer[Input] -> TaskPoolMapOperator[MapBatches(<lambda>)->MapBatches(<lambda>)]\n",
      "MapBatches(<lambda>)->MapBatches(<lambda>): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 100/100 [00:03<00:00, 28.88it/s]\n"
     ]
    }
   ],
   "source": [
    "output_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "c9591d28",
   "metadata": {},
   "outputs": [],
   "source": [
    "#     lj_df = pd.read_csv(\n",
    "#         \"https://uberduck-datasets-dirty.s3.us-west-2.amazonaws.com/vctk_mic1/all_with_embs.txt\",\n",
    "#         sep=\"|\",\n",
    "#         header=None,\n",
    "#         quoting=3,\n",
    "#         names=[\"path\", \"speaker_id\", \"transcript\", \"dataset_audio_file_id\", \"emb_path\"],\n",
    "#     )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "87b2cfb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# lj_df['path'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "ae5b6b61",
   "metadata": {},
   "outputs": [],
   "source": [
    "# transcripts_ds = ray.data.from_items(transcripts, parallelism=parallelism_length)\n",
    "# speaker_ids_ds = ray.data.from_items(speaker_ids, parallelism=parallelism_length)\n",
    "# dataset_audio_file_ids = ray.data.from_items(\n",
    "#     dataset_audio_files, parallelism=parallelism_length\n",
    "# )\n",
    "\n",
    "# pitch_paths_ds = ray.data.read_binary_files(\n",
    "#     pitch_paths,\n",
    "#     parallelism=parallelism_length,\n",
    "#     meta_provider=FastFileMetadataProvider(),\n",
    "#     ray_remote_args={\"num_cpus\": 0.2},\n",
    "# )\n",
    "\n",
    "# audio_ds = audio_ds.map_batches(\n",
    "#     lambda x: x, batch_format=\"pyarrow\", batch_size=None\n",
    "# )\n",
    "# transcripts_ds = transcripts_ds.map_batches(\n",
    "#     lambda x: x, batch_format=\"pyarrow\", batch_size=None\n",
    "# )\n",
    "# dataset_audio_file_ids = dataset_audio_file_ids.map_batches(\n",
    "#     lambda x: x, batch_format=\"pyarrow\", batch_size=None\n",
    "# )\n",
    "# paths_ds = paths.map_batches(lambda x: x, batch_format=\"pyarrow\", batch_size=None)\n",
    "# pitches_paths_ds = pitch_paths_ds.map_batches(\n",
    "#     lambda x: x, batch_format=\"pyarrow\", batch_size=None\n",
    "# )\n",
    "# speaker_ids_ds = speaker_ids_ds.map_batches(\n",
    "#     lambda x: x, batch_format=\"pyarrow\", batch_size=None\n",
    "# )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d71aa34",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
